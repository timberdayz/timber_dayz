name: Deploy to Production

on:
  # [NOTE] 方案A：生产发布只通过 push tag(v*) 触发（同一条流水线内 build -> deploy）
  push:
    tags:
      - "v*"
  # [NOTE] 手动部署：用于回滚或重试（不会重新 build 镜像，只部署指定 tag）
  workflow_dispatch:
    inputs:
      image_tag:
        description: "Image tag to deploy (e.g., v4.19.7)"
        required: true
        type: string
      confirm:
        description: 'Type "DEPLOY" to confirm production deployment'
        required: true
        type: string

# [NOTE] 并发控制：同一时间只允许一个生产部署在运行（避免带宽/资源冲突）
concurrency:
  group: deploy-production
  cancel-in-progress: true

env:
  REGISTRY: ghcr.io
  IMAGE_NAME_BACKEND: ${{ github.repository }}/backend
  IMAGE_NAME_FRONTEND: ${{ github.repository }}/frontend

jobs:
  # 检查是否配置了必要的 secrets
  check-config:
    runs-on: ubuntu-latest
    outputs:
      can_deploy: ${{ steps.check.outputs.can_deploy }}
    steps:
      - name: Check deployment configuration
        id: check
        run: |
          if [ -z "${{ secrets.PRODUCTION_SSH_PRIVATE_KEY }}" ] || [ -z "${{ secrets.PRODUCTION_HOST }}" ]; then
            echo "Production deployment secrets not configured. Skipping deployment."
            echo "Required secrets: PRODUCTION_SSH_PRIVATE_KEY, PRODUCTION_HOST"
            echo "can_deploy=false" >> $GITHUB_OUTPUT
          else
            echo "Production deployment secrets configured. Proceeding with deployment."
            echo "can_deploy=true" >> $GITHUB_OUTPUT
          fi

  validate:
    name: Validate Data Flow (Release Gate)
    runs-on: ubuntu-latest
    needs: check-config
    if: ${{ needs.check-config.outputs.can_deploy == 'true' && github.event_name == 'push' }}
    steps:
      - name: Checkout code (tag)
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Create temp directory
        run: mkdir -p temp

      # [FIX] 计算本次发布改动的文件（只验证改动文件，避免历史遗留问题阻断新发布）
      - name: Get changed files since last tag
        id: changed-files
        run: |
          # 获取所有 tag，按版本号排序
          git fetch --tags --force
          
          # 获取当前 tag
          CURRENT_TAG="${{ github.ref_name }}"
          echo "[INFO] Current tag: ${CURRENT_TAG}"
          
          # 获取上一个 tag（按版本号排序，排除当前 tag，取最新的）
          ALL_TAGS=$(git tag --sort=-version:refname | grep -E '^v[0-9]+\.[0-9]+\.[0-9]+$')
          PREV_TAG=$(echo "${ALL_TAGS}" | grep -v "^${CURRENT_TAG}$" | head -n 1)
          
          if [ -z "${PREV_TAG}" ]; then
            echo "[INFO] 未找到上一个 tag，将验证所有文件（首次发布或只有一个 tag）"
            echo "has_prev_tag=false" >> $GITHUB_OUTPUT
            echo "prev_tag=" >> $GITHUB_OUTPUT
            echo "changed_count=0" >> $GITHUB_OUTPUT
          else
            echo "[INFO] 上一个 tag: ${PREV_TAG}"
            echo "has_prev_tag=true" >> $GITHUB_OUTPUT
            echo "prev_tag=${PREV_TAG}" >> $GITHUB_OUTPUT
            
            # 计算改动的文件（相对于项目根目录）
            # 注意：HEAD 指向当前 checkout 的 tag commit
            git diff --name-only ${PREV_TAG}..HEAD > temp/changed_files.txt || true
            
            # 显示改动的文件数量
            CHANGED_COUNT=$(wc -l < temp/changed_files.txt | tr -d ' ' || echo "0")
            echo "[INFO] 发现 ${CHANGED_COUNT} 个改动文件（从 ${PREV_TAG} 到 ${CURRENT_TAG}）"
            echo "changed_count=${CHANGED_COUNT}" >> $GITHUB_OUTPUT
            
            # 显示前10个改动的文件（用于调试）
            if [ "${CHANGED_COUNT}" -gt 0 ]; then
              echo "[INFO] 改动的文件（前10个）:"
              head -10 temp/changed_files.txt | sed 's/^/  - /'
              
              # 显示改动的 router 文件数量
              ROUTER_COUNT=$(grep -c "^backend/routers/.*\.py$" temp/changed_files.txt || echo "0")
              echo "[INFO] 其中 router 文件: ${ROUTER_COUNT} 个"
            else
              echo "[INFO] 没有发现改动文件（可能是 tag 指向同一个 commit）"
            fi
          fi

      # [NOTE] 发布门禁：tag 发布必须通过这些检查；失败会阻断 build 和 deploy
      # [FIX] 只验证改动的 router 文件，避免历史遗留问题阻断新发布
      - name: Validate API Contracts (Release Gate)
        run: |
          if [ "${{ steps.changed-files.outputs.has_prev_tag }}" == "true" ] && [ -f "temp/changed_files.txt" ]; then
            echo "[INFO] 只验证改动的 router 文件..."
            python scripts/validate_api_contracts.py --changed-files temp/changed_files.txt
          else
            echo "[INFO] 未找到改动文件列表，验证所有文件..."
            python scripts/validate_api_contracts.py
          fi

      - name: Validate Frontend API Methods (Release Gate)
        run: python scripts/validate_frontend_api_methods.py

      - name: Validate Database Fields (Release Gate)
        run: python scripts/validate_database_fields.py

  build-and-push:
    name: Build and Push Images (Release Tag)
    runs-on: ubuntu-latest
    needs: validate
    if: ${{ github.event_name == 'push' }}
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout code (tag)
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata (tags, labels) for backend
        id: meta-backend
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}
          tags: |
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            # [FIX] 同时推送带 v 前缀的 tag（v4.20.5 / 4.20.5），避免部署端找不到 manifest
            type=semver,pattern=v{{version}}
            type=semver,pattern=v{{major}}.{{minor}}
            # [FIX] 固定 sha tag 规则，避免生成非法 tag
            type=sha,format=short,prefix=sha-

      - name: Extract metadata (tags, labels) for frontend
        id: meta-frontend
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_FRONTEND }}
          tags: |
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            # [FIX] 同时推送带 v 前缀的 tag（v4.20.5 / 4.20.5）
            type=semver,pattern=v{{version}}
            type=semver,pattern=v{{major}}.{{minor}}
            # [FIX] 固定 sha tag 规则，避免生成非法 tag
            type=sha,format=short,prefix=sha-

      - name: Build and push backend image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.backend
          push: true
          tags: ${{ steps.meta-backend.outputs.tags }}
          labels: ${{ steps.meta-backend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PYTHON_VERSION=3.11

      - name: Build and push frontend image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.frontend
          push: true
          tags: ${{ steps.meta-frontend.outputs.tags }}
          labels: ${{ steps.meta-frontend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          target: production
          build-args: |
            NODE_VERSION=18
            VITE_API_URL=${{ secrets.VITE_API_URL || 'http://localhost:8001' }}

  deploy-tag:
    name: Deploy to Production (Tag Release)
    runs-on: ubuntu-latest
    needs: [check-config, validate, build-and-push]
    if: ${{ needs.check-config.outputs.can_deploy == 'true' && github.event_name == 'push' }}
    environment:
      name: production

    steps:
      - name: Checkout code (tag)
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}

      - name: Determine deploy tag (from ref)
        id: image-tag
        run: |
          echo "tag=${GITHUB_REF_NAME}" >> $GITHUB_OUTPUT
          echo "Deploying with tag: ${GITHUB_REF_NAME}"

      - name: Set up SSH
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.PRODUCTION_SSH_PRIVATE_KEY }}

      - name: Sync compose files to production server
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
        run: |
          # [NOTE] 方案A1：直接使用 SCP 上传 compose 文件（移除 git pull，更简单、更稳定）
          # compose 文件很小，对 5MB 带宽影响很小，不需要配置服务器 git 凭据
          echo "[INFO] Uploading compose files via SCP..."

          # 1. 上传 docker-compose.yml（必需）
          echo "[INFO] Uploading docker-compose.yml..."
          scp -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              docker-compose.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.yml || {
            echo "[FAIL] Failed to upload docker-compose.yml"
            exit 1
          }
          echo "[OK] docker-compose.yml uploaded successfully"

          # 2. 上传 docker-compose.prod.yml（必需，如果存在）
          if [ -f "docker-compose.prod.yml" ]; then
            echo "[INFO] Uploading docker-compose.prod.yml..."
            scp -o StrictHostKeyChecking=no \
                -o ServerAliveInterval=30 \
                -o ServerAliveCountMax=10 \
                docker-compose.prod.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.prod.yml || {
              echo "[FAIL] Failed to upload docker-compose.prod.yml"
              exit 1
            }
            echo "[OK] docker-compose.prod.yml uploaded successfully"
          else
            echo "[WARN] docker-compose.prod.yml not found, skipping..."
          fi

          # 3. 上传 docker-compose.cloud.yml（可选，如果存在）
          if [ -f "docker-compose.cloud.yml" ]; then
            echo "[INFO] Uploading docker-compose.cloud.yml..."
            if scp -o StrictHostKeyChecking=no \
                -o ServerAliveInterval=30 \
                -o ServerAliveCountMax=10 \
                docker-compose.cloud.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.cloud.yml; then
              echo "[OK] docker-compose.cloud.yml uploaded successfully"
            else
              echo "[WARN] Failed to upload docker-compose.cloud.yml (optional file, continuing...)"
            fi
          else
            echo "[INFO] docker-compose.cloud.yml not found, skipping (optional file)..."
          fi

          # 4. 上传 docker-compose.metabase.yml（生产必需组件，如果存在）
          if [ -f "docker-compose.metabase.yml" ]; then
            echo "[INFO] Uploading docker-compose.metabase.yml..."
            scp -o StrictHostKeyChecking=no \
                -o ServerAliveInterval=30 \
                -o ServerAliveCountMax=10 \
                docker-compose.metabase.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.metabase.yml || {
              echo "[FAIL] Failed to upload docker-compose.metabase.yml (required for production)"
              exit 1
            }
            echo "[OK] docker-compose.metabase.yml uploaded successfully"
          else
            echo "[WARN] docker-compose.metabase.yml not found (required for production, deployment may fail if Metabase is not configured)"
          fi

          echo "[OK] All compose files synced successfully via SCP"

      - name: Backup current deployment
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
        run: |
          # [FIX] 使用 bash -c 远程执行，避免 heredoc 语法问题
          ssh -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              ${PRODUCTION_USER}@${PRODUCTION_HOST} \
              "bash -c 'set -e; \
              cd \"${PRODUCTION_PATH}\"; \
              BACKUP_DIR=\"backups/pre_deploy_\$(date +%Y%m%d_%H%M%S)\"; \
              mkdir -p \"\${BACKUP_DIR}\"; \
              docker-compose -f docker-compose.yml -f docker-compose.prod.yml --profile production config > \"\${BACKUP_DIR}/docker-compose.config.yaml\" 2>&1 || echo \"[WARN] Docker Compose config validation failed, but continuing backup...\"; \
              docker ps --format \"{{.Names}} {{.Image}}\" > \"\${BACKUP_DIR}/running_containers.txt\" || true; \
              echo \"[OK] Pre-deployment backup completed: \${BACKUP_DIR}\"'"

      - name: Deploy to production server
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          # [FIX] 避免 heredoc 语法问题，使用 bash -c 执行远程命令
          # [NOTE] 外层双引号允许本地变量展开（${IMAGE_TAG}），内层单引号中的变量需转义（\$retry）
          ssh -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              ${PRODUCTION_USER}@${PRODUCTION_HOST} \
          "bash -c '
          set -e
          cd \"${PRODUCTION_PATH}\"

          # 登录到容器仓库
          echo \"[INFO] Logging in to container registry...\"
          echo \"${{ secrets.GITHUB_TOKEN }}\" | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin
          echo \"[OK] Successfully logged in to container registry\"

          # [FIX] 使用 tag 而非 latest（提升可追溯性）
          # 拉取指定版本的镜像（添加进度输出、重试机制和容错机制）
          # [FIX] ${IMAGE_TAG} 在外层双引号中会展开，传递给远程服务器
          # 在 bash -c 单引号内，先赋值给变量，确保正确使用
          IMAGE_TAG_VAL=\"${IMAGE_TAG}\"
          ORIGINAL_REQUESTED_TAG=\"\${IMAGE_TAG_VAL}\"
          echo \"[INFO] Pulling images with tag: \${IMAGE_TAG_VAL}\"

          # [NOTE] 容错函数：尝试多个 tag 变体（v4.20.4 -> 4.20.4）
          # [FIX] 移除 2>/dev/null，让 docker pull 的真实错误输出可见（便于诊断网络/权限/tag 问题）
          pull_image_with_fallback() {
            local IMAGE_NAME=\$1
            local PRIMARY_TAG=\$2
            local FALLBACK_TAG=\"\${PRIMARY_TAG#v}\"
            local FULL_IMAGE=\"${{ env.REGISTRY }}/\${IMAGE_NAME}:\${PRIMARY_TAG}\"
            
            echo \"[INFO] Attempting to pull \${FULL_IMAGE}...\"
            
            # 先尝试主 tag（如 v4.20.4）
            for retry in {1..3}; do
              echo \"[INFO] Pull attempt \$retry/3 for \${FULL_IMAGE}...\"
              # [FIX] 移除 2>/dev/null，让错误直接输出到日志
              # 直接执行 docker pull，让所有输出（包括错误）都显示到日志
              # 使用 || 捕获失败，同时保持错误输出可见
              docker pull \${FULL_IMAGE} 2>&1
              PULL_EXIT_CODE=\$?
              if [ \${PULL_EXIT_CODE} -eq 0 ]; then
                echo \"[OK] Image pulled successfully with tag \${PRIMARY_TAG} (attempt \$retry/3)\"
                echo \"\${PRIMARY_TAG}\"
                return 0
              else
                echo \"[WARN] Pull failed with exit code \${PULL_EXIT_CODE} (attempt \$retry/3)\"
                echo \"[INFO] Error details shown above. Retrying in 5 seconds...\"
                if [ \$retry -lt 3 ]; then
                  sleep 5
                fi
              fi
            done
            
            # 如果主 tag 失败，尝试不带 v 前缀的 tag（如 4.20.4）
            if [ \"\${PRIMARY_TAG}\" != \"\${FALLBACK_TAG}\" ]; then
              FULL_IMAGE_FALLBACK=\"${{ env.REGISTRY }}/\${IMAGE_NAME}:\${FALLBACK_TAG}\"
              echo \"[WARN] Primary tag \${PRIMARY_TAG} failed after 3 attempts, trying fallback tag \${FALLBACK_TAG}...\"
              
              for retry in {1..3}; do
                echo \"[INFO] Fallback pull attempt \$retry/3 for \${FULL_IMAGE_FALLBACK}...\"
                # [FIX] 移除 2>/dev/null，让错误直接输出到日志
                # 直接执行 docker pull，让所有输出（包括错误）都显示到日志
                docker pull \${FULL_IMAGE_FALLBACK} 2>&1
                PULL_EXIT_CODE=\$?
                if [ \${PULL_EXIT_CODE} -eq 0 ]; then
                  echo \"[OK] Image pulled successfully with fallback tag \${FALLBACK_TAG} (attempt \$retry/3)\"
                  echo \"\${FALLBACK_TAG}\"
                  return 0
                else
                  echo \"[WARN] Fallback pull failed with exit code \${PULL_EXIT_CODE} (attempt \$retry/3)\"
                  echo \"[INFO] Error details shown above. Retrying in 5 seconds...\"
                  if [ \$retry -lt 3 ]; then
                    sleep 5
                  fi
                fi
              done
            fi
            
            # 所有尝试都失败
            echo \"[FAIL] Failed to pull image \${IMAGE_NAME} with both tags \${PRIMARY_TAG} and \${FALLBACK_TAG}\"
            echo \"[INFO] Checking available tags...\"
            docker pull ${{ env.REGISTRY }}/\${IMAGE_NAME} --all-tags 2>&1 | grep -E \"(v[0-9]|[0-9]+\.[0-9]|latest)\" | head -10 || true
            return 1
          }

          # 拉取 Backend 镜像
          echo \"[INFO] Pulling backend image...\"
          BACKEND_TAG=\$(pull_image_with_fallback \"${{ env.IMAGE_NAME_BACKEND }}\" \"\${IMAGE_TAG_VAL}\")
          if [ \$? -ne 0 ]; then
            echo \"[FAIL] Backend image pull failed\"
            exit 1
          fi
          echo \"[OK] Backend image tag resolved: \${BACKEND_TAG}\"

          # 拉取 Frontend 镜像
          echo \"[INFO] Pulling frontend image...\"
          FRONTEND_TAG=\$(pull_image_with_fallback \"${{ env.IMAGE_NAME_FRONTEND }}\" \"\${IMAGE_TAG_VAL}\")
          if [ \$? -ne 0 ]; then
            echo \"[FAIL] Frontend image pull failed\"
            exit 1
          fi
          echo \"[OK] Frontend image tag resolved: \${FRONTEND_TAG}\"

          # [FIX] 使用实际拉取成功的 tag（可能是 PRIMARY_TAG 或 FALLBACK_TAG）
          IMAGE_TAG_VAL=\"\${BACKEND_TAG}\"
          echo \"[INFO] Images pulled successfully with resolved tags: Backend=\${BACKEND_TAG}, Frontend=\${FRONTEND_TAG}\"
          echo \"[INFO] Using resolved tag for deployment (not latest) for better traceability\"

          # [NOTE] 清理可能占用端口80的旧容器
          echo \"[INFO] Cleaning up old containers that might conflict with port 80...\"
          docker stop xihong_erp_frontend 2>/dev/null || true
          docker rm xihong_erp_frontend 2>/dev/null || true
          PORT_80_CONTAINER=\$(docker ps --format \"{{.Names}}\" --filter \"publish=80\" 2>/dev/null | head -1 || echo \"\")
          if [ -n \"\${PORT_80_CONTAINER}\" ] && [ \"\${PORT_80_CONTAINER}\" != \"xihong_erp_nginx\" ]; then
            echo \"[WARN] Found container \${PORT_80_CONTAINER} using port 80, stopping it...\"
            docker stop \${PORT_80_CONTAINER} 2>/dev/null || true
          fi
          echo \"[OK] Cleanup completed\"

          # 使用 docker-compose 部署（生产环境）
          export APP_ENV=production
          export COMPOSE_PROJECT_NAME=xihong_erp

          # [NOTE] 同步 compose 文件后，docker-compose up -d 会自动检测配置变化
          # 如果配置有变化（如端口、环境变量等），docker-compose 会自动重新创建容器
          # 因此不需要手动重新部署，工作流会自动完成部署

          # [FIX] 创建临时 compose 文件，使用实际拉取成功的 tag（可能是 PRIMARY_TAG 或 FALLBACK_TAG）
          echo \"[INFO] Creating temporary docker-compose.deploy.yml...\"
          # 使用实际拉取成功的 tag 直接指定镜像（提升可追溯性）
          # [NOTE] 分别使用 BACKEND_TAG 和 FRONTEND_TAG，因为它们可能不同
          printf \"services:\\n  backend:\\n    image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}:\${BACKEND_TAG}\\n  frontend:\\n    image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_FRONTEND }}:\${FRONTEND_TAG}\\n    ports: []\\n\" > docker-compose.deploy.yml
          echo \"[OK] Temporary compose file created with tags: Backend=\${BACKEND_TAG}, Frontend=\${FRONTEND_TAG}\"

          # [NOTE] 分阶段启动服务（确保 Metabase 在 Nginx 之前启动）
          echo \"[INFO] 阶段1: 启动基础设施层（PostgreSQL, Redis）...\"
          if [ -f docker-compose.cloud.yml ]; then
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.cloud.yml --profile production up -d postgres redis
          else
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml --profile production up -d postgres redis
          fi

          # [FIX] 等待基础设施健康：从服务器 .env 读取环境变量（避免硬编码密码）
          echo \"[INFO] 等待基础设施服务健康...\"
          # [FIX] 从服务器 .env 加载环境变量（如果存在），支持自定义密码/用户
          if [ -f \".env\" ]; then
            echo \"[INFO] 从 .env 加载环境变量...\"
            set -a
            . ./.env
            set +a
            echo \"[INFO] 已加载环境变量：POSTGRES_USER=\${POSTGRES_USER:-erp_user}, POSTGRES_DB=\${POSTGRES_DB:-xihong_erp}, REDIS_PASSWORD=\${REDIS_PASSWORD:+***已设置}\"
          else
            echo \"[WARN] .env 文件不存在，使用默认值\"
          fi
          
          # [FIX] 使用环境变量（如果未设置则使用默认值）
          POSTGRES_USER_VAL=\"\${POSTGRES_USER:-erp_user}\"
          POSTGRES_DB_VAL=\"\${POSTGRES_DB:-xihong_erp}\"
          REDIS_PASSWORD_VAL=\"\${REDIS_PASSWORD:-redis_pass_2025}\"
          
          for i in {1..60}; do
            # [FIX] 移除 2>/dev/null，让 PostgreSQL 错误可见
            postgres_output=\$(docker exec xihong_erp_postgres pg_isready -U \"\${POSTGRES_USER_VAL}\" -d \"\${POSTGRES_DB_VAL}\" 2>&1)
            postgres_exit_code=\$?
            if [ \${postgres_exit_code} -eq 0 ]; then
              postgres_ready=\"ok\"
            else
              postgres_ready=\"\"
              if [ \$i -eq 1 ] || [ \$((i % 10)) -eq 0 ]; then
                echo \"[WARN] PostgreSQL 健康检查失败 (attempt \$i/60): \${postgres_output}\"
              fi
            fi
            
            # [FIX] 移除 2>/dev/null，让 Redis 错误可见（WRONGPASS 等）
            redis_output=\$(docker exec xihong_erp_redis redis-cli -a \"\${REDIS_PASSWORD_VAL}\" ping 2>&1)
            if echo \"\${redis_output}\" | grep -q \"^PONG\"; then
              redis_ready=\"ok\"
            else
              redis_ready=\"\"
              if [ \$i -eq 1 ] || [ \$((i % 10)) -eq 0 ]; then
                echo \"[WARN] Redis 健康检查失败 (attempt \$i/60): \${redis_output}\"
                # [FIX] 如果检测到 WRONGPASS 错误，给出明确提示
                if echo \"\${redis_output}\" | grep -qi \"WRONGPASS\|NOAUTH\"; then
                  echo \"[ERROR] Redis 密码错误！请检查服务器 .env 中的 REDIS_PASSWORD 是否与 docker-compose.prod.yml 中配置一致\"
                  echo \"[INFO] 当前使用的密码变量值: REDIS_PASSWORD=\${REDIS_PASSWORD_VAL}\"
                fi
              fi
            fi
            
            if [ -n \"\${postgres_ready}\" ] && [ -n \"\${redis_ready}\" ]; then
              echo \"[OK] 基础设施服务已健康 (PostgreSQL: \${POSTGRES_USER_VAL}@\${POSTGRES_DB_VAL}, Redis: 已认证)\"
              break
            fi
            
            if [ \$i -eq 60 ]; then
              echo \"[FAIL] 基础设施服务启动超时（60次检查，共120秒）\"
              echo \"[INFO] 诊断信息：\"
              echo \"  - PostgreSQL 用户: \${POSTGRES_USER_VAL}, 数据库: \${POSTGRES_DB_VAL}\"
              echo \"  - Redis 密码变量: REDIS_PASSWORD=\${REDIS_PASSWORD_VAL}\"
              echo \"[INFO] 容器状态：\"
              docker ps --format \"table {{.Names}}\\t{{.Status}}\" | grep -E \"xihong_erp_(postgres|redis)\" || echo \"  容器未找到\"
              echo \"[INFO] 容器日志（最后30行）：\"
              docker logs xihong_erp_postgres --tail 30 2>&1 | sed 's/^/  [PostgreSQL] /' || echo \"  无法获取 PostgreSQL 日志\"
              docker logs xihong_erp_redis --tail 30 2>&1 | sed 's/^/  [Redis] /' || echo \"  无法获取 Redis 日志\"
              exit 1
            fi
            
            echo \"等待基础设施... (\$i/60)\"
            sleep 2
          done

          # [NOTE] 关键：先启动 Metabase（生产必需组件，必须在 Nginx 之前）
          echo \"[INFO] 阶段2: 启动 Metabase 服务（必须在 Nginx 之前）...\"
          if [ -f docker-compose.metabase.yml ]; then
            docker-compose -f docker-compose.metabase.yml --profile production up -d metabase
            echo \"[INFO] 等待 Metabase 健康（最多60秒）...\"
            for i in {1..60}; do
              if docker exec xihong_erp_metabase curl -f http://localhost:3000/api/health > /dev/null 2>&1; then
                echo \"[OK] Metabase 已健康\"
                break
              fi
              if [ \$i -eq 60 ]; then
                echo \"[WARN] Metabase 启动超时，但继续部署（Nginx 可能失败）\"
                docker logs xihong_erp_metabase --tail 30
              fi
              echo \"等待 Metabase... (\$i/60)\"
              sleep 2
            done
          else
            echo \"[FAIL] docker-compose.metabase.yml 不存在，Metabase 是生产必需组件！\"
            exit 1
          fi

          # 启动应用层（Backend, Celery）
          echo \"[INFO] 阶段3: 启动应用层（Backend, Celery）...\"
          if [ -f docker-compose.cloud.yml ]; then
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.cloud.yml -f docker-compose.deploy.yml --profile production up -d backend celery-worker celery-beat celery-exporter
          else
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.deploy.yml --profile production up -d backend celery-worker celery-beat celery-exporter
          fi

          # 等待 Backend 健康（Frontend 依赖 Backend）
          echo \"[INFO] 等待 Backend 健康...\"
          for i in {1..60}; do
            if docker exec xihong_erp_backend curl -f http://localhost:8000/health > /dev/null 2>&1; then
              echo \"[OK] Backend 已健康\"
              break
            fi
            if [ \$i -eq 60 ]; then
              echo \"[FAIL] Backend 启动超时\"
              docker logs xihong_erp_backend --tail 50
              exit 1
            fi
            echo \"等待 Backend... (\$i/60)\"
            sleep 2
          done

          # 启动前端
          echo \"[INFO] 阶段4: 启动前端层（Frontend）...\"
          if [ -f docker-compose.cloud.yml ]; then
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.cloud.yml -f docker-compose.deploy.yml --profile production up -d frontend
          else
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.deploy.yml --profile production up -d frontend
          fi

          # 等待 Frontend 健康（可选）
          echo \"[INFO] 等待 Frontend 健康...\"
          for i in {1..30}; do
            if docker exec xihong_erp_frontend curl -f http://localhost:80 > /dev/null 2>&1; then
              echo \"[OK] Frontend 已健康\"
              break
            fi
            echo \"等待 Frontend... (\$i/30)\"
            sleep 2
          done

          # [NOTE] 关键：最后启动 Nginx（确保所有上游服务已就绪）
          echo \"[INFO] 阶段5: 启动网关层（Nginx，最后启动）...\"
          if [ -f docker-compose.cloud.yml ]; then
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.cloud.yml -f docker-compose.deploy.yml --profile production up -d nginx
          else
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.deploy.yml --profile production up -d nginx
          fi

          echo \"[OK] Docker Compose services started/updated in correct order\"

          # 等待服务启动
          echo \"[INFO] Waiting for services to start...\"
          sleep 15
          echo \"[INFO] Services should be starting now...\"

          # 健康检查（通过容器网络检查，不依赖宿主机端口）
          echo \"[INFO] Starting backend health check...\"
          for i in {1..60}; do
            if docker exec xihong_erp_backend curl -f http://localhost:8000/health > /dev/null 2>&1; then
              echo \"[OK] Backend health check passed (container internal)\"
              break
            fi
            if [ \$i -eq 60 ]; then
              echo \"[FAIL] Backend health check failed after 2 minutes\"
              echo \"[INFO] Checking backend logs...\"
              docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.deploy.yml logs backend 2>/dev/null || \
              docker-compose -f docker-compose.yml -f docker-compose.prod.yml logs backend
              exit 1
            fi
            if [ \$((i % 5)) -eq 0 ]; then
              echo \"[INFO] Waiting for backend... (\$i/60)\"
            fi
            sleep 2
          done

          # 验证前端（通过容器网络检查，不依赖宿主机端口）
          if docker ps | grep -q xihong_erp_frontend; then
            echo \"[INFO] Checking frontend health (container internal)...\"
            for i in {1..30}; do
              if docker exec xihong_erp_frontend curl -f http://localhost:80 > /dev/null 2>&1; then
                echo \"[OK] Frontend health check passed (container internal)\"
                break
              fi
              if [ \$i -eq 30 ]; then
                echo \"[WARN] Frontend health check failed (non-critical)\"
              fi
              sleep 2
            done
          else
            echo \"[INFO] Frontend container not found, skipping frontend health check\"
          fi

          # 验证 Nginx（如果部署了 Nginx）
          if docker ps | grep -q xihong_erp_nginx; then
            echo \"[INFO] Checking Nginx health...\"
            for i in {1..30}; do
              if curl -f http://localhost/health > /dev/null 2>&1; then
                echo \"[OK] Nginx health check passed (port 80)\"
                break
              fi
              if [ \$i -eq 30 ]; then
                echo \"[WARN] Nginx health check failed (non-critical)\"
              fi
              sleep 2
            done
          else
            echo \"[INFO] Nginx container not found, skipping Nginx health check\"
          fi

          echo \"[OK] Production deployment completed successfully\"
          echo \"Deployed image tags: Backend=\${BACKEND_TAG}, Frontend=\${FRONTEND_TAG}\"
          echo \"Original requested tag: \${ORIGINAL_REQUESTED_TAG}\"

          # 清理临时文件
          echo \"[INFO] Cleaning up temporary files...\"
          rm -f docker-compose.deploy.yml
          echo \"[OK] Cleanup completed\"
          '"

  deploy-manual:
    name: Deploy to Production (Manual)
    runs-on: ubuntu-latest
    needs: check-config
    if: ${{ needs.check-config.outputs.can_deploy == 'true' && github.event_name == 'workflow_dispatch' }}
    environment:
      name: production
    steps:
      - name: Checkout code (main)
        uses: actions/checkout@v4
        with:
          ref: main

      - name: Verify deployment confirmation
        run: |
          if [ "${{ github.event.inputs.confirm }}" != "DEPLOY" ]; then
            echo "Deployment confirmation failed. Please type 'DEPLOY' to confirm."
            exit 1
          fi
          echo "Deployment confirmed"

      - name: Determine deploy tag (manual input)
        id: image-tag
        run: |
          echo "tag=${{ github.event.inputs.image_tag }}" >> $GITHUB_OUTPUT
          echo "Deploying with tag: ${{ github.event.inputs.image_tag }}"

      - name: Set up SSH
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.PRODUCTION_SSH_PRIVATE_KEY }}

      - name: Sync compose files to production server
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
        run: |
          echo "[INFO] Uploading compose files via SCP..."
          scp -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              docker-compose.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.yml || {
            echo "[FAIL] Failed to upload docker-compose.yml"
            exit 1
          }
          if [ -f "docker-compose.prod.yml" ]; then
            scp -o StrictHostKeyChecking=no \
                -o ServerAliveInterval=30 \
                -o ServerAliveCountMax=10 \
                docker-compose.prod.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.prod.yml || {
              echo "[FAIL] Failed to upload docker-compose.prod.yml"
              exit 1
            }
          fi
          if [ -f "docker-compose.cloud.yml" ]; then
            scp -o StrictHostKeyChecking=no \
                -o ServerAliveInterval=30 \
                -o ServerAliveCountMax=10 \
                docker-compose.cloud.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.cloud.yml || {
              echo "[WARN] Failed to upload docker-compose.cloud.yml (optional file, continuing...)"
            }
          fi
          if [ -f "docker-compose.metabase.yml" ]; then
            scp -o StrictHostKeyChecking=no \
                -o ServerAliveInterval=30 \
                -o ServerAliveCountMax=10 \
                docker-compose.metabase.yml ${PRODUCTION_USER}@${PRODUCTION_HOST}:${PRODUCTION_PATH}/docker-compose.metabase.yml || {
              echo "[FAIL] Failed to upload docker-compose.metabase.yml (required for production)"
              exit 1
            }
          fi
          echo "[OK] All compose files synced successfully via SCP"

      - name: Backup current deployment
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
        run: |
          ssh -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              ${PRODUCTION_USER}@${PRODUCTION_HOST} \
              "bash -c 'set -e; \
              cd \"${PRODUCTION_PATH}\"; \
              BACKUP_DIR=\"backups/pre_deploy_$(date +%Y%m%d_%H%M%S)\"; \
              mkdir -p \"${BACKUP_DIR}\"; \
              docker-compose -f docker-compose.yml -f docker-compose.prod.yml --profile production config > \"${BACKUP_DIR}/docker-compose.config.yaml\" 2>&1 || echo \"[WARN] Docker Compose config validation failed, but continuing backup...\"; \
              docker ps --format \"{{.Names}} {{.Image}}\" > \"${BACKUP_DIR}/running_containers.txt\" || true; \
              echo \"[OK] Pre-deployment backup completed: ${BACKUP_DIR}\"'"

      - name: Deploy to production server
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          ssh -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              ${PRODUCTION_USER}@${PRODUCTION_HOST} \
          "bash -c '
          set -e
          cd \"${PRODUCTION_PATH}\"
          echo \"[INFO] Logging in to container registry...\"
          echo \"${{ secrets.GITHUB_TOKEN }}\" | docker login ${{ env.REGISTRY }} -u ${{ github.actor }} --password-stdin
          echo \"[OK] Logged in\"
          IMAGE_TAG_VAL=\"${IMAGE_TAG}\"
          ORIGINAL_REQUESTED_TAG=\"${IMAGE_TAG}\"
          echo \"[INFO] Pulling images with tag: ${IMAGE_TAG_VAL}\"
          BACKEND_IMAGE=\"${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}:${IMAGE_TAG_VAL}\"
          FRONTEND_IMAGE=\"${{ env.REGISTRY }}/${{ env.IMAGE_NAME_FRONTEND }}:${IMAGE_TAG_VAL}\"
          docker pull ${BACKEND_IMAGE}
          docker pull ${FRONTEND_IMAGE}
          echo \"[OK] Images pulled\"
          printf \"services:\\n  backend:\\n    image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BACKEND }}:${IMAGE_TAG_VAL}\\n  frontend:\\n    image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_FRONTEND }}:${IMAGE_TAG_VAL}\\n    ports: []\\n\" > docker-compose.deploy.yml
          if [ -f docker-compose.cloud.yml ]; then
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.cloud.yml -f docker-compose.deploy.yml --profile production up -d
          else
            docker-compose -f docker-compose.yml -f docker-compose.prod.yml -f docker-compose.deploy.yml --profile production up -d
          fi
          echo \"[OK] Production deployment completed successfully\"
          echo \"Original requested tag: ${ORIGINAL_REQUESTED_TAG}\"
          rm -f docker-compose.deploy.yml
          '"

      - name: Health check verification
        env:
          PRODUCTION_URL: ${{ secrets.PRODUCTION_URL }}
        run: |
          if [ -z "${PRODUCTION_URL}" ]; then
            echo "[WARN] PRODUCTION_URL not configured, skipping external health check"
            exit 0
          fi

          # [FIX] 域名备案期间，如果配置了 HTTPS 但 SSL 证书未配置，自动降级到 HTTP
          HEALTH_CHECK_URL="${PRODUCTION_URL}"
          if [[ "${PRODUCTION_URL}" == https://* ]]; then
            echo "[INFO] PRODUCTION_URL is HTTPS, attempting HTTPS health check first..."
            
            # 先尝试 HTTPS（如果 SSL 已配置）
            HTTPS_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 10 --connect-timeout 5 ${PRODUCTION_URL}/health 2>/dev/null || echo "000")
            
            if [ "${HTTPS_CODE}" = "200" ]; then
              echo "[OK] HTTPS health check passed, using HTTPS"
            else
              # HTTPS 失败，降级到 HTTP（域名备案期间，SSL 证书可能未配置）
              HTTP_URL="${PRODUCTION_URL/https:\/\//http:\/\/}"
              echo "[INFO] HTTPS health check failed (HTTP ${HTTPS_CODE}), domain may be in ICP filing process"
              echo "[INFO] Falling back to HTTP for health check: ${HTTP_URL}/health"
              echo "[INFO] Note: After ICP filing is completed and SSL certificate is configured, HTTPS will be used"
              HEALTH_CHECK_URL="${HTTP_URL}"
            fi
          fi

          echo "[INFO] Checking production health at: ${HEALTH_CHECK_URL}/health"

          # 增加重试机制和详细错误信息
          MAX_RETRIES=5
          RETRY_DELAY=10

          for i in $(seq 1 ${MAX_RETRIES}); do
            echo "[INFO] Health check attempt $i/${MAX_RETRIES}..."
            
            # 使用 curl 检查健康状态，增加超时和详细输出
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 30 --connect-timeout 10 ${HEALTH_CHECK_URL}/health 2>/dev/null || echo "000")
            
            if [ "${HTTP_CODE}" = "200" ]; then
              echo "[OK] Production health check passed (HTTP ${HTTP_CODE})"
              if [[ "${HEALTH_CHECK_URL}" == http://* ]] && [[ "${PRODUCTION_URL}" == https://* ]]; then
                echo "[INFO] Using HTTP during ICP filing period. HTTPS will be enabled after SSL certificate is configured."
              fi
              exit 0
            else
              echo "[WARN] Health check failed (HTTP ${HTTP_CODE}), attempt $i/${MAX_RETRIES}"
              
              if [ $i -lt ${MAX_RETRIES} ]; then
                echo "[INFO] Retrying in ${RETRY_DELAY} seconds..."
                sleep ${RETRY_DELAY}
              else
                echo "[FAIL] Production health check failed after ${MAX_RETRIES} attempts"
                echo "[INFO] Final HTTP Status Code: ${HTTP_CODE}"
                echo "[INFO] Health Check URL used: ${HEALTH_CHECK_URL}/health"
                echo "[INFO] Original PRODUCTION_URL: ${PRODUCTION_URL}"
                echo "[INFO] Please check:"
                echo "  1. Is the production URL correct? (${PRODUCTION_URL})"
                echo "  2. Is the service running and accessible?"
                echo "  3. Is the /health endpoint responding?"
                echo "  4. Check server logs: docker logs xihong_erp_backend"
                echo "  5. If domain is in ICP filing process, ensure DNS points to server IP"
                echo "  6. Check server firewall/security group allows port 80 (HTTP)"
                
                # 尝试获取更多诊断信息
                echo "[INFO] Attempting to get more diagnostic information..."
                curl -v --max-time 10 ${HEALTH_CHECK_URL}/health 2>&1 | head -20 || true
                
                exit 1
              fi
            fi
          done

      - name: Set up SSH for rollback
        if: failure()
        uses: webfactory/ssh-agent@v0.8.0
        with:
          ssh-private-key: ${{ secrets.PRODUCTION_SSH_PRIVATE_KEY }}

      - name: Rollback on failure
        if: failure()
        env:
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER || 'root' }}
          PRODUCTION_PATH: ${{ secrets.PRODUCTION_PATH || '/opt/xihong_erp' }}
        run: |
          # [FIX] 避免 heredoc 语法问题，使用 bash -c 执行远程命令
          ssh -o StrictHostKeyChecking=no \
              -o ServerAliveInterval=30 \
              -o ServerAliveCountMax=10 \
              ${PRODUCTION_USER}@${PRODUCTION_HOST} \
              "bash -c '
              set -e
              cd \"${PRODUCTION_PATH}\"
              
              echo \"[WARNING] Deployment failed, attempting rollback...\"
              
              # 查找上一个成功的部署备份
              LAST_BACKUP=\$(ls -td backups/pre_deploy_* 2>/dev/null | head -1)
              if [ -n \"\${LAST_BACKUP}\" ]; then
                echo \"Found backup: \${LAST_BACKUP}\"
                # 这里可以实现回滚逻辑（恢复配置、拉取上一个镜像等）
                echo \"[WARNING] Manual rollback required. Check backup: \${LAST_BACKUP}\"
              else
                echo \"[WARNING] No backup found for rollback\"
              fi
              '"

      - name: Send deployment notification
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          fields: repo,message,commit,author,action,eventName,ref,workflow
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        continue-on-error: true # 如果 SLACK_WEBHOOK_URL 未配置会静默失败

  # 当部署被跳过时显示消息
  skip-notification:
    runs-on: ubuntu-latest
    needs: check-config
    if: ${{ needs.check-config.outputs.can_deploy == 'false' }}
    steps:
      - name: Deployment skipped
        run: |
          echo "========================================"
          echo "Deployment to production was SKIPPED"
          echo "========================================"
          echo ""
          echo "Required GitHub Secrets not configured:"
          echo "  - PRODUCTION_SSH_PRIVATE_KEY"
          echo "  - PRODUCTION_HOST"
          echo ""
          echo "To enable deployment, configure these secrets in:"
          echo "  Settings > Secrets and variables > Actions"
          echo "========================================"
