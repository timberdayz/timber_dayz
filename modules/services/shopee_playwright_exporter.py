#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Shopee Playwright å®‰å…¨å¯¼å‡ºå™¨
===========================

- åœ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡å†…å‘èµ·è¯·æ±‚ä¸ä¸‹è½½ï¼Œè§„é¿è£¸ requests é£é™©
- æ”¯æŒåˆ—å‡ºè´¦å·ä¸‹æ‰€æœ‰åº—é“ºï¼ˆå®æ—¶æ‹‰å–ï¼‰
- æ”¯æŒâ€œå•†å“è¡¨ç°-æŒ‰å‘¨â€å¯¼å‡ºï¼šexport -> report_id -> download_link -> ç­‰å¾…ä¸‹è½½
- ç»Ÿä¸€åˆ†ç±»è¾“å‡ºè·¯å¾„ï¼štemp/outputs/<platform>/<account>/<shop_name>/<data_type>/<granularity>/
  æ–‡ä»¶å‘½åï¼šYYYYMMDD_HHMMSS__<account>__<shop>__<data_type>__<granularity>__<start>_<end>.xlsx
- æ—¥æœŸæ§ä»¶æ¢æµ‹ä¸åˆ†æ
"""
from __future__ import annotations

import json
import re
import time
import glob
import os
from typing import Dict, List, Optional, Tuple, TYPE_CHECKING
from dataclasses import dataclass
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, TYPE_CHECKING

if TYPE_CHECKING:
    from playwright.async_api import Page

from modules.utils.logger import get_logger
from modules.utils.path_sanitizer import build_output_path, build_filename
from modules.core.config import get_config_value

logger = get_logger(__name__)


@dataclass
class Shop:
    id: str
    name: str
    region: str = ""


class ShopeePlaywrightExporter:
    def __init__(self, playwright):
        from modules.utils.persistent_browser_manager import PersistentBrowserManager

        # å…¼å®¹ä¸¤ç§ä¼ å‚ï¼š
        # 1) Playwright å®ä¾‹ â†’ åˆ›å»ºæ–°çš„ PersistentBrowserManager
        # 2) PersistentBrowserManager å®ä¾‹ â†’ ç›´æ¥å¤ç”¨ï¼Œé¿å…é‡å¤åˆå§‹åŒ–ï¼ˆå‡å°‘â€œåˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨â€æ—¥å¿—ï¼‰
        if hasattr(playwright, 'get_or_create_persistent_context') and hasattr(playwright, 'playwright'):
            # è§†ä¸º PersistentBrowserManager
            self.pb = playwright
            self.playwright = playwright.playwright
        else:
            self.playwright = playwright
            self.pb = PersistentBrowserManager(playwright)
        self.base = "https://seller.shopee.cn"

    def _open_account_page(self, account: Dict, download_path: str = None):
        platform = account.get("platform", "shopee").lower()
        # æ ‡å‡†åŒ–æŒä¹…åŒ–ä¸Šä¸‹æ–‡Keyï¼šä¼˜å…ˆä½¿ç”¨ label/ç”¨æˆ·åï¼Œç¡®ä¿ä¸â€œè‡ªåŠ¨ç™»å½•æµç¨‹ä¿®æ­£â€ä¸€è‡´
        account_key = (
            account.get("store_name")
            or account.get("username")
            or str(account.get("account_id") or "account")
        )

        # å¦‚æœæŒ‡å®šäº†ä¸‹è½½è·¯å¾„ï¼Œè®¾ç½®æµè§ˆå™¨ä¸‹è½½ç›®å½•
        extra_options = {}
        if download_path:
            extra_options = {
                "accept_downloads": True,
                "downloads_path": download_path,
            }
            logger.info(f"è®¾ç½®ä¸‹è½½ç›®å½•: {download_path}")

        ctx = self.pb.get_or_create_persistent_context(platform, str(account_key), account, **extra_options)
        page = ctx.pages[0] if ctx.pages else ctx.new_page()
        login_url = account.get("login_url") or f"{self.base}/?cnsc_shop_id="
        logger.info(f"å¯¼èˆªåˆ°è´¦å·å…¥å£: {login_url}")
        page.goto(login_url, wait_until="domcontentloaded", timeout=60000)
        # è½»ç­‰å¾…æ¸²æŸ“
        page.wait_for_timeout(1200)

        # ä¼˜å…ˆç­‰å¾…å¯èƒ½çš„ä¼šè¯é‡å®šå‘ï¼ˆå·²ç™»å½•å°†ä» /account/signin è·³åˆ° /portalï¼‰
        try:
            from time import sleep
            for _ in range(8):  # ~4.8s å®½é™
                url_now = (page.url or "").lower()
                if ("/account/signin" not in url_now) and ("/login" not in url_now):
                    logger.info("æ£€æµ‹åˆ°å·²ç™»å½•ä¼šè¯ï¼Œè·³è¿‡è‡ªåŠ¨ç™»å½•")
                    return ctx, page, platform, str(account_key)
                sleep(0.6)
        except Exception:
            pass

        # ç¡®ä¿å·²ç™»å½•ï¼ˆè‹¥ä»åœ¨ç™»å½•é¡µåˆ™è‡ªåŠ¨å°è¯•ç™»å½•ä¸€æ¬¡ï¼‰
        try:
            flags = {}
            try:
                flags = (account.get("login_flags") or {}) if isinstance(account, dict) else {}
            except Exception:
                flags = {}
            use_enhanced = bool(flags.get("use_enhanced_login", True))
            if use_enhanced:
                # èµ°â€œğŸ¤– è‡ªåŠ¨ç™»å½•æµç¨‹ä¿®æ­£â€åŒæºå®ç°ï¼Œè·å–æ›´å¼ºçš„è‡ªé€‚åº”ä¸è¯¦å°½æ—¥å¿—
                try:
                    from modules.utils.enhanced_recording_wizard import EnhancedRecordingWizard
                    _wiz = EnhancedRecordingWizard()
                    _wiz._perform_enhanced_auto_login(page, account, "Shopee")
                except Exception as we:
                    logger.debug(f"å¢å¼ºç™»å½•å§”æ‰˜å¤±è´¥ï¼Œå›é€€ LoginService: {we}")
                    from modules.services.platform_login_service import LoginService as _LS
                    _LS().ensure_logged_in("shopee", page, account)
            else:
                from modules.services.platform_login_service import LoginService as _LS
                _LS().ensure_logged_in("shopee", page, account)
        except Exception as e:
            logger.debug(f"ç™»å½•çŠ¶æ€æ£€æŸ¥/è‡ªåŠ¨ç™»å½•è·³è¿‡: {e}")
        return ctx, page, platform, str(account_key)

    def _is_on_login_page(self, page) -> bool:
        """æ›´ä¸¥æ ¼åœ°åˆ¤æ–­æ˜¯å¦ä¸ºç™»å½•é¡µï¼Œé¿å…æŠŠé¦–é¡µè¯¯åˆ¤ä¸ºç™»å½•é¡µã€‚"""
        try:
            url = page.url or ''
            if 'account/signin' in url:
                return True

            def _visible(selector: str) -> bool:
                try:
                    loc = page.locator(selector)
                    return loc.count() > 0 and loc.first.is_visible()
                except Exception:
                    return False

            has_user = _visible('input[name="loginKey"], input[name="username"], input[placeholder*="é‚®ç®±"], input[placeholder*="æ‰‹æœº"]')
            has_pass = _visible('input[type="password"], input[name="password"]')
            has_submit = _visible('button:has-text("ç™»å½•"), button:has-text("ç™»å…¥")')

            # éœ€è¦åŒæ—¶å‘½ä¸­è´¦å·ä¸å¯†ç è¾“å…¥æ¡†ï¼›æäº¤æŒ‰é’®å¯é€‰
            if has_user and has_pass:
                return True
        except Exception:
            pass
        return False

    def _ensure_shopee_logged_in(self, page, account: Dict) -> None:
        """è‹¥æ£€æµ‹åˆ°ç™»å½•é¡µï¼Œå°è¯•ä½¿ç”¨è´¦æˆ·ä¿¡æ¯è‡ªåŠ¨ç™»å½•ä¸€æ¬¡ï¼Œå¹¶åœ¨éœ€è¦æ—¶è¿›å…¥éªŒè¯ç æµç¨‹ã€‚"""
        try:
            if not self._is_on_login_page(page):
                return

            username = account.get('Username') or account.get('username') or account.get('email')
            password = account.get('Password') or account.get('password')
            if not username or not password:
                logger.warning('æ£€æµ‹åˆ°æœªç™»å½•ï¼Œä½†è´¦å·æœªæä¾›ç”¨æˆ·å/å¯†ç ï¼Œæ— æ³•è‡ªåŠ¨ç™»å½•')
                return

            logger.info('ğŸ” æ£€æµ‹åˆ°ç™»å½•é¡µï¼Œå°è¯•è‡ªåŠ¨ç™»å½•â€¦')
            # å¡«å†™ç”¨æˆ·å
            for sel in ['input[name="loginKey"]', 'input[name="username"]', 'input[placeholder*="é‚®ç®±"]', 'input[placeholder*="æ‰‹æœº"]', 'input[type="text"]']:
                try:
                    el = page.locator(sel)
                    if el.count() > 0 and el.first.is_visible():
                        el.first.fill(username)
                        break
                except Exception:
                    continue
            # å¡«å†™å¯†ç 
            for sel in ['input[type="password"]', 'input[name="password"]']:
                try:
                    el = page.locator(sel)
                    if el.count() > 0 and el.first.is_visible():
                        el.first.fill(password)
                        break
                except Exception:
                    continue
            # å‹¾é€‰â€œè®°ä½æˆ‘â€å¤é€‰æ¡†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰â€”å¼ºåŒ–ç‰ˆï¼šå¤šç­–ç•¥ç‚¹å‡» + çŠ¶æ€æ ¡éªŒ
            try:
                def _is_checked() -> bool:
                    try:
                        box = page.locator('input[type="checkbox"]').first
                        if box.count() > 0:
                            try:
                                return box.is_checked()
                            except Exception:
                                val = box.get_attribute('value') or ''
                                return val.strip().lower() in ['true', '1', 'on']
                    except Exception:
                        return False
                    return False

                if not _is_checked():
                    tried = False
                    for csel in [
                        'input.eds-checkbox__input[type="checkbox"]',
                        'label:has-text("è®°ä½æˆ‘") input[type="checkbox"]',
                        'input[type="checkbox"]',
                    ]:
                        try:
                            loc = page.locator(csel).first
                            if loc.count() > 0 and loc.is_visible():
                                try:
                                    loc.check(force=True)  # type: ignore[attr-defined]
                                except Exception:
                                    loc.click(force=True)
                                tried = True
                                logger.info('âœ… å·²å°è¯•ç›´æ¥å‹¾é€‰â€œè®°ä½æˆ‘â€å¤é€‰æ¡†')
                                break
                        except Exception:
                            continue

                    if not _is_checked():
                        try:
                            lab = page.get_by_text('è®°ä½æˆ‘')  # type: ignore[attr-defined]
                            if lab and lab.count() > 0:
                                lab.first.click(force=True)
                                tried = True
                                logger.info('âœ… é€šè¿‡æ–‡æœ¬ç‚¹å‡»è§¦å‘â€œè®°ä½æˆ‘â€')
                        except Exception:
                            pass

                    if not _is_checked():
                        try:
                            frm = page.locator('form').first
                            if frm and frm.count() > 0:
                                try:
                                    frm.get_by_role('img').first.click()  # type: ignore[attr-defined]
                                    tried = True
                                except Exception:
                                    try:
                                        frm.locator('span').first.click()
                                        tried = True
                                    except Exception:
                                        pass
                        except Exception:
                            pass

                    if _is_checked():
                        logger.success('âœ… â€œè®°ä½æˆ‘â€å·²å¤„äºå‹¾é€‰çŠ¶æ€')
                    else:
                        if tried:
                            logger.warning('âš ï¸ å·²å°è¯•ç‚¹å‡»â€œè®°ä½æˆ‘â€ï¼Œä½†çŠ¶æ€æœªæ”¹å˜ï¼Œç»§ç»­ç™»å½•ï¼ˆä¸é˜»å¡ï¼‰')
                        else:
                            logger.debug('â„¹ï¸ æœªæ‰¾åˆ°â€œè®°ä½æˆ‘â€å…ƒç´ ï¼Œè·³è¿‡å‹¾é€‰æ­¥éª¤')
                else:
                    logger.info('â„¹ï¸ â€œè®°ä½æˆ‘â€å·²æ˜¯å‹¾é€‰çŠ¶æ€')
            except Exception:
                logger.debug('å‹¾é€‰â€œè®°ä½æˆ‘â€è¿‡ç¨‹å¿½ç•¥å¼‚å¸¸')

            # ç‚¹å‡»ç™»å½•
            for sel in ['button:has-text("ç™»å½•")', 'button:has-text("ç™»å…¥")', '.ant-btn-primary', '.btn-primary']:
                try:
                    btn = page.locator(sel)
                    if btn.count() > 0 and btn.first.is_visible():
                        btn.first.click()
                        break
                except Exception:
                    continue

            # ç­‰å¾…è·³è½¬æˆ–cookieç”Ÿæ•ˆ
            page.wait_for_timeout(2500)

            # è‹¥ä»åœ¨ç™»å½•é¡µï¼Œè¿›ä¸€æ­¥æ£€æµ‹æ˜¯å¦å‡ºç°éªŒè¯ç å¼¹çª—å¹¶å°è¯•è‡ªåŠ¨å¤„ç†
            if self._is_on_login_page(page):
                def _has_verification_modal_anywhere() -> bool:
                    selectors = [
                        '.phone-verify-container',
                        '[data-testid*="verify"]',
                        '[data-testid*="verification"]',
                        'div:has-text("éªŒè¯æ‰‹æœºå·")',
                        'div:has-text("éªŒè¯ç”µè¯å·ç ")',
                        'div:has-text("æ‰‹æœºéªŒè¯")',
                        'div:has-text("å‘é€è‡³é‚®ç®±")',
                        'div:has-text("å‘é€è‡³ç”µè¯")',
                        'div:has-text("å‘é€è‡³æ‰‹æœº")',
                        'div:has-text("è¾“å…¥éªŒè¯ç ")',
                        'div:has-text("Verification")',
                        'div:has-text("OTP")',
                        'button:has-text("å‘é€è‡³ç”µè¯")',
                        'button:has-text("å‘é€è‡³æ‰‹æœº")',
                        'button:has-text("æ‰‹æœºéªŒè¯")',
                        'input[placeholder*="éªŒè¯ç "]',
                    ]
                    try:
                        # å½“å‰é¡µé¢
                        for _sel in selectors:
                            try:
                                loc = page.locator(_sel)
                                if loc.count() > 0 and loc.first.is_visible():
                                    return True
                            except Exception:
                                continue
                        # æ‰€æœ‰frame
                        for fr in page.frames:
                            for _sel in selectors:
                                try:
                                    loc = fr.locator(_sel)
                                    if loc.count() > 0 and loc.first.is_visible():
                                        return True
                                except Exception:
                                    continue
                    except Exception:
                        pass
                    return False

                try:
                    # ä½¿ç”¨æ›´ç¨³å¥çš„æ™ºèƒ½éªŒè¯ç å¤„ç†å™¨V2ï¼ˆè¦†ç›–â€œéªŒè¯ç”µè¯å·ç â€é¡µé¢ç­‰åœºæ™¯ï¼‰
                    from modules.utils.smart_verification_handler_v2 import SmartVerificationHandlerV2

                    if _has_verification_modal_anywhere():
                        logger.info('ğŸ” æ£€æµ‹åˆ°éªŒè¯ç å¼¹çª—ï¼Œå¯åŠ¨éªŒè¯ç å¤„ç†æµç¨‹â€¦')
                    else:
                        logger.info('ğŸ” æœªæ˜¾å¼æ£€æµ‹åˆ°éªŒè¯ç å¼¹çª—ï¼Œä½†ä»åœç•™åœ¨ç™»å½•é¡µï¼Œå°è¯•èµ°éªŒè¯ç å¤„ç†å…œåº•â€¦')

                    handler = SmartVerificationHandlerV2(page, account)
                    handled = handler.handle_verification()
                    page.wait_for_timeout(2000)

                    if not self._is_on_login_page(page):
                        logger.info('âœ… è‡ªåŠ¨ç™»å½•+éªŒè¯ç å¤„ç†å®Œæˆï¼ˆæ£€æµ‹é€šè¿‡ï¼‰')
                        return

                    if handled:
                        logger.warning('éªŒè¯ç æµç¨‹ç»“æŸï¼Œä½†ä»åœç•™åœ¨ç™»å½•é¡µï¼Œåç»­æ­¥éª¤å¯èƒ½éœ€è¦äººå·¥ç¡®è®¤')
                    else:
                        logger.warning('éªŒè¯ç å¤„ç†å¤±è´¥ï¼Œå¯èƒ½éœ€è¦äººå·¥ä»‹å…¥')
                except Exception as ve:
                    logger.warning(f'éªŒè¯ç å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {ve}')
            else:
                logger.info('âœ… è‡ªåŠ¨ç™»å½•å®Œæˆï¼ˆæ£€æµ‹é€šè¿‡ï¼‰')
        except Exception as e:
            logger.debug(f'_ensure_shopee_logged_in å¼‚å¸¸: {e}')

    def list_shops(self, account: Dict) -> List[Shop]:
        """å®æ—¶æ‹‰å–è´¦å·ä¸‹åº—é“ºåˆ—è¡¨ï¼ˆåœ¨é¡µé¢ä¸Šä¸‹æ–‡å‘èµ· fetchï¼‰ã€‚"""
        ctx, page, platform, account_id = self._open_account_page(account)
        # å¤šä¸ªåŒºåŸŸå°è¯•ï¼Œå¢åŠ é‡è¯•å’Œè¯¦ç»†æ—¥å¿—
        regions = ["sg", "br", "tw", "my", "th", "ph", "id", "mx", "cl", "co", "pl", "es"]
        shops: Dict[str, Shop] = {}
        successful_regions = []

        for region in regions:
            for retry in range(2):  # æ¯ä¸ªåŒºåŸŸé‡è¯•2æ¬¡
                try:
                    js = """
                    (async (region) => {
                      const u = new URL('/api/cnsc/selleraccount/get_merchant_shop_list/', location.origin);
                      u.searchParams.set('page_index','1');
                      u.searchParams.set('page_size','50');
                      u.searchParams.set('region', region);
                      u.searchParams.set('auth_codes','["access_my_product"]');
                      const resp = await fetch(u.toString(), { credentials: 'include' });
                      if (!resp.ok) return { error: `HTTP ${resp.status}` };
                      return await resp.json();
                    })
                    """
                    data = page.evaluate(js, region)

                    if not data:
                        logger.debug(f"åŒºåŸŸ {region} è¿”å›ç©ºæ•°æ® (é‡è¯• {retry+1}/2)")
                        continue

                    if isinstance(data, dict) and data.get("error"):
                        logger.debug(f"åŒºåŸŸ {region} APIé”™è¯¯: {data.get('error')} (é‡è¯• {retry+1}/2)")
                        continue

                    if isinstance(data, dict) and data.get("code") not in (0, 200):
                        logger.debug(f"åŒºåŸŸ {region} è¿”å›é”™è¯¯ç : {data.get('code')} (é‡è¯• {retry+1}/2)")
                        continue

                    items = (
                        data.get("data", {}).get("shops")
                        or data.get("data", {}).get("list")
                        or data.get("data", {}).get("items")
                        or []
                    )

                    region_shops = 0
                    for it in items:
                        shop_id = str(it.get("shop_id") or it.get("cnsc_shop_id") or it.get("id") or "")
                        name = it.get("shop_name") or it.get("name") or it.get("label") or shop_id
                        if shop_id and shop_id not in shops:
                            shops[shop_id] = Shop(id=shop_id, name=name, region=region)
                            region_shops += 1

                    if region_shops > 0:
                        logger.debug(f"åŒºåŸŸ {region} å‘ç° {region_shops} ä¸ªåº—é“º")
                        successful_regions.append(region)
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯

                except Exception as e:
                    logger.debug(f"æ‹‰å–åŒºåŸŸ {region} åº—é“ºå¤±è´¥ (é‡è¯• {retry+1}/2): {e}")
                    if retry == 1:  # æœ€åä¸€æ¬¡é‡è¯•ä¹Ÿå¤±è´¥
                        continue

        logger.info(f"å…±å‘ç°åº—é“º {len(shops)} ä¸ªï¼ŒæˆåŠŸåŒºåŸŸ: {successful_regions}")
        return list(shops.values())

    def export_traffic_overview(
        self,
        account: Dict,
        shop: Shop,
        start_date: str,
        end_date: str,
        *,
        account_label: str,
        output_root: Path,
        enable_diagnostics: bool = False,
        enable_compare_diagnostics: bool = False,
        enable_recording_mode: bool = False,
    ) -> Tuple[bool, str, Optional[Path]]:
        """å¯¼å‡ºShopeeæµé‡è¡¨ç°æ•°æ®

        Args:
            account: è´¦å·ä¿¡æ¯
            shop: åº—é“ºä¿¡æ¯
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            account_label: è´¦å·æ ‡ç­¾
            output_root: è¾“å‡ºæ ¹ç›®å½•
            enable_diagnostics: å¯ç”¨è¯Šæ–­æ¨¡å¼
            enable_compare_diagnostics: å¯ç”¨å¯¹æ¯”è¯Šæ–­
            enable_recording_mode: å¯ç”¨å½•åˆ¶æ¨¡å¼

        Returns:
            (æˆåŠŸæ ‡å¿—, æ¶ˆæ¯, æ–‡ä»¶è·¯å¾„)
        """
        ctx, page, platform, account_id = self._open_account_page(account)

        # ç»Ÿä¸€ç›®å½• + æ–‡ä»¶å
        # ç»Ÿä¸€ç²’åº¦è§„åˆ™ï¼šæ ¹æ®èµ·æ­¢æ—¥æœŸè®¡ç®— daily/weekly/monthly
        gran = self._calculate_granularity(start_date, end_date)
        data_type = "traffic"
        include_shop_id = get_config_value('data_collection', 'path_options.include_shop_id', False)
        out_dir = build_output_path(
            root=output_root,
            platform=platform,
            account_label=account_label,
            shop_name=shop.name,
            data_type=data_type,
            granularity=gran,
            shop_id=getattr(shop, 'id', None),
            include_shop_id=include_shop_id,
        )
        out_dir.mkdir(parents=True, exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = build_filename(
            ts=ts,
            account_label=account_label,
            shop_name=shop.name,
            data_type=data_type,
            granularity=gran,
            start_date=start_date,
            end_date=end_date,
            suffix=".xlsx",
        )
        target_path = out_dir / filename

        # è¯Šæ–­ç›®å½•
        diag_dir = out_dir / ".diag"
        if enable_diagnostics or enable_compare_diagnostics or enable_recording_mode:
            diag_dir.mkdir(exist_ok=True)

        try:
            # å¯¼èˆªåˆ°æµé‡è¡¨ç°é¡µé¢
            traffic_url = f"https://seller.shopee.cn/datacenter/traffic/overview?cnsc_shop_id={shop.id}"
            logger.info(f"å¯¼èˆªåˆ°æµé‡è¡¨ç°é¡µé¢: {traffic_url}")
            page.goto(traffic_url, wait_until="domcontentloaded", timeout=60000)

            # æ£€æŸ¥å¹¶å…³é—­å¯èƒ½çš„é€šçŸ¥å¼¹çª—
            self._close_notification_modal(page)

            # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
            page.wait_for_timeout(2000)

            # æ ¹æ®æ—¶é—´èŒƒå›´é€‰æ‹©åˆé€‚çš„é€‰é¡¹
            time_option = self._determine_traffic_time_option(start_date, end_date)
            logger.info(f"ğŸ¯ æµé‡è¡¨ç°æ—¶é—´é€‰æ‹©: {time_option}")

            # æ‰§è¡Œæ—¶é—´é€‰æ‹©ï¼ˆå¦‚éœ€è¦ï¼‰å¹¶è¿›è¡Œæ ¡éªŒ
            if time_option != "æ˜¨å¤©":
                if not self._execute_traffic_time_selection(page, time_option, diag_dir, enable_recording_mode):
                    return False, f"æ—¶é—´é€‰æ‹©å¤±è´¥: {time_option}", None
                page.wait_for_timeout(800)
                if not self._verify_traffic_time_selection(page, start_date, end_date, time_option):
                    logger.info("â³ æ—¶é—´æœªç”Ÿæ•ˆï¼Œé‡è¯•ä¸€æ¬¡æ—¶é—´é€‰æ‹©â€¦")
                    if not self._execute_traffic_time_selection(page, time_option, diag_dir, enable_recording_mode):
                        return False, f"æ—¶é—´é€‰æ‹©å¤±è´¥(é‡è¯•): {time_option}", None
                    page.wait_for_timeout(800)
                    if not self._verify_traffic_time_selection(page, start_date, end_date, time_option):
                        return False, "æ—¶é—´é€‰æ‹©æœªç”Ÿæ•ˆï¼Œè¯·æ£€æŸ¥é¡µé¢æˆ–ç¨åé‡è¯•", None
            else:
                logger.info("âœ… é¡µé¢é»˜è®¤ä¸º'æ˜¨å¤©'ï¼Œè·³è¿‡æ—¶é—´é€‰æ‹©æ“ä½œ")

            # ç­‰å¾…æ•°æ®åŠ è½½
            page.wait_for_timeout(1500)

            # ç›´æ¥å›´ç»•â€œå¯¼å‡ºæ•°æ®â€åŠ¨ä½œæ•è·ä¸‹è½½äº‹ä»¶ï¼ˆæµé‡è¡¨ç°ï¼šç‚¹å‡»å³ä¸‹è½½ï¼‰
            with page.expect_download(timeout=120000) as dl_info:
                success, message = self._execute_traffic_export(page, diag_dir, enable_recording_mode)
                if not success:
                    return False, f"å¯¼å‡ºæ“ä½œå¤±è´¥: {message}", None
            download = dl_info.value
            suggested = target_path.parent / download.suggested_filename
            download.save_as(str(suggested))
            if suggested != target_path:
                try:
                    suggested.rename(target_path)
                except Exception:
                    import shutil
                    shutil.move(str(suggested), str(target_path))
            download_path = target_path

            logger.info(f"âœ… æµé‡è¡¨ç°æ•°æ®å¯¼å‡ºæˆåŠŸ: {download_path}")
            return True, f"å¯¼å‡ºæˆåŠŸï¼Œæ–‡ä»¶ä¿å­˜è‡³: {download_path}", download_path

        except Exception as e:
            logger.error(f"æµé‡è¡¨ç°å¯¼å‡ºå¼‚å¸¸: {e}")
            return False, f"å¯¼å‡ºå¼‚å¸¸: {e}", None
        finally:
            # ä¸Šä¸‹æ–‡ç”±æ‰¹é‡ç¼–æ’å™¨åœ¨è´¦å·çº§ç»Ÿä¸€å…³é—­ï¼›æ­¤å¤„ä¸å†å…³é—­ä»¥ä¾¿åŒè´¦å·åç»­æ•°æ®åŸŸå¤ç”¨
            pass

    def _determine_traffic_time_option(self, start_date: str, end_date: str) -> str:
        """æ ¹æ®æ—¥æœŸèŒƒå›´ç¡®å®šæµé‡è¡¨ç°çš„æ—¶é—´é€‰é¡¹

        æµé‡è¡¨ç°é¡µé¢åªæœ‰3ä¸ªé€‰é¡¹ï¼šæ˜¨å¤©ã€è¿‡å»7å¤©ã€è¿‡å»30å¤©
        """
        try:
            start = datetime.strptime(start_date, "%Y-%m-%d")
            end = datetime.strptime(end_date, "%Y-%m-%d")
            today = datetime.now().date()
            yesterday = today - timedelta(days=1)

            # å¦‚æœæ˜¯æ˜¨å¤©
            if start.date() == yesterday and end.date() == yesterday:
                return "æ˜¨å¤©"

            # å¦‚æœæ˜¯è¿‡å»7å¤©èŒƒå›´
            week_start = today - timedelta(days=7)
            if abs((start.date() - week_start).days) <= 1 and abs((end.date() - yesterday).days) <= 1:
                return "è¿‡å»7å¤©"

            # å¦‚æœæ˜¯è¿‡å»30å¤©èŒƒå›´
            month_start = today - timedelta(days=30)
            if abs((start.date() - month_start).days) <= 1 and abs((end.date() - yesterday).days) <= 1:
                return "è¿‡å»30å¤©"

            # é»˜è®¤ä½¿ç”¨æ˜¨å¤©
            logger.warning(f"æ—¥æœŸèŒƒå›´ {start_date}~{end_date} ä¸åŒ¹é…æ ‡å‡†é€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤'æ˜¨å¤©'")
            return "æ˜¨å¤©"

        except Exception as e:
            logger.error(f"æ—¥æœŸè§£æå¤±è´¥: {e}")
            return "æ˜¨å¤©"

    def _execute_traffic_time_selection(self, page, time_option: str, diag_dir: Path, enable_recording_mode: bool) -> bool:
        """æ‰§è¡Œæµé‡è¡¨ç°é¡µé¢çš„æ—¶é—´é€‰æ‹©"""
        try:
            logger.info(f"ğŸ¬ å¼€å§‹æµé‡è¡¨ç°æ—¶é—´é€‰æ‹©ï¼Œç›®æ ‡é€‰é¡¹: {time_option}")

            # ä½¿ç”¨é…æ–¹æ‰§è¡Œå™¨
            from modules.services.recipe_executor import RecipeExecutor
            executor = RecipeExecutor()

            # æ‰§è¡Œæ—¶é—´é€‰æ‹©é…æ–¹
            success = executor.execute_traffic_date_recipe(page, time_option)
            if success:
                logger.info(f"âœ… æ—¶é—´é€‰æ‹©æˆåŠŸ: {time_option}")
                return True
            else:
                logger.error(f"âŒ æ—¶é—´é€‰æ‹©å¤±è´¥: {time_option}")
                return False

        except Exception as e:
            logger.error(f"æ—¶é—´é€‰æ‹©å¼‚å¸¸: {e}")
            return False

    def _verify_traffic_time_selection(self, page, start_date: str, end_date: str, time_option: str) -> bool:
        """æ ¡éªŒæµé‡è¡¨ç°é¡µé¢çš„æ—¶é—´æ˜¯å¦å·²æŒ‰é¢„æœŸç”Ÿæ•ˆã€‚

        ä¼˜å…ˆä»UIè¯»å–æ¯«ç§’æ—¶é—´æˆ³å¹¶ä¸æœŸæœ›çš„ start/end æ¯”è¾ƒï¼›å¤±è´¥åˆ™å›é€€åˆ°æ–‡æœ¬å…³é”®å­—åˆ¤æ–­ã€‚
        """
        try:
            # ä¼˜å…ˆï¼šè§£æ UI æ—¶é—´èŒƒå›´ï¼ˆæ¯«ç§’ï¼Œå³å¼€åŒºé—´ï¼‰
            try:
                start_ms, end_ms = self._read_week_from_ui(page)
            except Exception:
                start_ms, end_ms = None, None
            if start_ms and end_ms:
                from datetime import datetime as dt, timezone, timedelta
                tz = timezone(timedelta(hours=8))  # ç»Ÿä¸€åˆ° +08 ä»…ç”¨äºæ—¥æœŸæ¯”è¾ƒ
                s = dt.fromtimestamp(start_ms / 1000, tz).date().isoformat()
                e = (dt.fromtimestamp(end_ms / 1000, tz) - timedelta(days=1)).date().isoformat()
                if s == start_date and e == end_date:
                    logger.info("âœ… æ—¶é—´èŒƒå›´æ ¡éªŒé€šè¿‡(UI)")
                    return True

            # å›é€€ï¼šåŸºäºæ—¶é—´æ˜¾ç¤ºæ–‡æœ¬åšå…³é”®å­—æ ¡éªŒ
            info = (self._read_time_display(page) or {})
            val = (info.get("value") or info.get("text") or "").strip()
            if time_option == "æ˜¨å¤©" and ("æ˜¨å¤©" in val or "Yesterday" in val):
                logger.info("âœ… æ—¶é—´èŒƒå›´æ ¡éªŒé€šè¿‡(æ–‡æœ¬=æ˜¨å¤©)")
                return True
            if "7" in time_option and any(k in val for k in ["è¿‡å»7", "è¿‘7", "Last 7", "7å¤©", "7 Days", "7D"]):
                logger.info("âœ… æ—¶é—´èŒƒå›´æ ¡éªŒé€šè¿‡(æ–‡æœ¬=è¿‡å»7å¤©)")
                return True
            if "30" in time_option and any(k in val for k in ["è¿‡å»30", "è¿‘30", "Last 30", "30å¤©", "30 Days", "30D"]):
                logger.info("âœ… æ—¶é—´èŒƒå›´æ ¡éªŒé€šè¿‡(æ–‡æœ¬=è¿‡å»30å¤©)")
                return True

            logger.warning(f"æ—¶é—´èŒƒå›´æ ¡éªŒæœªé€šè¿‡ï¼Œæ˜¾ç¤º='{val}'ï¼ŒæœŸæœ›={start_date}~{end_date}({time_option})")
            return False
        except Exception as e:
            logger.warning(f"æ—¶é—´èŒƒå›´æ ¡éªŒå¼‚å¸¸: {e}")
            return False

    def _execute_traffic_export(self, page, diag_dir: Path, enable_recording_mode: bool) -> Tuple[bool, str]:
        """æ‰§è¡Œæµé‡è¡¨ç°é¡µé¢çš„å¯¼å‡ºæ“ä½œ"""
        try:
            logger.info("ğŸ¬ å¼€å§‹æµé‡è¡¨ç°æ•°æ®å¯¼å‡º...")

            # æŸ¥æ‰¾å¯¼å‡ºæŒ‰é’®
            export_selectors = [
                'button:has-text("å¯¼å‡º")',
                'button:has-text("ä¸‹è½½")',
                '[data-testid*="export"]',
                '.export-btn',
                '.download-btn'
            ]

            export_clicked = False
            for selector in export_selectors:
                try:
                    element = page.locator(selector).first
                    if element.count() > 0 and element.is_visible():
                        logger.info(f"ğŸ¯ ç‚¹å‡»å¯¼å‡ºæŒ‰é’®: {selector}")
                        element.click()
                        export_clicked = True
                        break
                except Exception as e:
                    logger.debug(f"å¯¼å‡ºæŒ‰é’®å°è¯•å¤±è´¥ {selector}: {e}")
                    continue

            if not export_clicked:
                return False, "æœªæ‰¾åˆ°å¯ç”¨çš„å¯¼å‡ºæŒ‰é’®"

            # ç­‰å¾…å¯¼å‡ºå¤„ç†
            page.wait_for_timeout(2000)

            logger.info("âœ… å¯¼å‡ºæ“ä½œæ‰§è¡ŒæˆåŠŸ")
            return True, "å¯¼å‡ºæ“ä½œæˆåŠŸ"

        except Exception as e:
            logger.error(f"å¯¼å‡ºæ“ä½œå¼‚å¸¸: {e}")
            return False, f"å¯¼å‡ºå¼‚å¸¸: {e}"

    def export_products_weekly_pure(
        self,
        page,  # å·²ç»è®¾ç½®å¥½çš„pageå¯¹è±¡
        shop: Shop,
        start_date: str,
        end_date: str,
        *,
        account_label: str,
        output_root: Path,
        enable_diagnostics: bool = False,
        enable_compare_diagnostics: bool = False,
        enable_recording_mode: bool = False,
        enable_auto_regenerate: bool = True,  # çº¯å¯¼å‡ºé»˜è®¤å¯ç”¨è‡ªåŠ¨é‡ç”Ÿ
        enable_api_fallback: bool = False,    # APIå¤‡é€‰é»˜è®¤ç¦ç”¨ï¼ˆé¿å…timestamp errorï¼‰
        metrics: Optional[List[str]] = None,
    ) -> Tuple[bool, str, Optional[Path]]:
        """çº¯å¯¼å‡ºæ–¹æ³•ï¼šè·³è¿‡ç™»å½•/å¯¼èˆª/æ—¥æœŸè®¾ç½®ï¼Œç›´æ¥æ‰§è¡Œå¯¼å‡ºã€‚

        é€‚ç”¨äºç»„ä»¶åŒ–è·¯å¾„ï¼Œå‡è®¾pageå·²ç»åœ¨æ­£ç¡®çš„é¡µé¢ä¸”æ—¶é—´å·²è®¾ç½®ã€‚
        """
        # é»˜è®¤æŒ‡æ ‡åˆ—è¡¨
        if metrics is None:
            metrics = [
                "é”€é‡", "é”€å”®é¢", "å•†å“é¡µè®¿é—®é‡", "åŠ è´­é‡",
                "ç‚¹å‡»ç‡", "è½¬åŒ–ç‡", "è®¢å•ä¹°å®¶æ•°", "æ›å…‰é‡"
            ]

        # åŠ¨æ€è®¡ç®—ç²’åº¦
        gran = self._calculate_granularity(start_date, end_date)
        data_type = "products"
        include_shop_id = get_config_value('data_collection', 'path_options.include_shop_id', False)
        out_dir = build_output_path(
            root=output_root,
            platform="shopee",
            account_label=account_label,
            shop_name=shop.name,
            data_type=data_type,
            granularity=gran,
            shop_id=getattr(shop, 'id', None),
            include_shop_id=include_shop_id,
        )
        out_dir.mkdir(parents=True, exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = build_filename(
            ts=ts,
            account_label=account_label,
            shop_name=shop.name,
            data_type=data_type,
            granularity=gran,
            start_date=start_date,
            end_date=end_date,
            suffix=".xlsx",
        )
        target_path = out_dir / filename

        try:
            # è·³è¿‡ç™»å½•/å¯¼èˆª/æ—¥æœŸè®¾ç½®ï¼Œç›´æ¥æ‰§è¡Œå¯¼å‡ºæµç¨‹
            logger.info("ğŸ¯ çº¯å¯¼å‡ºæ¨¡å¼ï¼šè·³è¿‡ç™»å½•/å¯¼èˆª/æ—¥æœŸè®¾ç½®ï¼Œç›´æ¥å¯¼å‡º")

            # è¯Šæ–­ç›®å½•
            diag_dir = out_dir / ".diag"
            if enable_diagnostics or enable_compare_diagnostics or enable_recording_mode:
                diag_dir.mkdir(exist_ok=True)

            # æ£€æŸ¥å¹¶å…³é—­å¯èƒ½çš„é€šçŸ¥å¼¹çª—
            self._close_notification_modal(page)

            # å…ˆå°è¯•â€œé¡µé¢äº¤äº’å¼å¯¼å‡ºâ€ï¼ˆç‚¹å‡»é¡µé¢ä¸Šçš„å¯¼å‡º/ä¸‹è½½æŒ‰é’®å¹¶æ•è·ä¸‹è½½ï¼‰
            try:
                ok, ui_msg = self._export_via_ui(
                    page,
                    target_path,
                    diag_dir=diag_dir if (enable_diagnostics or enable_compare_diagnostics or enable_recording_mode) else None,
                    ts=ts,
                    capture_network=(enable_diagnostics or enable_compare_diagnostics or enable_recording_mode),
                    enable_auto_regenerate=enable_auto_regenerate,
                )
                if ok:
                    # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                    if target_path.exists() and target_path.stat().st_size > 0:
                        # å†™å…¥å¯¼å‡ºå…ƒæ•°æ®æ¸…å•ï¼ˆä¸ç»„ä»¶åŒ–å¯¼å‡ºä¿æŒä¸€è‡´ï¼‰
                        try:
                            from datetime import datetime as _dt
                            import json as _json
                            manifest = {
                                "platform": "shopee",
                                "account_label": account_label,
                                "shop_name": getattr(shop, 'name', None),
                                "shop_id": getattr(shop, 'id', None),
                                "region": getattr(shop, 'region', None),
                                "data_type": data_type,
                                "granularity": gran,
                                "start_date": start_date,
                                "end_date": end_date,
                                "exported_at": _dt.now().isoformat(),
                                "file_path": str(target_path),
                            }
                            manifest_path = Path(str(target_path) + ".json")
                            manifest_path.write_text(_json.dumps(manifest, ensure_ascii=False, indent=2), encoding="utf-8")
                        except Exception:
                            pass
                        return True, ui_msg, target_path
                    else:
                        logger.warning(f"âš ï¸ UIå¯¼å‡ºè¿”å›æˆåŠŸä½†æ–‡ä»¶ä¸å­˜åœ¨: {target_path}")
                        # ç»§ç»­å°è¯•APIæ–¹æ¡ˆ
            except Exception as e:
                logger.debug(f"UIå¯¼å‡ºæµç¨‹æœªæˆåŠŸï¼Œå›é€€åˆ°APIæ–¹æ¡ˆ: {e}")

            # APIå¤‡é€‰è·¯å¾„ï¼ˆå¯é…ç½®å¼€å…³ï¼Œé»˜è®¤ç¦ç”¨é¿å…timestamp errorï¼‰
            if not enable_api_fallback:
                logger.info("ğŸš« APIå¤‡é€‰å·²ç¦ç”¨ï¼Œå¯¼å‡ºå¤±è´¥")
                return False, "UIå¯¼å‡ºå¤±è´¥ä¸”APIå¤‡é€‰å·²ç¦ç”¨", None

            logger.info("ğŸ”„ å¯ç”¨APIå¤‡é€‰è·¯å¾„...")
            # åœ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡å†…å‘èµ· export â†’ è½®è¯¢ report â†’ ç”Ÿæˆä¸‹è½½é“¾æ¥
            export_url = f"{self.base}/api/mydata/cnsc/shop/v2/product/performance/export/"
            download_api = f"{self.base}/api/v3/settings/download_report/"

            # æŒ‡æ ‡å‹¾é€‰å·²ç¦ç”¨ï¼šå¯¼å‡ºè·å–å…¨é‡æ•°æ®
            logger.info("ğŸ“Š è·³è¿‡æŒ‡æ ‡å‹¾é€‰ï¼ˆå¯¼å‡ºè·å–å…¨é‡æ•°æ®ï¼‰")

            # ä¼˜å…ˆä½¿ç”¨UIè¯»å–åˆ°çš„ç§’çº§æ—¶é—´æˆ³ï¼›è‹¥UIä¸å¯ç”¨ï¼Œå›é€€åˆ°å…¥å‚è®¡ç®—ï¼ˆä¸¥æ ¼ +08:00ï¼Œå³å¼€åŒºé—´ï¼‰
            try:
                ui_start_ms, ui_end_ms = self._read_week_from_ui(page)
                start_ts = ui_start_ms // 1000 if ui_start_ms else None
                end_ts = ui_end_ms // 1000 if ui_end_ms else None
            except Exception:
                start_ts = None
                end_ts = None

            if not start_ts or not end_ts:
                # å›é€€ï¼šæ ¹æ®å…¥å‚è®¡ç®—æ—¶é—´æˆ³ï¼ˆ+08:00ï¼Œå³å¼€åŒºé—´ï¼‰
                try:
                    from datetime import datetime as dt, timedelta, timezone
                    tz = timezone(timedelta(hours=8))
                    sd = dt.strptime(start_date, "%Y-%m-%d").replace(tzinfo=tz)
                    ed = dt.strptime(end_date, "%Y-%m-%d").replace(tzinfo=tz)
                    start_ts = int(sd.timestamp())
                    end_ts = int((ed + timedelta(days=1)).timestamp())  # å³å¼€åŒºé—´
                    logger.info(f"æ—¶é—´æˆ³å›é€€è®¡ç®—: start_ts={start_ts}, end_ts={end_ts}")
                except Exception as te:
                    logger.error(f"æ—¶é—´æˆ³è®¡ç®—å¤±è´¥: {te}")
                    return False, f"æ—¶é—´æˆ³è®¡ç®—å¤±è´¥: {te}", None

            # å¯ç”¨ç½‘ç»œè¯·æ±‚ç›‘å¬ï¼ˆè¯Šæ–­æ¨¡å¼ï¼‰
            network_requests = []
            if enable_diagnostics:
                def handle_request(request):
                    if 'export' in request.url or 'download' in request.url:
                        network_requests.append({
                            "url": request.url,
                            "method": request.method,
                            "headers": dict(request.headers),
                            "post_data": request.post_data,
                        })
                try:
                    page.on("request", handle_request)
                except Exception:
                    pass

            # æ„é€ å¯¼å‡ºè„šæœ¬
            script_export = """
            async ({export_url, download_api, shop_id, start_ts, end_ts}) => {
              const p = new URL(export_url);
              p.searchParams.set('start_ts', String(start_ts));
              p.searchParams.set('end_ts', String(end_ts));
              p.searchParams.set('period', 'week');
              p.searchParams.set('sort_by', '');
              p.searchParams.set('cnsc_shop_id', shop_id);

              // å‘èµ·è¯·æ±‚
              const r = await fetch(p.toString(), { credentials:'include' });
              if (!r.ok) throw new Error('export http ' + r.status);
              const ct = (r.headers.get('content-type')||'').toLowerCase();
              const cd = r.headers.get('content-disposition') || '';
              const filename = (cd.match(/filename\*=UTF-8''([^;]+)|filename="?([^";]+)"?/i) || []).slice(1).find(Boolean) || '';

              // åˆ†æ”¯1ï¼šJSONæµç¨‹ï¼ˆè¿”å› report_idï¼Œéœ€è½®è¯¢ï¼‰
              if (ct.includes('application/json')) {
                const j = await r.json();
                if (!(j && (j.code===0 || j.code===200))) throw new Error('export code ' + JSON.stringify(j));
                const report_id = j?.data?.report_id;
                if (!report_id) throw new Error('no report_id');
                // è½®è¯¢æŸ¥è¯¢çŠ¶æ€
                const wait = (ms)=>new Promise(res=>setTimeout(res,ms));
                for (let i=0;i<30;i++) {
                  const d = new URL(download_api);
                  d.searchParams.set('report_id', String(report_id));
                  d.searchParams.set('cnsc_shop_id', shop_id);
                  const dr = await fetch(d.toString(), { credentials:'include' });
                  if (dr.ok) {
                    const dj = await dr.json();
                    if (dj && (dj.code===0 || dj.code===200)) {
                      const info = dj.data || {};
                      if (info.status === 2 && info.download_link) {
                        return { mode: 'report', report_id, download_link: info.download_link };
                      }
                      if (info.status === 3) throw new Error('report failed');
                    }
                  }
                  await wait(5000);
                }
                throw new Error('report timeout');
              }

              // åˆ†æ”¯2ï¼šéJSONï¼ˆå¯èƒ½ç›´æ¥è¿”å›Excel/CSVç­‰ï¼‰ï¼Œæ”¹ç”¨ç›´æ¥ä¸‹è½½æ¨¡å¼
              if (ct.includes('application/octet-stream') || ct.includes('application/vnd') || ct.includes('excel') || cd.toLowerCase().includes('attachment')) {
                return { mode: 'direct', direct_url: p.toString(), content_type: ct, filename };
              }

              // å…¶ä»–æœªçŸ¥ç±»å‹ï¼Œè¿”å›æ–‡æœ¬è¯Šæ–­å¹¶èµ° direct_url å…œåº•
              const text = await r.text().catch(()=>'' );
              return { mode: 'unknown', direct_url: p.toString(), content_type: ct, filename, preview: (text||'').slice(0,200) };
            }
            """

            # å°è¯•å¯¼å‡ºï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨é‡è¯•ä¸€æ¬¡ï¼ˆè°ƒæ•´æ—¶é—´æˆ³æ ¼å¼ï¼‰
            export_attempts = []

            try:
                params = {
                    "export_url": export_url,
                    "download_api": download_api,
                    "shop_id": shop.id,
                    "start_ts": start_ts,
                    "end_ts": end_ts,
                }
                export_attempts.append({"attempt": 1, "params": params.copy()})

                result = page.evaluate(script_export, params)
                mode = result.get("mode")
                if mode == 'report':
                    download_link = result.get("download_link")
                    logger.info(f"æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œå‡†å¤‡ä¸‹è½½: {download_link}")
                else:
                    download_link = None
                    logger.info(f"å¯¼å‡ºè¿”å›éJSONï¼ˆ{result.get('content_type')}ï¼‰ï¼Œå°†å°è¯•ç›´æ¥ä¸‹è½½æ¨¡å¼")
            except Exception as e:
                # å¦‚æœèµ°éJSONåˆ†æ”¯ï¼ˆç›´æ¥ä¸‹è½½ï¼‰ï¼Œè®°å½•å°è¯•å‚æ•°å¤´ä¿¡æ¯ï¼ˆä»…ç¬¬ä¸€è½®ï¼‰
                try:
                    export_attempts[-1]["result_head"] = {k: result.get(k) for k in ["mode","content_type","filename","preview"] if k in result}
                except Exception:
                    pass

                logger.warning(f"ç¬¬ä¸€æ¬¡å¯¼å‡ºå¤±è´¥: {e}")

                # è‡ªåŠ¨é‡è¯•ï¼šå°è¯•æ¯«ç§’æ—¶é—´æˆ³
                try:
                    logger.info("è‡ªåŠ¨é‡è¯•ï¼šæ—¶é—´æˆ³å®¹é”™å›é€€...")
                    start_ts_fallback = start_ts * 1000
                    end_ts_fallback = end_ts * 1000

                    retry_params = {
                        "export_url": export_url,
                        "download_api": download_api,
                        "shop_id": shop.id,
                        "start_ts": start_ts_fallback,
                        "end_ts": end_ts_fallback,
                    }
                    export_attempts.append({"attempt": 2, "params": retry_params.copy(), "retry_reason": str(e)})

                    result = page.evaluate(script_export, retry_params)
                    mode = result.get("mode")
                    if mode == 'report':
                        download_link = result.get("download_link")
                        logger.info(f"é‡è¯•æˆåŠŸï¼ŒæŠ¥å‘Šç”Ÿæˆï¼Œå‡†å¤‡ä¸‹è½½: {download_link}")
                    else:
                        download_link = None
                        logger.info(f"é‡è¯•è¿”å›éJSONï¼ˆ{result.get('content_type')}ï¼‰ï¼Œå°†å°è¯•ç›´æ¥ä¸‹è½½æ¨¡å¼")
                except Exception as retry_e:
                    logger.error(f"é‡è¯•ä¹Ÿå¤±è´¥: {retry_e}")
                    # ä¿å­˜å¯¼å‡ºå°è¯•è®°å½•ç”¨äºè¯Šæ–­
                    if enable_diagnostics or enable_compare_diagnostics:
                        attempts_file = diag_dir / f"{ts}_export_attempts.json"
                        attempts_file.write_text(
                            json.dumps(export_attempts, ensure_ascii=False, indent=2),
                            encoding="utf-8"
                        )
                    return False, f"å¯¼å‡ºå¤±è´¥ï¼ˆå·²é‡è¯•ï¼‰: {retry_e}", None

            # ä¸‹è½½é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨ download_linkï¼›å¦åˆ™å°è¯•ç›´æ¥ä¸‹è½½æ¨¡å¼
            try:
                if download_link:
                    # æ­£å¸¸æŠ¥å‘Šä¸‹è½½
                    with page.expect_download(timeout=120000) as dl_info:
                        page.evaluate(
                            "(url)=>{ const a=document.createElement('a'); a.href=url; a.download=''; document.body.appendChild(a); a.click(); }",
                            download_link,
                        )
                    download = dl_info.value
                    download.save_as(str(target_path))
                else:
                    # ç›´æ¥ä¸‹è½½æ¨¡å¼ï¼šåœ¨é¡µé¢ä¸Šä¸‹æ–‡è§¦å‘ fetch(blob) å¹¶è§¦å‘ä¸‹è½½
                    with page.expect_download(timeout=120000) as dl_info:
                        page.evaluate(
                            "(url)=>{ fetch(url, {credentials:'include'}).then(r=>r.blob()).then(b=>{ const blobUrl=URL.createObjectURL(b); const a=document.createElement('a'); a.href=blobUrl; a.download='export.xlsx'; document.body.appendChild(a); a.click(); setTimeout(()=>URL.revokeObjectURL(blobUrl), 5000); }); }",
                            result.get("direct_url") or result.get("download_link") or export_url,
                        )
                    download = dl_info.value
                    download.save_as(str(target_path))

                size = target_path.stat().st_size if target_path.exists() else 0
                meta = {
                    "platform": "shopee",
                    "account": account_label,
                    "shop_name": shop.name,
                    "shop_id": shop.id,
                    "data_type": data_type,
                    "granularity": gran,
                    "start_date": start_date,
                    "end_date": end_date,
                    "created_at": ts,
                    "report_id": result.get("report_id"),
                    "download_link": download_link or result.get("direct_url"),
                    "file_path": str(target_path),
                    "file_size": size,
                    "mode": result.get("mode"),
                    "content_type": result.get("content_type"),
                }
                try:
                    (out_dir / f"{ts}_meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")
                except Exception:
                    pass
                # ç»Ÿä¸€ï¼šåœ¨ç›®æ ‡æ–‡ä»¶æ—å†™å…¥æ ‡å‡†åŒ– manifestï¼ˆä¸æ‰¹é‡/ç»„ä»¶åŒ–ä¸€è‡´ï¼‰
                try:
                    from datetime import datetime as _dt
                    import json as _json
                    adj_manifest = {
                        "platform": "shopee",
                        "account_label": account_label,
                        "shop_name": getattr(shop, 'name', None),
                        "shop_id": getattr(shop, 'id', None),
                        "region": getattr(shop, 'region', None),
                        "data_type": data_type,
                        "granularity": gran,
                        "start_date": start_date,
                        "end_date": end_date,
                        "exported_at": _dt.now().isoformat(),
                        "file_path": str(target_path),
                    }
                    (Path(str(target_path) + ".json")).write_text(_json.dumps(adj_manifest, ensure_ascii=False, indent=2), encoding="utf-8")
                except Exception:
                    pass


                logger.success(f"ä¸‹è½½å®Œæˆ: {target_path} ({size:,} bytes)")
                return True, "ä¸‹è½½å®Œæˆ", target_path
            except Exception as e:
                logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
                return False, f"ä¸‹è½½å¤±è´¥: {e}", None

        except Exception as e:
            logger.error(f"çº¯å¯¼å‡ºå¼‚å¸¸: {e}")
            return False, f"çº¯å¯¼å‡ºå¼‚å¸¸: {e}", None

    def _prepare_export_context(
        self,
        account: Dict,
        shop: Shop,
        start_date: str,
        end_date: str,
        download_path: str = None,
    ) -> Tuple[bool, str, Optional[object], Optional[object]]:
        """å‡†å¤‡å¯¼å‡ºä¸Šä¸‹æ–‡ï¼šç™»å½• â†’ å¯¼èˆª â†’ æ—¥æœŸè®¾ç½®ã€‚

        Args:
            download_path: å¯é€‰çš„ä¸‹è½½ç›®å½•è·¯å¾„

        Returns:
            (success, message, page_or_none, ctx_or_none)
        """
        try:
            # æ‰“å¼€è´¦å·é¡µé¢ï¼ˆè®¾ç½®ä¸‹è½½ç›®å½•ï¼‰
            ctx, page, platform, account_id = self._open_account_page(account, download_path)

            # å¯¼èˆªåˆ°å•†å“è¡¨ç°é¡µé¢
            self._navigate_to_product_performance(page, shop)

            # è®¾ç½®æ—¶é—´èŒƒå›´
            self._set_date_range(page, start_date, end_date)

            return True, "å‡†å¤‡å®Œæˆ", page, ctx

        except Exception as e:
            logger.error(f"å‡†å¤‡å¯¼å‡ºä¸Šä¸‹æ–‡å¼‚å¸¸: {e}")
            return False, f"å‡†å¤‡å¯¼å‡ºä¸Šä¸‹æ–‡å¼‚å¸¸: {e}", None, None

    def export_products_weekly(
        self,
        account: Dict,
        shop: Shop,
        start_date: str,
        end_date: str,
        *,
        account_label: str,
        output_root: Path,
        enable_diagnostics: bool = False,
        enable_compare_diagnostics: bool = False,
        enable_recording_mode: bool = False,
        enable_auto_regenerate: bool = False,
        enable_api_fallback: bool = False,    # APIå¤‡é€‰é»˜è®¤ç¦ç”¨
        metrics: Optional[List[str]] = None,
    ) -> Tuple[bool, str, Optional[Path]]:
        """åœ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡å†…æ‰§è¡Œå¯¼å‡ºå¹¶ç­‰å¾…ä¸‹è½½ã€‚

        Args:
            metrics: è¦å‹¾é€‰çš„æŒ‡æ ‡åˆ—è¡¨ï¼Œå¦‚ ["é”€é‡", "é”€å”®é¢", "å•†å“é¡µè®¿é—®é‡", "åŠ è´­é‡"]
                    å¦‚æœä¸ºNoneï¼Œå°†ä½¿ç”¨é»˜è®¤æŒ‡æ ‡åˆ—è¡¨
        """
        # é»˜è®¤æŒ‡æ ‡åˆ—è¡¨ï¼ˆåŸºäºä½ æˆªå›¾ä¸­çœ‹åˆ°çš„æŒ‡æ ‡ï¼‰
        if metrics is None:
            metrics = [
                "é”€é‡", "é”€å”®é¢", "å•†å“é¡µè®¿é—®é‡", "åŠ è´­é‡",
                "ç‚¹å‡»ç‡", "è½¬åŒ–ç‡", "è®¢å•ä¹°å®¶æ•°", "æ›å…‰é‡"
            ]

        # ç»Ÿä¸€ç›®å½•
        gran = self._calculate_granularity(start_date, end_date)
        data_type = "products"
        platform = "shopee"  # ç¡¬ç¼–ç å¹³å°å
        include_shop_id = get_config_value('data_collection', 'path_options.include_shop_id', False)
        out_dir = build_output_path(
            root=output_root,
            platform=platform,
            account_label=account_label,
            shop_name=shop.name,
            data_type=data_type,
            granularity=gran,
            shop_id=getattr(shop, 'id', None),
            include_shop_id=include_shop_id,
        )
        out_dir.mkdir(parents=True, exist_ok=True)

        # å‡†å¤‡æ­¥éª¤ï¼šç™»å½• â†’ å¯¼èˆª â†’ æ—¥æœŸè®¾ç½®ï¼ˆè®¾ç½®ä¸‹è½½ç›®å½•ï¼‰
        success, msg, page, ctx = self._prepare_export_context(
            account, shop, start_date, end_date, str(out_dir)
        )
        if not success:
            return False, msg, None

        # æ–‡ä»¶åä¸ç›®æ ‡è·¯å¾„
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = build_filename(
            ts=ts,
            account_label=account_label,
            shop_name=shop.name,
            data_type=data_type,
            granularity=gran,
            start_date=start_date,
            end_date=end_date,
            suffix=".xlsx",
        )
        target_path = out_dir / filename

        # è¯Šæ–­ç›®å½•
        diag_dir = out_dir / ".diag"
        if enable_diagnostics or enable_compare_diagnostics or enable_recording_mode:
            diag_dir.mkdir(exist_ok=True)
            if not enable_compare_diagnostics and not enable_recording_mode:
                self._capture_time_controls_snapshot(page, out_dir, ts)

        # å¯¼èˆªåˆ°å•†å“è¡¨ç°é¡µé¢å¹¶è®¾ç½®å‘¨åº¦
        recipe_automation_success = False  # åˆå§‹åŒ–é…æ–¹è‡ªåŠ¨åŒ–æˆåŠŸæ ‡è®°
        try:
            self._navigate_to_product_performance(page, shop.id)

            # æ£€æŸ¥å¹¶å…³é—­å¯èƒ½çš„é€šçŸ¥å¼¹çª—
            self._close_notification_modal(page)

            # å½•åˆ¶æ¨¡å¼ï¼šå¯ç”¨tracingã€æ³¨å…¥ç›‘å¬å™¨ã€æ‰“å¼€Inspector
            if enable_recording_mode:
                logger.info("ğŸ¬ å¯åŠ¨å½•åˆ¶æ¨¡å¼...")

                # å¯åŠ¨tracing
                trace_path = diag_dir / f"{ts}_recording_trace.zip"
                try:
                    ctx.tracing.start(screenshots=True, snapshots=True, sources=True)
                    logger.info(f"ğŸ“¹ Playwright tracingå·²å¯åŠ¨ï¼Œå°†ä¿å­˜åˆ°: {trace_path}")
                except Exception as e:
                    logger.warning(f"å¯åŠ¨tracingå¤±è´¥: {e}")

                # å®‰è£…æ—¥æœŸæ§ä»¶ç›‘å¬å™¨åˆ°æ‰€æœ‰frames
                self._install_recording_monitors(page)

                # æ˜¾ç¤ºå½•åˆ¶æŒ‡å¼•å¹¶ç«‹å³æ‰“å¼€Inspector
                print("\nğŸ¯ å½•åˆ¶æ¨¡å¼å·²å¯åŠ¨ï¼š")
                print("1. é¡µé¢å·²å¯¼èˆªåˆ°å•†å“è¡¨ç°é¡µé¢")
                print("2. æ—¥æœŸæ§ä»¶ç›‘å¬å™¨å·²å®‰è£…ï¼ˆæ”¯æŒiframeï¼‰")
                print("3. æ­£åœ¨æ‰“å¼€Playwright Inspector...")
                print("4. è¯·åœ¨é¡µé¢ä¸Šæ‰‹åŠ¨æ“ä½œæ—¥æœŸé€‰æ‹©ï¼ˆåŒ…æ‹¬iframeå†…çš„æ§ä»¶ï¼‰")
                print("5. å®Œæˆæ“ä½œååœ¨Inspectorä¸­ç‚¹å‡»'Resume'ç»§ç»­")
                print("6. ç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆå½•åˆ¶é…æ–¹å’Œtraceæ–‡ä»¶")

                # ç«‹å³æ‰“å¼€Inspectorè¿›è¡Œå½•åˆ¶
                logger.info("ğŸ” æ‰“å¼€Playwright Inspectorè¿›è¡Œå½•åˆ¶...")
                page.pause()

                # å½•åˆ¶å®Œæˆåçš„å¤„ç†
                logger.info("ğŸ“Š å½•åˆ¶å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆé…æ–¹...")
                self.generate_date_picker_recipe(page, diag_dir, ts)

                # åœæ­¢tracing
                try:
                    ctx.tracing.stop(path=str(trace_path))
                    logger.info(f"âœ… Tracingå·²ä¿å­˜: {trace_path}")
                except Exception as e:
                    logger.warning(f"åœæ­¢tracingå¤±è´¥: {e}")

                # ä¸æ‰§è¡Œè‡ªåŠ¨æ—¶é—´è®¾ç½®ï¼Œå› ä¸ºç”¨æˆ·å·²æ‰‹åŠ¨æ“ä½œ
                logger.info("ğŸ¯ å½•åˆ¶æ¨¡å¼ï¼šè·³è¿‡è‡ªåŠ¨æ—¶é—´è®¾ç½®ï¼ˆç”¨æˆ·å·²æ‰‹åŠ¨æ“ä½œï¼‰")

            # å¯¹æ¯”è¯Šæ–­æ¨¡å¼ï¼šå…ˆä¿å­˜ before å¿«ç…§
            elif enable_compare_diagnostics:
                # æ—¥æœŸæ§ä»¶æ¢æµ‹
                logger.info("ğŸ” æ‰§è¡Œæ—¥æœŸæ§ä»¶æ¢æµ‹...")
                date_picker_info = self.inspect_date_picker(page)
                self.install_date_picker_monitor(page)

                # before å¿«ç…§
                self._save_compare_snapshot(page, diag_dir, ts, "before")
                # å®‰è£… MutationObserverï¼Œæ•æ‰ä¹‹åçš„DOMå˜åŒ–
                try:
                    self._install_mutation_observer(page)
                except Exception as _:
                    pass
                print("\nğŸ”§ å¯¹æ¯”è¯Šæ–­æ¨¡å¼ï¼š")
                print("è¯·æ‰‹åŠ¨å®Œæˆä»¥ä¸‹æ“ä½œï¼š")
                print("1. åˆ‡æ¢åˆ°'æŒ‰å‘¨'æ¨¡å¼")
                print("2. è®¾ç½®æ—¥æœŸèŒƒå›´ä¸º 2025-08-25 ~ 2025-08-31")
                print("3. ç‚¹å‡»'é€‰æ‹©æŒ‡æ ‡'æŒ‰é’®")
                print("4. å‹¾é€‰ä½ éœ€è¦çš„æŒ‡æ ‡ï¼ˆå¦‚ï¼šé”€é‡ã€é”€å”®é¢ã€å•†å“é¡µè®¿é—®é‡ç­‰ï¼‰")
                print("5. ç¡®è®¤æ‰€æœ‰è®¾ç½®")
                input("\nå®Œæˆä¸Šè¿°æ“ä½œåï¼ŒæŒ‰å›è½¦é”®ç»§ç»­...")

                # å°è¯•æ‰“å¼€ä¸€æ¬¡â€œé€‰æ‹©æŒ‡æ ‡â€æµ®å±‚ï¼Œä¾¿äº after å¿«ç…§æ•è·
                try:
                    self._open_metric_selector(page)
                except Exception:
                    pass

                # è·å–æ—¥æœŸæ§ä»¶äº¤äº’äº‹ä»¶
                events = self.get_date_picker_events(page)
                if events:
                    logger.info(f"ğŸ“Š æ•è·åˆ° {len(events)} ä¸ªæ—¥æœŸæ§ä»¶äº¤äº’äº‹ä»¶")
                    for event in events[-3:]:  # æ˜¾ç¤ºæœ€å3ä¸ªäº‹ä»¶
                        logger.info(f"  {event['type']}: {event.get('details', {})}")

                # ä¿å­˜ after å¿«ç…§
                self._save_compare_snapshot(page, diag_dir, ts, "after")
                # å¯¼å‡º Mutation å˜åŒ–
                try:
                    self._dump_mutations(page, diag_dir, ts)
                except Exception as _:
                    pass
                # ç”Ÿæˆå¯¹æ¯”
                self._generate_comparison_report(diag_dir, ts)
                # ç”Ÿæˆæ—¥æœŸæ§ä»¶æ“ä½œé…æ–¹
                self.generate_date_picker_recipe(page, diag_dir, ts)
            else:
                # æ ‡å‡†æ¨¡å¼ï¼šå°è¯•ä½¿ç”¨å½•åˆ¶é…æ–¹ï¼Œå¤±è´¥åˆ™å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
                recipe_success = self._try_recipe_automation(page, start_date, end_date)
                if not recipe_success:
                    logger.info("ğŸ“‹ é…æ–¹è‡ªåŠ¨åŒ–å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ—¶é—´è®¾ç½®æ–¹æ³•")
                    self._set_weekly_timerange(page, start_date, end_date)
                else:
                    # é…æ–¹è‡ªåŠ¨åŒ–æˆåŠŸï¼Œè®¾ç½®æ ‡è®°è·³è¿‡åç»­æ—¥æœŸæ§ä»¶æ¢æµ‹
                    recipe_automation_success = True
        except Exception as e:
            logger.error(f"è®¾ç½®é¡µé¢å‘¨åº¦å¤±è´¥: {e}")
            # å›é€€ä¸ºå¿«æ·é¡¹ï¼šè¿‡å»7å¤©
            try:
                self._set_quick_timerange(page, label='è¿‡å»7')
            except Exception:
                pass
            return False, f"è®¾ç½®é¡µé¢å‘¨åº¦å¤±è´¥: {e}", None

        # è‹¥ä»æ˜¾ç¤ºâ€œä»Šæ—¥å®æ—¶â€ï¼Œå›é€€ä¸ºå¿«æ·é¡¹è®¾ç½®â€œè¿‡å»7å¤©â€
        # æ³¨é‡Šï¼šç§»é™¤å¼ƒç”¨çš„æŒ‰å‘¨è®¾ç½®æ£€æŸ¥é€»è¾‘ï¼Œç°åœ¨ä½¿ç”¨é…æ–¹è‡ªåŠ¨åŒ–
        # try:
        #     info = self.inspect_date_picker(page)
        #     if info and info.get('activeShortcut') in ("ä»Šæ—¥å®æ—¶", "Today", "ä»Šå¤©"):
        #         logger.warning("æŒ‰å‘¨è®¾ç½®å¯èƒ½æœªç”Ÿæ•ˆï¼Œå›é€€ä¸ºå¿«æ·é¡¹ï¼šè¿‡å»7å¤©")
        #         self._set_quick_timerange(page, label='è¿‡å»7')
        # except Exception:
        #     pass

        # å¢å¼ºè¯Šæ–­ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if enable_diagnostics:
            self._enhanced_diagnostics(page, diag_dir)

        # æŒ‡æ ‡å‹¾é€‰åº”å½“å‘ç”Ÿåœ¨å¯¼å‡ºä¹‹å‰ï¼ˆæ ‡å‡†æ¨¡å¼ï¼‰
        # åœ¨æ ‡å‡†æ¨¡å¼ä¸‹ä¹Ÿæ‰§è¡Œæ—¥æœŸæ§ä»¶æ¢æµ‹ï¼ˆä½†é…æ–¹è‡ªåŠ¨åŒ–æˆåŠŸæ—¶è·³è¿‡ï¼‰
        if not enable_compare_diagnostics and not enable_recording_mode and not recipe_automation_success:
            logger.info("ğŸ” æ‰§è¡Œæ—¥æœŸæ§ä»¶æ¢æµ‹...")
            self.inspect_date_picker(page)
        # æŒ‡æ ‡å‹¾é€‰å·²ç¦ç”¨ï¼šå¯¼å‡ºè·å–å…¨é‡æ•°æ®
        logger.info("ğŸ“Š æ ‡å‡†æ¨¡å¼ï¼šè·³è¿‡æŒ‡æ ‡å‹¾é€‰ï¼ˆå¯¼å‡ºè·å–å…¨é‡æ•°æ®ï¼‰")

        # å…ˆå°è¯•â€œé¡µé¢äº¤äº’å¼å¯¼å‡ºâ€ï¼ˆç‚¹å‡»é¡µé¢ä¸Šçš„å¯¼å‡º/ä¸‹è½½æŒ‰é’®å¹¶æ•è·ä¸‹è½½ï¼‰
        try:
            if enable_diagnostics or enable_compare_diagnostics or enable_recording_mode:
                try:
                    pre_net = diag_dir / f"{ts}_pre_net.json"
                    self._capture_network_snapshot(page, duration_ms=8000, out_file=pre_net)
                except Exception as ne:
                    logger.debug(f"é¢„æŠ“å–ç½‘ç»œå¿«ç…§å¤±è´¥: {ne}")

            ok, ui_msg = self._export_via_ui(
                page,
                target_path,
                diag_dir=diag_dir,
                ts=ts,
                capture_network=(enable_diagnostics or enable_compare_diagnostics or enable_recording_mode),
                enable_auto_regenerate=enable_auto_regenerate,
            )
            if ok:
                return True, ui_msg, target_path
        except Exception as e:
            logger.debug(f"UIå¯¼å‡ºæµç¨‹æœªæˆåŠŸï¼Œå›é€€åˆ°APIæ–¹æ¡ˆ: {e}")

        # APIå¤‡é€‰è·¯å¾„ï¼ˆå¯é…ç½®å¼€å…³ï¼Œé»˜è®¤ç¦ç”¨é¿å…timestamp errorï¼‰
        if not enable_api_fallback:
            logger.info("ğŸš« APIå¤‡é€‰å·²ç¦ç”¨ï¼Œå¯¼å‡ºå¤±è´¥")
            return False, "UIå¯¼å‡ºå¤±è´¥ä¸”APIå¤‡é€‰å·²ç¦ç”¨", None

        logger.info("ğŸ”„ å¯ç”¨APIå¤‡é€‰è·¯å¾„...")
        # åœ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡å†…å‘èµ· export â†’ è½®è¯¢ report â†’ ç”Ÿæˆä¸‹è½½é“¾æ¥
        export_url = f"{self.base}/api/mydata/cnsc/shop/v2/product/performance/export/"
        download_api = f"{self.base}/api/v3/settings/download_report/"

        # æŒ‡æ ‡å‹¾é€‰å·²ç¦ç”¨ï¼šå¯¼å‡ºè·å–å…¨é‡æ•°æ®
        logger.info("ğŸ“Š è·³è¿‡æŒ‡æ ‡å‹¾é€‰ï¼ˆå¯¼å‡ºè·å–å…¨é‡æ•°æ®ï¼‰")
        if False:  # æŒ‡æ ‡å‹¾é€‰å·²ç¦ç”¨
            try:
                self._select_metrics(page, metrics)
                # å‹¾é€‰åå°è¯•ç‚¹å‡»â€œç¡®å®š/åº”ç”¨/å®Œæˆâ€ç±»æŒ‰é’®ç¡®ä¿è®¾ç½®ç”Ÿæ•ˆ
                try:
                    self._confirm_metrics_selection(page)
                except Exception:
                    pass
            except Exception as e:
                logger.warning(f"æŒ‡æ ‡å‹¾é€‰å¤±è´¥ï¼ˆå°†ç»§ç»­å¯¼å‡ºï¼‰: {e}")

        # ä¼˜å…ˆä½¿ç”¨UIè¯»å–åˆ°çš„ç§’çº§æ—¶é—´æˆ³ï¼›è‹¥UIä¸å¯ç”¨ï¼Œå›é€€åˆ°å…¥å‚è®¡ç®—ï¼ˆä¸¥æ ¼ +08:00ï¼Œå³å¼€åŒºé—´ï¼‰
        try:
            ui_start_ms, ui_end_ms = self._read_week_from_ui(page)
            start_ts_ui = ui_start_ms // 1000 if ui_start_ms else None
            end_ts_ui = ui_end_ms // 1000 if ui_end_ms else None
        except Exception as e:
            start_ts_ui, end_ts_ui = None, None
            logger.warning(f"ä»UIè¯»å–æ—¶é—´å¤±è´¥: {e}")

        def to_ts_start_tz(d: str) -> int:
            from datetime import timezone, timedelta
            tz = timezone(timedelta(hours=8))
            dt = datetime.strptime(d, "%Y-%m-%d").replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=tz)
            return int(dt.timestamp())
        def to_ts_end_tz(d: str) -> int:
            from datetime import timezone, timedelta
            tz = timezone(timedelta(hours=8))
            dt = datetime.strptime(d, "%Y-%m-%d").replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=tz)
            dt = dt + timedelta(days=1)
            return int(dt.timestamp())

        if start_ts_ui and end_ts_ui:
            start_ts, end_ts = start_ts_ui, end_ts_ui
            logger.info(f"ä½¿ç”¨æ—¶é—´æˆ³(ç§’): start_ts={start_ts}, end_ts={end_ts} ï¼ˆæ¥æº=UIï¼‰")
        else:
            start_ts, end_ts = to_ts_start_tz(start_date), to_ts_end_tz(end_date)
            logger.info(f"ä½¿ç”¨æ—¶é—´æˆ³(ç§’): start_ts={start_ts}, end_ts={end_ts} ï¼ˆæ¥æº=ç›®æ ‡å‘¨åº¦ï¼ŒUI={start_ts_ui},{end_ts_ui}ï¼‰")

        # å¯ç”¨ç½‘ç»œè¯·æ±‚ç›‘å¬ï¼ˆè¯Šæ–­æ¨¡å¼ï¼‰
        network_requests = []
        if enable_diagnostics:
            def handle_request(request):
                if 'export' in request.url or 'download' in request.url:
                    network_requests.append({
                        "url": request.url,
                        "method": request.method,
                        "headers": dict(request.headers),
                        "post_data": request.post_data
                    })
            page.on("request", handle_request)

        # æ—¶é—´æˆ³å®¹é”™å›é€€ç­–ç•¥
        start_ts_fallback = start_ts
        end_ts_fallback = end_ts

        logger.info("å‘èµ·å¯¼å‡ºè¯·æ±‚ï¼ˆé¡µé¢ä¸Šä¸‹æ–‡ï¼‰â€¦")
        script_export = """
        async ({export_url, download_api, shop_id, start_ts, end_ts}) => {
          const p = new URL(export_url);
          p.searchParams.set('start_ts', String(start_ts));
          p.searchParams.set('end_ts', String(end_ts));
          p.searchParams.set('period', 'week');
          p.searchParams.set('sort_by', '');
          p.searchParams.set('cnsc_shop_id', shop_id);

          // å‘èµ·è¯·æ±‚
          const r = await fetch(p.toString(), { credentials:'include' });
          if (!r.ok) throw new Error('export http ' + r.status);
          const ct = (r.headers.get('content-type')||'').toLowerCase();
          const cd = r.headers.get('content-disposition') || '';
          const filename = (cd.match(/filename\\*=UTF-8''([^;]+)|filename="?([^";]+)"?/i) || []).slice(1).find(Boolean) || '';

          // åˆ†æ”¯1ï¼šJSONæµç¨‹ï¼ˆè¿”å› report_idï¼Œéœ€è½®è¯¢ï¼‰
          if (ct.includes('application/json')) {
            const j = await r.json();
            if (!(j && (j.code===0 || j.code===200))) throw new Error('export code ' + JSON.stringify(j));
            const report_id = j?.data?.report_id;
            if (!report_id) throw new Error('no report_id');
            // è½®è¯¢æŸ¥è¯¢çŠ¶æ€
            const wait = (ms)=>new Promise(res=>setTimeout(res,ms));
            for (let i=0;i<30;i++) {
              const d = new URL(download_api);
              d.searchParams.set('report_id', String(report_id));
              d.searchParams.set('cnsc_shop_id', shop_id);
              const dr = await fetch(d.toString(), { credentials:'include' });
              if (dr.ok) {
                const dj = await dr.json();
                if (dj && (dj.code===0 || dj.code===200)) {
                  const info = dj.data || {};
                  if (info.status === 2 && info.download_link) {
                    return { mode: 'report', report_id, download_link: info.download_link };
                  }
                  if (info.status === 3) throw new Error('report failed');
                }
              }
              await wait(5000);
            }
            throw new Error('report timeout');
          }

          // åˆ†æ”¯2ï¼šéJSONï¼ˆå¯èƒ½ç›´æ¥è¿”å›Excel/CSVç­‰ï¼‰ï¼Œæ”¹ç”¨ç›´æ¥ä¸‹è½½æ¨¡å¼
          if (ct.includes('application/octet-stream') || ct.includes('application/vnd') || ct.includes('excel') || cd.toLowerCase().includes('attachment')) {
            return { mode: 'direct', direct_url: p.toString(), content_type: ct, filename };
          }

          // å…¶ä»–æœªçŸ¥ç±»å‹ï¼Œè¿”å›æ–‡æœ¬è¯Šæ–­å¹¶èµ° direct_url å…œåº•
          const text = await r.text().catch(()=>'');
          return { mode: 'unknown', direct_url: p.toString(), content_type: ct, filename, preview: (text||'').slice(0,200) };
        }
        """

        # å°è¯•å¯¼å‡ºï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨é‡è¯•ä¸€æ¬¡ï¼ˆè°ƒæ•´æ—¶é—´æˆ³æ ¼å¼ï¼‰
        export_attempts = []

        try:
            params = {
                "export_url": export_url,
                "download_api": download_api,
                "shop_id": shop.id,
                "start_ts": start_ts,
                "end_ts": end_ts,
            }
            export_attempts.append({"attempt": 1, "params": params.copy()})

            result = page.evaluate(script_export, params)
            mode = result.get("mode")
            if mode == 'report':
                download_link = result.get("download_link")
                logger.info(f"æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Œå‡†å¤‡ä¸‹è½½: {download_link}")
            else:
                download_link = None
                logger.info(f"å¯¼å‡ºè¿”å›éJSONï¼ˆ{result.get('content_type')}ï¼‰ï¼Œå°†å°è¯•ç›´æ¥ä¸‹è½½æ¨¡å¼")
        except Exception as e:
            # å¦‚æœèµ°éJSONåˆ†æ”¯ï¼ˆç›´æ¥ä¸‹è½½ï¼‰ï¼Œè®°å½•å°è¯•å‚æ•°å¤´ä¿¡æ¯ï¼ˆä»…ç¬¬ä¸€è½®ï¼‰
            try:
                export_attempts[-1]["result_head"] = {k: result.get(k) for k in ["mode","content_type","filename","preview"] if k in result}
            except Exception:
                pass

            logger.warning(f"ç¬¬ä¸€æ¬¡å¯¼å‡ºå¤±è´¥: {e}")

            # è‡ªåŠ¨é‡è¯•ï¼šå°è¯•æ¯«ç§’æ—¶é—´æˆ³
            try:
                logger.info("è‡ªåŠ¨é‡è¯•ï¼šæ—¶é—´æˆ³å®¹é”™å›é€€...")

                # æ—¶é—´æˆ³å›é€€ç­–ç•¥ï¼šä¸¥æ ¼ +08:00 å¯¹é½ï¼Œend_ts å®‰å…¨é’³åˆ¶
                from datetime import timezone, timedelta
                tz_plus8 = timezone(timedelta(hours=8))

                # å°† start_ts å¯¹é½åˆ°å½“å¤© 00:00 +08:00
                start_dt = datetime.fromtimestamp(start_ts, tz=tz_plus8)
                start_aligned = start_dt.replace(hour=0, minute=0, second=0, microsecond=0)
                start_ts_fallback = int(start_aligned.timestamp())

                # end_ts é’³åˆ¶ï¼šä¸è¶…è¿‡æ˜¨å¤© 23:59:59 +08:00
                now_plus8 = datetime.now(tz=tz_plus8)
                yesterday_end = (now_plus8 - timedelta(days=1)).replace(hour=23, minute=59, second=59, microsecond=0)
                end_ts_max = int(yesterday_end.timestamp())
                end_ts_fallback = min(end_ts, end_ts_max)

                logger.info(f"å›é€€æ—¶é—´æˆ³: start={start_ts_fallback}, end={end_ts_fallback}")

                retry_params = {
                    "export_url": export_url,
                    "download_api": download_api,
                    "shop_id": shop.id,
                    "start_ts": start_ts_fallback,
                    "end_ts": end_ts_fallback,
                }
                export_attempts.append({"attempt": 2, "params": retry_params.copy(), "retry_reason": str(e)})

                result = page.evaluate(script_export, retry_params)
                mode = result.get("mode")
                if mode == 'report':
                    download_link = result.get("download_link")
                    logger.info(f"é‡è¯•æˆåŠŸï¼ŒæŠ¥å‘Šç”Ÿæˆï¼Œå‡†å¤‡ä¸‹è½½: {download_link}")
                else:
                    download_link = None
                    logger.info(f"é‡è¯•è¿”å›éJSONï¼ˆ{result.get('content_type')}ï¼‰ï¼Œå°†å°è¯•ç›´æ¥ä¸‹è½½æ¨¡å¼")
            except Exception as retry_e:
                logger.error(f"é‡è¯•ä¹Ÿå¤±è´¥: {retry_e}")

                # ä¿å­˜å¯¼å‡ºå°è¯•è®°å½•ç”¨äºè¯Šæ–­
                if enable_diagnostics or enable_compare_diagnostics:
                    attempts_file = diag_dir / f"{ts}_export_attempts.json"
                    attempts_file.write_text(
                        json.dumps(export_attempts, ensure_ascii=False, indent=2),
                        encoding="utf-8"
                    )
                return False, f"å¯¼å‡ºå¤±è´¥ï¼ˆå·²é‡è¯•ï¼‰: {retry_e}", None
        # ä¸‹è½½é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨ download_linkï¼›å¦åˆ™å°è¯•ç›´æ¥ä¸‹è½½æ¨¡å¼
        try:
            if download_link:
                # æ­£å¸¸æŠ¥å‘Šä¸‹è½½
                with page.expect_download(timeout=120000) as dl_info:
                    page.evaluate(
                        "(url)=>{ const a=document.createElement('a'); a.href=url; a.download=''; document.body.appendChild(a); a.click(); }",
                        download_link,
                    )
                download = dl_info.value
                download.save_as(str(target_path))
            else:
                # ç›´æ¥ä¸‹è½½æ¨¡å¼ï¼šåœ¨é¡µé¢ä¸Šä¸‹æ–‡è§¦å‘ fetch(blob) å¹¶è§¦å‘ä¸‹è½½
                with page.expect_download(timeout=120000) as dl_info:
                    page.evaluate(
                        "(url)=>{ fetch(url, {credentials:'include'}).then(r=>r.blob()).then(b=>{ const blobUrl=URL.createObjectURL(b); const a=document.createElement('a'); a.href=blobUrl; a.download='export.xlsx'; document.body.appendChild(a); a.click(); setTimeout(()=>URL.revokeObjectURL(blobUrl), 5000); }); }",
                        result.get("direct_url") or result.get("download_link") or export_url,
                    )
                download = dl_info.value
                download.save_as(str(target_path))

            size = target_path.stat().st_size if target_path.exists() else 0
            meta = {
                "platform": platform,
                "account": account_label,
                "shop_id": shop.id,
                "shop_name": shop.name,
                "data_type": data_type,
                "granularity": gran,

                "start_date": start_date,
                "end_date": end_date,
                "created_at": ts,
                "report_id": result.get("report_id"),
                "download_link": download_link or result.get("direct_url"),
                "file_path": str(target_path),
                "file_size": size,
                "mode": result.get("mode"),
                "content_type": result.get("content_type"),
            }
            (target_path.with_suffix(target_path.suffix + ".meta.json")).write_text(
                json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8"
            )

            if enable_diagnostics and network_requests:
                network_file = diag_dir / f"{ts}_network_requests.json"
                network_file.write_text(
                    json.dumps(network_requests, ensure_ascii=False, indent=2),
                    encoding="utf-8"
                )
                logger.info(f"ç½‘ç»œè¯·æ±‚ä¿¡æ¯å·²ä¿å­˜: {network_file}")

            logger.success(f"ä¸‹è½½å®Œæˆ: {target_path} ({size:,} bytes)")
            return True, "ä¸‹è½½å®Œæˆ", target_path
        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            return False, f"ä¸‹è½½å¤±è´¥: {e}", None




    def _open_date_picker(self, page) -> bool:
        """æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨å¼¹å‡ºå±‚ã€‚
        åŸºäºDOMå·®å¼‚ï¼š
        - æœªæ‰“å¼€ï¼šclass="bi-date-input track-click-open-time-selector"
        - å·²æ‰“å¼€ï¼šclass="bi-date-input bi-date-input__focus track-click-open-time-selector"
        """
        try:
            container_selectors = [

                '.bi-date-input.track-click-open-time-selector',
                '.track-click-open-time-selector.bi-date-input',
                '.track-click-open-time-selector .bi-date-input',
                'div.track-click-open-time-selector',
                'div:has(.bi-date-input-icon):has-text("ç»Ÿè®¡æ—¶é—´")',
                'div.bi-date-input',
                'div:has(span.title:has-text("ç»Ÿè®¡æ—¶é—´"))',
                'div:has(span.value)',
                '[class*="bi-date-input"][class*="track-click-open-time-selector"]',
                '.bi-date-input:has(span.title:has-text("ç»Ÿè®¡æ—¶é—´"))',
                '.bi-date-input__suffix',
                '.bi-date-input-icon',
                'span.value',
                'text=ä»Šæ—¥å®æ—¶',
                'text=Today',
            ]

            def is_open() -> bool:
                # 1) æ ¹æ® focus class åˆ¤æ–­ï¼ˆåŒ…æ‹¬å®¹å™¨ç¥–å…ˆï¼‰
                try:
                    if page.locator('.bi-date-input.bi-date-input__focus.track-click-open-time-selector, .bi-date-input.bi-date-input__focus').count() > 0:
                        return True
                except Exception:
                    pass
                for s in container_selectors:
                    try:
                        loc = page.locator(s)
                        if loc.count() > 0:
                            parent = loc.first.locator('xpath=ancestor-or-self::div[contains(@class,"bi-date-input")]').first
                            if parent and (parent.get_attribute('class') or '').find('bi-date-input__focus') >= 0:
                                return True
                    except Exception:
                        continue
                # 2) å¼¹å±‚å†…å®¹å‡ºç°ä¹Ÿè§†ä¸ºå·²æ‰“å¼€
                if page.locator('.eds-date-shortcut-item, .bi-date-shortcuts li, .eds-date-picker, .bi-date-picker').count() > 0:
                    return True
                # 3) èšç„¦æ€é€šè¿‡ARIA/roleä¹Ÿå¯èƒ½å¯è§
                try:
                    role_popup = page.get_by_role('dialog')
                    if role_popup.count() > 0 and role_popup.first.is_visible():
                        return True
                except Exception:
                    pass
                return False

            # å·²ç»æ‰“å¼€
            if is_open():
                return True

            # ä¼˜å…ˆå°è¯•é…æ–¹å¤åˆ»ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                # ä»å½“å‰URLæå–shop_id
                current_url = page.url
                shop_id_match = re.search(r'cnsc_shop_id=(\d+)', current_url)
                if shop_id_match:
                    shop_id = shop_id_match.group(1)
                    recipe = self.load_date_picker_recipe(shop_id)
                    if recipe:
                        logger.info("ğŸ¬ å°è¯•ä½¿ç”¨é…æ–¹å¤åˆ»æ‰“å¼€æ—¥æœŸæ§ä»¶")
                        if self.replay_date_picker_recipe(page, recipe):
                            page.wait_for_timeout(500)
                            if is_open():
                                logger.info("å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: é…æ–¹å¤åˆ»æˆåŠŸ")
                                return True
            except Exception as e:
                logger.debug(f"é…æ–¹å¤åˆ»å¤±è´¥: {e}")

            # è‹¥æœªæ‰“å¼€ï¼Œä½¿ç”¨å¼ºåˆ¶æ‰“å¼€ä¸€æ¬¡ï¼ˆJS+åæ ‡ï¼‰
            try:
                if self._force_open_date_picker(page):
                    page.wait_for_timeout(300)
                    if is_open():
                        logger.info("å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: å¼ºåˆ¶æ‰“å¼€æˆåŠŸ")
                        return True
            except Exception:
                pass

            # å¤šè½®å°è¯•ç‚¹å‡»å®¹å™¨/å›¾æ ‡/åæ ‡
            for _ in range(3):
                clicked = False
                for sel in container_selectors:
                    try:
                        loc = page.locator(sel)
                        if loc.count() > 0 and loc.first.is_visible():
                            el = loc.first
                            try:
                                before = el.get_attribute('class') or ''
                                logger.debug(f'æ—¥æœŸå®¹å™¨[{sel}] before class="{before}"')
                            except Exception:
                                pass

                            # ç¡®ä¿åœ¨è§†å£å†…å¹¶æ‚¬åœ
                            try:
                                el.scroll_into_view_if_needed()
                                el.hover()
                            except Exception:
                                pass

                            # 1) å¸¸è§„ç‚¹å‡» + ç­‰å¾…
                            try:
                                el.click(force=True)
                                clicked = True
                                page.wait_for_timeout(300)
                                # æ˜¾å¼ç­‰å¾…ç„¦ç‚¹æˆ–å¼¹å±‚å¯è§
                                try:
                                    page.wait_for_selector('.bi-date-input.bi-date-input__focus.track-click-open-time-selector, .eds-date-picker, .bi-date-picker, [role="dialog"]', state='visible', timeout=1200)
                                except Exception:
                                    pass
                                if is_open():
                                    logger.info(f"å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: é€šè¿‡ç‚¹å‡» {sel}")
                                    return True
                                # é¢å¤–ç‚¹å‡» span.value æ–‡æœ¬
                                try:
                                    val = el.locator('span.value')
                                    if val.count() > 0 and val.first.is_visible():
                                        val.first.click()
                                        page.wait_for_timeout(200)
                                        if is_open():
                                            logger.info("å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: ç‚¹å‡» span.value")
                                            return True
                                except Exception:
                                    pass
                                # å›è½¦é”®å°è¯•æ‰“å¼€
                                try:
                                    el.focus()
                                    el.press('Enter')
                                    page.wait_for_timeout(200)
                                    if is_open():
                                        logger.info("å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: Enter é”®")
                                        return True
                                except Exception:
                                    pass
                            except Exception:
                                pass

                            # 2) åŒå‡»å°è¯•
                            try:
                                el.dblclick()
                                page.wait_for_timeout(300)
                                if is_open():
                                    logger.info(f"å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: åŒå‡» {sel}")
                                    return True
                            except Exception:
                                pass

                            # 3) ç‚¹å‡»å†…éƒ¨å›¾æ ‡/åç¼€
                            try:
                                icon = el.locator('.bi-date-input-icon, .bi-date-input__suffix')
                                if icon.count() > 0 and icon.first.is_visible():
                                    icon.first.click(force=True)
                                    page.wait_for_timeout(300)
                                    if is_open():
                                        logger.info(f"å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: ç‚¹å‡»å›¾æ ‡ {sel}")
                                        return True
                            except Exception:
                                pass

                            # 4) åæ ‡ç‚¹å‡»å…œåº•
                            try:
                                box = el.bounding_box()
                                if box:
                                    page.mouse.move(box['x'] + box['width']/2, box['y'] + box['height']/2)
                                    page.mouse.down()
                                    page.mouse.up()
                                    page.wait_for_timeout(300)
                                    if is_open():
                                        logger.info(f"å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: åæ ‡ç‚¹å‡» {sel}")
                                        return True
                            except Exception:
                                pass

                            # 5) JS å¼ºåˆ¶ç‚¹å‡»
                            try:
                                page.evaluate("(sel)=>{const el=document.querySelector(sel); if(el){el.click(); el.dispatchEvent(new MouseEvent('click',{bubbles:true}))}}", sel)
                                page.wait_for_timeout(300)
                                if is_open():
                                    logger.info(f"å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: JS ç‚¹å‡» {sel}")
                                    return True
                            except Exception:
                                pass
                    except Exception:
                        continue

                if not clicked:
                    # å…œåº•ï¼šç‚¹å‡»â€œç»Ÿè®¡æ—¶é—´â€æ–‡æœ¬æˆ–å›¾æ ‡
                    try:
                        t = page.locator('text=ç»Ÿè®¡æ—¶é—´')
                        if t.count() > 0 and t.first.is_visible():
                            t.first.scroll_into_view_if_needed()
                            t.first.hover()
                            t.first.click(force=True)
                            page.wait_for_timeout(300)
                            if is_open():
                                logger.info('å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: ç‚¹å‡»ç»Ÿè®¡æ—¶é—´æ–‡æœ¬')
                                return True
                    except Exception:
                        pass
                    try:
                        ico = page.locator('.bi-date-input-icon')
                        if ico.count() > 0 and ico.first.is_visible():
                            try:
                                ico.first.scroll_into_view_if_needed()
                                ico.first.hover()
                                ico.first.click(force=True)
                                page.wait_for_timeout(300)
                                if is_open():
                                    logger.info('å·²æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨: ç‚¹å‡»é¡µé¢çº§å›¾æ ‡')
                                    return True
                            except Exception:
                                pass
                    except Exception:
                        pass

                logger.warning('å¤šæ¬¡å°è¯•åä»æœªèƒ½æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨')
                return False
        except Exception as e:
            logger.error(f'æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨å¤±è´¥: {e}')
            return False

    def _force_open_date_picker(self, page) -> bool:
        """ä½¿ç”¨JS+åæ ‡çš„å¼ºåˆ¶æ‰“å¼€æ–¹å¼ï¼Œç›´æ¥ä½œç”¨äº .bi-date-input å®¹å™¨ã€‚
        è¿”å› True è¡¨ç¤ºæ¨æµ‹å·²æ‰“å¼€ï¼ˆéšåç”± is_open äºŒæ¬¡æ ¡éªŒï¼‰ã€‚"""
        try:
            # 1) ç­‰å¾…æ—¶é—´æ˜¾ç¤ºå…ƒç´ å‡ºç°
            try:
                page.wait_for_selector('span.value, .bi-date-input', state='attached', timeout=2000)
            except Exception:
                pass

            # 2) ç”¨ JS æ‰¾åˆ°å®¹å™¨å¹¶å°è¯•æ»šåŠ¨ä¸ç‚¹å‡»
            script = """
            () => {
                const res = { ok: false, x: null, y: null, w: null, h: null, used: null };
                let container = document.querySelector('.bi-date-input.track-click-open-time-selector');
                if (!container) {
                    const val = document.querySelector('span.value');
                    if (val) container = val.closest('.bi-date-input');
                }
                if (!container) container = document.querySelector('.bi-date-input');
                if (!container) return res;

                const rect = container.getBoundingClientRect();
                const topOffset = Math.max(0, rect.top - 160);
                window.scrollTo({ top: window.scrollY + topOffset, behavior: 'instant' });

                // ç›´æ¥è§¦å‘ click äº‹ä»¶
                try {
                    container.click();
                    container.dispatchEvent(new MouseEvent('click', { bubbles: true }));
                    res.ok = true;
                    res.x = rect.left + rect.width / 2;
                    res.y = rect.top + rect.height / 2;
                    res.w = rect.width; res.h = rect.height; res.used = 'element.click';
                    return res;
                } catch (e) {}

                // é€€åŒ–æ–¹æ¡ˆï¼šç‚¹å‡»å›¾æ ‡/åç¼€
                const ico = container.querySelector('.bi-date-input-icon, .bi-date-input__suffix');
                if (ico) {
                    try { ico.click(); res.ok = true; res.used = 'icon.click'; } catch(e){}
                }

                res.x = rect.left + rect.width / 2;
                res.y = rect.top + rect.height / 2;
                res.w = rect.width; res.h = rect.height; res.used = res.used || 'coords';
                return res;
            }
            """
            info = page.evaluate(script)
            if info:
                try:
                    # 3) å¦‚æœéœ€è¦ï¼Œç”¨åæ ‡å†ç‚¹ä¸€æ¬¡
                    if info.get('used') == 'coords' or not self._read_time_display(page):
                        x = float(info.get('x') or 0.0)
                        y = float(info.get('y') or 0.0)
                        if x and y:
                            page.mouse.move(x, y)
                            page.mouse.down()
                            page.mouse.up()
                except Exception:
                    pass
            page.wait_for_timeout(350)
            return True
        except Exception as e:
            logger.warning(f"_force_open_date_picker å¤±è´¥: {e}")
            return False


    def _read_time_display(self, page) -> Dict[str, str]:
        """è¯»å–é¡µé¢æ—¶é—´æ§ä»¶çš„æ˜¾ç¤ºæ–‡æœ¬ï¼ˆlabel/valueï¼‰ã€‚"""
        try:
            script = """
            () => {
                const res = { label: null, value: null, text: null };
                const candidates = Array.from(document.querySelectorAll(
                    '.bi-date-input.track-click-open-time-selector, .bi-date-input'
                ));
                for (const el of candidates) {
                    const title = el.querySelector('.title')?.textContent?.trim();
                    const label = el.querySelector('.label')?.textContent?.trim() || null;
                    const value = el.querySelector('.value')?.textContent?.trim() || null;
                    const text = el.textContent?.trim() || null;
                    if (title?.includes('ç»Ÿè®¡æ—¶é—´') || label || value) {
                        return { label, value, text };
                    }
                }
                // fallback: å…¨å±€æœç´¢åŒ…å«â€œç»Ÿè®¡æ—¶é—´â€çš„å…ƒç´ 
                const all = Array.from(document.querySelectorAll('*'));
                const node = all.find(n => (n.textContent || '').includes('ç»Ÿè®¡æ—¶é—´'));
                if (node) {
                    const el = node.closest('.bi-date-input') || node.parentElement;
                    if (el) {
                        const label = el.querySelector('.label')?.textContent?.trim() || null;
                        const value = el.querySelector('.value')?.textContent?.trim() || null;
                        const text = el.textContent?.trim() || null;
                        return { label, value, text };
                    }
                }
                return res;
            }
            """;
            return page.evaluate(script)
        except Exception:
            return {"label": None, "value": None, "text": None}

    def _wait_time_display_change(self, page, prev_text: str | None, timeout_ms: int = 6000) -> bool:
        """ç­‰å¾…æ—¶é—´æ§ä»¶æ˜¾ç¤ºæ–‡æœ¬å‘ç”Ÿå˜åŒ–ã€‚
        è¿”å› True è¡¨ç¤ºæ–‡æœ¬æ›´æ–°ä¸”ä¸å†æ˜¯â€œä»Šæ—¥å®æ—¶/Today/ä»Šå¤©â€ã€‚
        """
        try:
            checks = 0
            while checks * 300 < timeout_ms:
                info = self._read_time_display(page)
                cur = info.get('value') or info.get('label') or info.get('text') or ''
                if cur and cur != prev_text and ('ä»Šæ—¥å®æ—¶' not in cur) and ('Today' not in cur) and ('ä»Šå¤©' not in cur):
                    return True
                page.wait_for_timeout(300)
                checks += 1
        except Exception:
            pass
        return False

    def _set_quick_timerange(self, page, label: str = 'è¿‡å»7') -> bool:
        """é€šè¿‡å¿«æ·é¡¹è®¾ç½®æ—¶é—´èŒƒå›´ï¼Œä¾‹å¦‚ï¼šè¿‡å»7å¤©/è¿‡å»30å¤©ã€‚
        label: å…³é”®å­—ï¼Œæ”¯æŒ 'è¿‡å»7' / 'è¿‡å»30' / 'Last 7' / 'Last 30' / 'è¿‘7' / 'è¿‘30'
        """
        try:
            # è¯»å–ä¹‹å‰çš„æ—¶é—´æ˜¾ç¤º
            prev = (self._read_time_display(page) or {}).get('value')

            opened = self._open_date_picker(page)
            if not opened:
                logger.warning("æœªèƒ½æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨ï¼Œå°†å°è¯•ç›´æ¥æŸ¥æ‰¾å¿«æ·é¡¹ã€‚")

            candidates = [
                f'.eds-date-shortcut-item:has-text("{label}")',
                f'.bi-date-shortcuts li:has-text("{label}")',
            ]
            # å¤šè¯­è¨€å€™é€‰
            synonyms = []
            if '7' in label:
                synonyms = ['è¿‡å»7', 'Last 7', 'è¿‘7', '7 å¤©', '7å¤©']
            elif '30' in label:
                synonyms = ['è¿‡å»30', 'Last 30', 'è¿‘30', '30 å¤©', '30å¤©']
            for s in synonyms:
                candidates.append(f'.eds-date-shortcut-item:has-text("{s}")')
                candidates.append(f'.bi-date-shortcuts li:has-text("{s}")')

            clicked = False
            for sel in candidates:
                try:
                    loc = page.locator(sel)
                    if loc.count() > 0 and loc.first.is_visible():
                        loc.first.click()
                        logger.info(f"ç‚¹å‡»å¿«æ·é¡¹: {sel}")
                        clicked = True
                        break
                except Exception:
                    continue

            if not clicked:
                logger.warning(f"æœªæ‰¾åˆ°å¿«æ·é¡¹: {label}")
                return False

            # å¯èƒ½éœ€è¦ç‚¹å‡»ç¡®å®š/åº”ç”¨
            for ok_sel in ['button:has-text("ç¡®å®š")', 'button:has-text("åº”ç”¨")', '.ant-modal .ant-btn-primary', '.el-dialog .el-button--primary']:
                try:
                    ok = page.locator(ok_sel)
                    if ok.count() > 0 and ok.first.is_visible():
                        ok.first.click()
                        logger.info(f"ç‚¹å‡»å¿«æ·é¡¹ç¡®è®¤æŒ‰é’®: {ok_sel}")
                        break
                except Exception:
                    continue

            # ç­‰å¾…æ—¶é—´æ˜¾ç¤ºå‘ç”Ÿå˜åŒ–ï¼ˆä¸å†æ˜¯â€œä»Šæ—¥å®æ—¶â€ï¼‰
            if self._wait_time_display_change(page, prev):
                logger.info("å¿«æ·é¡¹ç”Ÿæ•ˆï¼šæ—¶é—´æ˜¾ç¤ºå·²å˜åŒ–")
                return True

            # è‹¥æœªèƒ½é€šè¿‡æ˜¾ç¤ºæ–‡æœ¬åˆ¤æ–­ï¼Œå›é€€åˆ°æ¢æµ‹å™¨åˆ¤æ–­
            try:
                info = self.inspect_date_picker(page)
                active = (info or {}).get('activeShortcut')
                if active and ('7' in label and ('7' in active or '7 ' in active)):
                    return True
                if active and ('30' in label and ('30' in active or '30 ' in active)):
                    return True
            except Exception:
                pass

            # å…œåº•ï¼šè®¤ä¸ºå·²ç‚¹å‡»ï¼Œè¿”å› Trueï¼Œè®©åç»­ç½‘ç»œå‚æ•°æ ¡éªŒæ¥ä¿è¯
            return True
        except Exception as e:
            logger.error(f"å¿«æ·æ—¶é—´è®¾ç½®å¤±è´¥: {e}")
            return False


    def _navigate_to_product_performance(self, page, shop_id: str):
        """å¯¼èˆªåˆ°å•†å“è¡¨ç°é¡µé¢"""
        perf_url = f"{self.base}/datacenter/product/performance?cnsc_shop_id={shop_id}"
        logger.info(f"å¯¼èˆªåˆ°å•†å“è¡¨ç°é¡µé¢: {perf_url}")
        page.goto(perf_url, wait_until="domcontentloaded", timeout=60000)
        page.wait_for_timeout(2000)  # ç­‰å¾…é¡µé¢æ¸²æŸ“

    def _close_notification_modal(self, page):
        """æ£€æŸ¥å¹¶å…³é—­å¯èƒ½çš„é€šçŸ¥å¼¹çª—"""
        try:
            logger.info("ğŸ” æ£€æŸ¥æ˜¯å¦æœ‰é€šçŸ¥å¼¹çª—éœ€è¦å…³é—­...")

            # ç­‰å¾…é¡µé¢ç¨³å®š
            page.wait_for_timeout(1000)

            # å¤šç§å¯èƒ½çš„å¼¹çª—å…³é—­æŒ‰é’®é€‰æ‹©å™¨
            close_selectors = [
                # æ‚¨æä¾›çš„å…·ä½“é€‰æ‹©å™¨
                'i.eds-icon.eds-modal__close',
                'i[data-v-ef5019c0][data-v-25a12b69].eds-icon.eds-modal__close',

                # é€šç”¨çš„å¼¹çª—å…³é—­é€‰æ‹©å™¨
                '.eds-modal__close',
                '.modal-close',
                '.close-btn',
                'button[aria-label="Close"]',
                'button[aria-label="å…³é—­"]',
                '.ant-modal-close',
                '.el-dialog__close',

                # SVGå…³é—­å›¾æ ‡
                'svg[viewBox="0 0 16 16"] path[fill-rule="evenodd"]',

                # é€šç”¨å…³é—­æŒ‰é’®æ–‡æœ¬
                'button:has-text("å…³é—­")',
                'button:has-text("å–æ¶ˆ")',
                'button:has-text("ç¨åå†è¯´")',
                'button:has-text("æˆ‘çŸ¥é“äº†")',

                # Xå½¢çŠ¶çš„å…³é—­æŒ‰é’®
                '[class*="close"]:visible',
                '[class*="dismiss"]:visible'
            ]

            modal_closed = False
            for selector in close_selectors:
                try:
                    # æ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨ä¸”å¯è§
                    element = page.locator(selector).first
                    if element.count() > 0 and element.is_visible():
                        logger.info(f"ğŸ¯ å‘ç°é€šçŸ¥å¼¹çª—ï¼Œç‚¹å‡»å…³é—­æŒ‰é’®: {selector}")
                        element.click()
                        page.wait_for_timeout(500)  # ç­‰å¾…å¼¹çª—å…³é—­åŠ¨ç”»
                        modal_closed = True
                        break
                except Exception as e:
                    logger.debug(f"å°è¯•å…³é—­é€‰æ‹©å™¨å¤±è´¥ {selector}: {e}")
                    continue

            if modal_closed:
                logger.info("âœ… é€šçŸ¥å¼¹çª—å·²å…³é—­")
                page.wait_for_timeout(1000)  # ç­‰å¾…é¡µé¢ç¨³å®š
            else:
                logger.debug("ğŸ“ æœªå‘ç°éœ€è¦å…³é—­çš„é€šçŸ¥å¼¹çª—")

        except Exception as e:
            logger.debug(f"æ£€æŸ¥é€šçŸ¥å¼¹çª—å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­åç»­æ“ä½œ

    def _set_weekly_timerange(self, page, start_date: str, end_date: str):
        """è®¾ç½®é¡µé¢ä¸ºæŒ‰å‘¨æ¨¡å¼å¹¶é€‰æ‹©ç›®æ ‡å‘¨åº¦"""
        try:
            # 0. æ‰“å¼€æ—¥æœŸæ§ä»¶
            if not self._open_date_picker(page):
                logger.warning("æœªèƒ½æ‰“å¼€æ—¥æœŸé€‰æ‹©å™¨ï¼Œå°†ç›´æ¥å°è¯•ç‚¹å‡»â€˜æŒ‰å‘¨â€™æ ‡ç­¾")

            # 1. åˆ‡æ¢åˆ°æŒ‰å‘¨æ¨¡å¼
            logger.info("åˆ‡æ¢åˆ°æŒ‰å‘¨æ¨¡å¼...")

            # å°è¯•å¤šç§å¯èƒ½çš„"æŒ‰å‘¨"é€‰æ‹©å™¨ï¼ˆåœ¨å¼¹å±‚å†…ï¼‰
            week_selectors = [
                '.eds-date-shortcut-item:has-text("æŒ‰å‘¨")',
                '.bi-date-shortcuts li:has-text("æŒ‰å‘¨")',
                'text="æŒ‰å‘¨"',
                '[data-testid*="week"]',
                '.time-range-selector [role="radio"]:has-text("å‘¨")',
                '.period-selector button:has-text("å‘¨")',
                'button:has-text("æŒ‰å‘¨")',
                'label:has-text("æŒ‰å‘¨")',
            ]

            week_clicked = False
            for selector in week_selectors:
                try:
                    if page.locator(selector).count() > 0:
                        page.locator(selector).first.click()
                        week_clicked = True
                        logger.info(f"æˆåŠŸç‚¹å‡»æŒ‰å‘¨é€‰æ‹©å™¨: {selector}")
                        break
                except Exception:
                    continue

            if not week_clicked:
                logger.warning("æœªæ‰¾åˆ°æŒ‰å‘¨é€‰æ‹©å™¨ï¼Œå°è¯•ç»§ç»­...")

            page.wait_for_timeout(1500)

            # 2. è®¾ç½®æ—¥æœŸèŒƒå›´ï¼ˆå¦‚æœæœ‰æ—¥æœŸé€‰æ‹©å™¨ï¼‰
            logger.info(f"è®¾ç½®æ—¥æœŸèŒƒå›´: {start_date} ~ {end_date}")

            # å°è¯•è®¾ç½®å¼€å§‹æ—¥æœŸ
            start_selectors = [
                'input[placeholder*="å¼€å§‹"]',
                'input[placeholder*="èµ·å§‹"]',
                'input[name*="start"]',
                '.date-picker input:first-child',
                '.time-range input:first-child',
            ]

            for selector in start_selectors:
                try:
                    if page.locator(selector).count() > 0:
                        page.locator(selector).first.fill(start_date)
                        logger.info(f"è®¾ç½®å¼€å§‹æ—¥æœŸ: {selector}")
                        break
                except Exception:
                    continue

            # å°è¯•è®¾ç½®ç»“æŸæ—¥æœŸ
            end_selectors = [
                'input[placeholder*="ç»“æŸ"]',
                'input[placeholder*="æˆªæ­¢"]',
                'input[name*="end"]',
                '.date-picker input:last-child',
                '.time-range input:last-child',
            ]

            for selector in end_selectors:
                try:
                    if page.locator(selector).count() > 0:
                        page.locator(selector).first.fill(end_date)
                        logger.info(f"è®¾ç½®ç»“æŸæ—¥æœŸ: {selector}")
                        break
                except Exception:
                    continue

            page.wait_for_timeout(1000)

            # 3. ç¡®è®¤/åº”ç”¨è®¾ç½®
            confirm_selectors = [
                'button:has-text("ç¡®å®š")',
                'button:has-text("åº”ç”¨")',
                'button:has-text("æŸ¥è¯¢")',
                '.date-picker button[type="submit"]',
            ]

            for selector in confirm_selectors:
                try:
                    if page.locator(selector).count() > 0:
                        page.locator(selector).first.click()
                        logger.info(f"ç‚¹å‡»ç¡®è®¤æŒ‰é’®: {selector}")
                        break
                except Exception:
                    continue

            page.wait_for_timeout(2000)  # ç­‰å¾…é¡µé¢æ›´æ–°
            logger.info("å‘¨åº¦è®¾ç½®å®Œæˆ")

        except Exception as e:
            logger.error(f"è®¾ç½®å‘¨åº¦å¤±è´¥: {e}")
            raise

    def _capture_time_controls_snapshot(self, page, out_dir: Path, timestamp: str):
        """æ•è·æ—¶é—´æ§ä»¶å¿«ç…§ç”¨äºè¯Šæ–­"""
        try:
            diag_dir = out_dir / ".diag"
            diag_dir.mkdir(parents=True, exist_ok=True)

            # æ•è·æ—¶é—´æ§ä»¶åŒºåŸŸçš„HTML
            time_selectors = [
                '.time-range-selector',
                '.date-picker',
                '.period-selector',
                '[class*="time"]',
                '[class*="date"]',
                '[class*="period"]',
            ]

            snapshot = {
                "timestamp": timestamp,
                "url": page.url,
                "time_controls": {}
            }

            for i, selector in enumerate(time_selectors):
                try:
                    elements = page.locator(selector)
                    if elements.count() > 0:
                        element = elements.first
                        snapshot["time_controls"][f"selector_{i}"] = {
                            "selector": selector,
                            "count": elements.count(),
                            "html": element.inner_html(),
                            "text": element.inner_text(),
                            "outer_html": element.evaluate("el => el.outerHTML")
                        }
                except Exception as e:
                    snapshot["time_controls"][f"selector_{i}_error"] = str(e)

            # ä¿å­˜å¿«ç…§
            snapshot_file = diag_dir / f"{timestamp}_time_controls.json"
            snapshot_file.write_text(json.dumps(snapshot, ensure_ascii=False, indent=2), encoding="utf-8")
            logger.info(f"æ—¶é—´æ§ä»¶å¿«ç…§å·²ä¿å­˜: {snapshot_file}")

        except Exception as e:
            logger.warning(f"æ•è·æ—¶é—´æ§ä»¶å¿«ç…§å¤±è´¥: {e}")

    def _enhanced_diagnostics(self, page: "Page", diag_dir: Path) -> None:
        """å¢å¼ºè¯Šæ–­ï¼šä¿å­˜é¡µé¢HTMLã€æˆªå›¾ã€æ—¶é—´æ§ä»¶ã€æŒ‡æ ‡å‹¾é€‰é¡¹ã€ç½‘ç»œè¯·æ±‚ç­‰"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # 1. å…¨é¡µHTMLå’Œæˆªå›¾
            html_file = diag_dir / f"{timestamp}_page.html"
            screenshot_file = diag_dir / f"{timestamp}_page.png"

            html_file.write_text(page.content(), encoding="utf-8")
            page.screenshot(path=str(screenshot_file), full_page=True)
            logger.info(f"é¡µé¢HTMLå’Œæˆªå›¾å·²ä¿å­˜: {html_file}, {screenshot_file}")

            # 2. æ—¶é—´æ§ä»¶è¯¦ç»†ä¿¡æ¯
            time_info = self._extract_time_controls(page)
            time_file = diag_dir / f"{timestamp}_time_controls_enhanced.json"
            time_file.write_text(json.dumps(time_info, ensure_ascii=False, indent=2), encoding="utf-8")
            logger.info(f"æ—¶é—´æ§ä»¶è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜: {time_file}")

            # 3. æŒ‡æ ‡å‹¾é€‰é¡¹æ¸…å•
            metrics_info = self._extract_metrics_checkboxes(page)
            metrics_file = diag_dir / f"{timestamp}_metrics_checkboxes.json"
            metrics_file.write_text(json.dumps(metrics_info, ensure_ascii=False, indent=2), encoding="utf-8")
            logger.info(f"æŒ‡æ ‡å‹¾é€‰é¡¹æ¸…å•å·²ä¿å­˜: {metrics_file}")

            # 4. å¯è®¿é—®æ€§æ ‘å¿«ç…§
            try:
                accessibility_tree = page.accessibility.snapshot()
                accessibility_file = diag_dir / f"{timestamp}_accessibility.json"
                accessibility_file.write_text(json.dumps(accessibility_tree, ensure_ascii=False, indent=2), encoding="utf-8")
                logger.info(f"å¯è®¿é—®æ€§æ ‘å·²ä¿å­˜: {accessibility_file}")
            except Exception as e:
                logger.warning(f"å¯è®¿é—®æ€§æ ‘å¿«ç…§å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"å¢å¼ºè¯Šæ–­å¤±è´¥: {e}")

    def _extract_time_controls(self, page: "Page") -> Dict:
        """æå–æ—¶é—´æ§ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
        time_info = {
            "timestamp": datetime.now().isoformat(),
            "url": page.url,
            "time_selectors": {}
        }

        # å¸¸è§çš„æ—¶é—´é€‰æ‹©å™¨
        selectors = [
            'span.value',  # ä½ æä¾›çš„æ—¶é—´æ˜¾ç¤ºå…ƒç´ 
            '[data-v-2aefd622].value',
            '.date-range-picker span',
            '.time-range span',
            '.date-picker-input',
            'input[placeholder*="æ—¶é—´"]',
            'input[placeholder*="æ—¥æœŸ"]',
        ]

        for selector in selectors:
            try:
                elements = page.locator(selector).all()
                for i, element in enumerate(elements):
                    if element.is_visible():
                        info = {
                            "selector": selector,
                            "index": i,
                            "text_content": element.text_content(),
                            "inner_text": element.inner_text(),
                            "outer_html": element.get_attribute("outerHTML"),
                            "bounding_box": element.bounding_box(),
                            "attributes": {}
                        }

                        # è·å–æ‰€æœ‰å±æ€§
                        try:
                            attrs = page.evaluate("""
                                (element) => {
                                    const attrs = {};
                                    for (let attr of element.attributes) {
                                        attrs[attr.name] = attr.value;
                                    }
                                    return attrs;
                                }
                            """, element.element_handle())
                            info["attributes"] = attrs
                        except:
                            pass

                        key = f"{selector}_{i}"
                        time_info["time_selectors"][key] = info

            except Exception as e:
                logger.debug(f"æ—¶é—´é€‰æ‹©å™¨ {selector} æå–å¤±è´¥: {e}")

        return time_info

    def _extract_metrics_checkboxes(self, page: "Page") -> Dict:
        """æå–æŒ‡æ ‡å‹¾é€‰é¡¹çš„è¯¦ç»†ä¿¡æ¯"""
        metrics_info = {
            "timestamp": datetime.now().isoformat(),
            "url": page.url,
            "checkboxes": {},
            "labels": {},
            "multi_selector_items": {},
            "table_headers": []
        }

        try:
            # æ–¹æ³•1: é€šè¿‡checkboxè§’è‰²æŸ¥æ‰¾
            checkboxes = page.get_by_role("checkbox").all()
            for i, checkbox in enumerate(checkboxes):
                if checkbox.is_visible():
                    try:
                        info = {
                            "index": i,
                            "checked": checkbox.is_checked(),
                            "text": checkbox.text_content(),
                            "inner_text": checkbox.inner_text(),
                            "bounding_box": checkbox.bounding_box(),
                            "locator_info": str(checkbox)
                        }

                        # å°è¯•è·å–å…³è”çš„labelæ–‡æœ¬
                        try:
                            # æŸ¥æ‰¾çˆ¶çº§æˆ–å…„å¼Ÿå…ƒç´ ä¸­çš„æ–‡æœ¬
                            parent = checkbox.locator("..")
                            parent_text = parent.text_content()
                            if parent_text and parent_text.strip():
                                info["parent_text"] = parent_text.strip()
                        except:
                            pass

                        metrics_info["checkboxes"][f"checkbox_{i}"] = info
                    except Exception as e:
                        logger.debug(f"checkbox {i} ä¿¡æ¯æå–å¤±è´¥: {e}")

        except Exception as e:
            logger.debug(f"checkboxè§’è‰²æŸ¥æ‰¾å¤±è´¥: {e}")

        try:
            # æ–¹æ³•2: é€šè¿‡input[type="checkbox"]æŸ¥æ‰¾
            checkbox_inputs = page.locator('input[type="checkbox"]').all()
            for i, checkbox in enumerate(checkbox_inputs):
                if checkbox.is_visible():
                    try:
                        info = {
                            "index": i,
                            "checked": checkbox.is_checked(),
                            "value": checkbox.get_attribute("value"),
                            "name": checkbox.get_attribute("name"),
                            "id": checkbox.get_attribute("id"),
                            "bounding_box": checkbox.bounding_box()
                        }

                        # æŸ¥æ‰¾å…³è”çš„label
                        checkbox_id = checkbox.get_attribute("id")
                        if checkbox_id:
                            try:
                                label = page.locator(f'label[for="{checkbox_id}"]')
                                if label.is_visible():
                                    info["label_text"] = label.text_content()
                            except:
                                pass

                        metrics_info["labels"][f"input_checkbox_{i}"] = info
                    except Exception as e:
                        logger.debug(f"input checkbox {i} ä¿¡æ¯æå–å¤±è´¥: {e}")

        except Exception as e:
            logger.debug(f"input checkboxæŸ¥æ‰¾å¤±è´¥: {e}")

        # æ–¹æ³•3: ä¸“é—¨é‡‡é›† multi-selector æŒ‡æ ‡é¡¹ï¼ˆé’ˆå¯¹ Shopee è‡ªå®šä¹‰ç»„ä»¶ï¼‰
        try:
            multi_items = page.locator('li.multi-selector__item').all()
            for i, item in enumerate(multi_items):
                if item.is_visible():
                    try:
                        # è·å–æ ‡é¢˜æ–‡æœ¬
                        title_element = item.locator('.title').first
                        title_text = title_element.text_content() if title_element.count() > 0 else ""

                        # è·å– class å±æ€§ï¼Œåˆ¤æ–­æ˜¯å¦é€‰ä¸­
                        class_attr = item.get_attribute("class") or ""
                        is_selected = "selected" in class_attr

                        info = {
                            "index": i,
                            "title": title_text.strip() if title_text else "",
                            "class": class_attr,
                            "selected": is_selected,
                            "bounding_box": item.bounding_box(),
                            "outer_html": item.evaluate("el => el.outerHTML")[:500] if item.count() > 0 else ""
                        }

                        metrics_info["multi_selector_items"][f"item_{i}"] = info

                    except Exception as e:
                        logger.debug(f"multi-selector item {i} ä¿¡æ¯æå–å¤±è´¥: {e}")
        except Exception as e:
            logger.debug(f"multi-selector æŸ¥æ‰¾å¤±è´¥: {e}")
        # æ–¹æ³•4: é‡‡é›†è¡¨æ ¼è¡¨å¤´ï¼ˆä½œä¸ºå·²é€‰æŒ‡æ ‡çš„æ›¿ä»£ä¿¡å·ï¼‰
        try:
            header_cells = page.locator('table thead th .title, table thead th [class*="title"]').all()
            headers = []
            for cell in header_cells:
                try:
                    text = (cell.text_content() or '').strip()
                    if text:
                        headers.append(text)
                except:
                    pass
            metrics_info["table_headers"] = headers
        except Exception as e:
            logger.debug(f"è¡¨å¤´æå–å¤±è´¥: {e}")

        return metrics_info

    def _read_week_from_ui(self, page: "Page") -> Tuple[Optional[int], Optional[int]]:
        """ä»é¡µé¢UIè¯»å–å‘¨åº¦æ—¶é—´èŒƒå›´ï¼Œè¿”å›æ¯«ç§’æ—¶é—´æˆ³"""
        try:
            # æŸ¥æ‰¾æ—¶é—´æ˜¾ç¤ºå…ƒç´ 
            time_selectors = [
                'span.value',
                '[data-v-2aefd622].value',
                '.date-range-picker span',
                '.time-range span'
            ]

            date_text = None
            for selector in time_selectors:
                try:
                    element = page.locator(selector).first
                    if element.is_visible():
                        text = element.text_content()
                        # æ”¯æŒèŒƒå›´æ ¼å¼å’Œå•æ—¥æ ¼å¼
                        if text and 'GMT' in text and (('-' in text) or ('/' in text) or ('-' in text)):
                            date_text = text
                            logger.info(f"ä»UIè¯»å–åˆ°æ—¶é—´èŒƒå›´: {date_text}")
                            break
                except:
                    continue

            if not date_text:
                logger.warning("æœªèƒ½ä»UIè¯»å–åˆ°æ—¶é—´èŒƒå›´")
                return None, None

            # è§£ææ ¼å¼: æ”¯æŒå¤šç§æ ¼å¼
            # 1. èŒƒå›´æ ¼å¼: "11-08-2025 - 17-08-2025 (GMT+08)" æˆ– "23/08/2025 - 29/08/2025 (GMT-03)"
            # 2. å•æ—¥æ ¼å¼: "29/08/2025 (GMT-03)" æˆ– "29-08-2025 (GMT+08)"
            patterns = [
                # èŒƒå›´æ ¼å¼
                (r'(\d{2}-\d{2}-\d{4})\s*-\s*(\d{2}-\d{2}-\d{4})\s*\(GMT([+-]\d{2})\)', "%d-%m-%Y", "range"),
                (r'(\d{2}/\d{2}/\d{4})\s*-\s*(\d{2}/\d{2}/\d{4})\s*\(GMT([+-]\d{2})\)', "%d/%m/%Y", "range"),
                # å•æ—¥æ ¼å¼
                (r'(\d{2}/\d{2}/\d{4})\s*\(GMT([+-]\d{2})\)', "%d/%m/%Y", "single"),
                (r'(\d{2}-\d{2}-\d{4})\s*\(GMT([+-]\d{2})\)', "%d-%m-%Y", "single")
            ]

            match = None
            date_format = None
            pattern_type = None
            for pattern, fmt, ptype in patterns:
                match = re.search(pattern, date_text)
                if match:
                    date_format = fmt
                    pattern_type = ptype
                    break

            if not match:
                logger.warning(f"æ—¶é—´æ ¼å¼ä¸åŒ¹é…: {date_text}")
                return None, None

            # æ ¹æ®æ¨¡å¼ç±»å‹å¤„ç†åŒ¹é…ç»“æœ
            if pattern_type == "range":
                start_str, end_str, tz_offset = match.groups()
            else:  # single
                start_str, tz_offset = match.groups()
                end_str = start_str  # å•æ—¥æ ¼å¼ï¼Œå¼€å§‹å’Œç»“æŸæ˜¯åŒä¸€å¤©

            # è§£ææ—¥æœŸï¼Œä½¿ç”¨åŒ¹é…çš„æ ¼å¼
            start_date = datetime.strptime(start_str, date_format)
            end_date = datetime.strptime(end_str, date_format)

            # å¹´ä»½éªŒè¯ï¼šç¡®ä¿å¹´ä»½åˆç†ï¼ˆä¸ä¿®æ­£ï¼Œåªè®°å½•ï¼‰
            current_year = datetime.now().year
            if abs(start_date.year - current_year) > 1:
                logger.warning(f"æ£€æµ‹åˆ°å¼‚å¸¸å¹´ä»½ {start_date.year}ï¼Œå½“å‰å¹´ä»½ {current_year}")
            else:
                logger.debug(f"å¹´ä»½æ­£å¸¸: {start_date.year}")

            # åˆ›å»ºæ—¶åŒºå¯¹è±¡ï¼Œæ”¯æŒæ­£è´Ÿæ—¶åŒºåç§» GMT+08 æˆ– GMT-03
            from datetime import timezone, timedelta
            tz_hours = int(tz_offset)  # tz_offset å·²ç»åŒ…å«æ­£è´Ÿå·
            tz = timezone(timedelta(hours=tz_hours))

            # è®¾ç½®ä¸ºå½“å¤©00:00:00ï¼Œå¹¶åº”ç”¨æ—¶åŒº
            start_dt = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
            start_dt = start_dt.replace(tzinfo=tz)

            # ç»“æŸæ—¶é—´è®¾ä¸ºä¸‹ä¸€å¤©00:00:00ï¼ˆå³å¼€åŒºé—´ï¼‰
            end_dt = end_date.replace(hour=0, minute=0, second=0, microsecond=0)
            end_dt = end_dt + timedelta(days=1)  # ä¸‹ä¸€å¤©
            end_dt = end_dt.replace(tzinfo=tz)

            # è½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³
            start_ts_ms = int(start_dt.timestamp() * 1000)
            end_ts_ms = int(end_dt.timestamp() * 1000)

            logger.info(f"è§£ææ—¶é—´èŒƒå›´: {start_dt} ~ {end_dt}")
            logger.info(f"æ¯«ç§’æ—¶é—´æˆ³: start_ts={start_ts_ms}, end_ts={end_ts_ms}")

            return start_ts_ms, end_ts_ms

        except Exception as e:
            logger.error(f"ä»UIè¯»å–æ—¶é—´èŒƒå›´å¤±è´¥: {e}")
            return None, None

    def _select_metrics(self, page: "Page", metrics: List[str]) -> None:
        """æŒ‡æ ‡å‹¾é€‰å·²ç¦ç”¨ï¼šå¯¼å‡ºè·å–å…¨é‡æ•°æ®"""
        logger.info("ğŸ“Š æŒ‡æ ‡å‹¾é€‰å·²ç¦ç”¨ï¼šå¯¼å‡ºè·å–å…¨é‡æ•°æ®")
        return

        # ç¡®ä¿â€œé€‰æ‹©æŒ‡æ ‡â€åŒºåŸŸå·²æ‰“å¼€å¹¶å¯è§
        try:
            self._open_metric_selector(page)
        except Exception:
            pass
        page.wait_for_timeout(500)

        for metric in metrics:
            try:
                # å°†æœŸæœ›æŒ‡æ ‡åæ˜ å°„ä¸ºé¡µé¢ä¸Šçš„çœŸå®æ ‡é¢˜ï¼ˆåŒä¹‰è¯/ç›¸ä¼¼åº¦å®¹é”™ï¼‰
                target_text = self._match_metric_title(page, metric) or metric
                if target_text != metric:
                    logger.info(f"æŒ‡æ ‡åæ˜ å°„: '{metric}' -> '{target_text}'")

                # å°è¯•æ»šåŠ¨åˆ°æŒ‡æ ‡åŒºåŸŸï¼Œé¿å…å…ƒç´ ä¸å¯è§
                try:
                    page.locator('li.multi-selector__item').first.scroll_into_view_if_needed(timeout=1000)
                except Exception:
                    pass

                # æ–¹æ³•1: é€šè¿‡ has= å­å®šä½å™¨åŒ¹é… .title æ–‡æœ¬ï¼ˆPlaywright æ­£ç¡®ç”¨æ³•ï¼‰
                try:
                    items = page.locator('li.multi-selector__item')
                    item = items.filter(has=page.locator('.title', has_text=target_text)).first

                    if item.count() > 0 and item.is_visible():
                        class_attr = item.get_attribute("class") or ""
                        if "selected" not in class_attr:
                            checkbox_area = item.locator('.checkbox').first
                            if checkbox_area.count() > 0:
                                checkbox_area.click()
                            else:
                                item.click()
                            # ç­‰å¾…é€‰ä¸­çŠ¶æ€æ›´æ–°ï¼ˆæœ€å¤š3ç§’ï¼‰
                            try:
                                page.wait_for_function(
                                    "el => el && el.classList.contains('selected')",
                                    arg=item.element_handle(),
                                    timeout=3000,
                                )
                                logger.info(f"âœ“ å·²å‹¾é€‰æŒ‡æ ‡: {target_text}")
                            except Exception:
                                logger.info(f"âœ“ ç‚¹å‡»æŒ‡æ ‡: {target_text} (çŠ¶æ€å¾…ç¡®è®¤)")
                        else:
                            logger.info(f"âœ“ æŒ‡æ ‡å·²å‹¾é€‰: {target_text}")
                        continue
                except Exception as e:
                    logger.debug(f"multi-selector æ–¹æ³•å¤±è´¥ {metric}: {e}")

                # æ–¹æ³•2: æ¨¡ç³Šæ–‡æœ¬åŒ¹é… + ç¥–å…ˆå®¹å™¨ç‚¹å‡» + ç­‰å¾…
                try:
                    title_locator = page.locator('.title').filter(has_text=re.compile(re.escape(target_text), re.IGNORECASE))
                    if title_locator.count() > 0:
                        parent_li = title_locator.first.locator('xpath=ancestor::li[contains(@class,"multi-selector__item")][1]')
                        if parent_li.count() > 0 and parent_li.is_visible():
                            class_attr = parent_li.get_attribute("class") or ""
                            if "selected" not in class_attr:
                                parent_li.click()
                                try:
                                    page.wait_for_function(
                                        "el => el && el.classList.contains('selected')",
                                        arg=parent_li.element_handle(),
                                        timeout=3000,
                                    )
                                except Exception:
                                    pass
                                logger.info(f"âœ“ é€šè¿‡æ¨¡ç³ŠåŒ¹é…å‹¾é€‰: {target_text}")
                            else:
                                logger.info(f"âœ“ æ¨¡ç³ŠåŒ¹é…æŒ‡æ ‡å·²å‹¾é€‰: {target_text}")
                            continue
                except Exception as e:
                    logger.debug(f"æ¨¡ç³ŠåŒ¹é…æ–¹æ³•å¤±è´¥ {metric}: {e}")

                # æ–¹æ³•3: é€šç”¨æ–‡æœ¬ç‚¹å‡» + ç¥–å…ˆå®¹å™¨
                try:
                    label = page.get_by_text(target_text, exact=False).first
                    if label and label.is_visible():
                        container = label.locator("xpath=ancestor::*[self::li or self::label or self::div][contains(@class, 'selector') or contains(@class, 'item')][1]")
                        if container.count() > 0:
                            container.scroll_into_view_if_needed(timeout=1000)
                            container.click()
                            logger.info(f"âœ“ é€šè¿‡æ–‡æœ¬å®¹å™¨ç‚¹å‡»: {target_text}")
                            continue
                        label.click()
                        logger.info(f"âœ“ é€šè¿‡æ–‡æœ¬ç‚¹å‡»: {target_text}")
                        continue
                except Exception as e:
                    logger.debug(f"æ–‡æœ¬ç‚¹å‡»æ–¹æ³•å¤±è´¥ {metric}: {e}")

            except Exception as e:
                logger.warning(f"âš  å‹¾é€‰æŒ‡æ ‡å¤±è´¥ {metric}: {e}")

    def _confirm_metrics_selection(self, page: "Page") -> None:
        """åœ¨æŒ‡æ ‡é€‰æ‹©é¢æ¿å†…ç‚¹å‡»â€œç¡®å®š/å®Œæˆ/åº”ç”¨â€ä¹‹ç±»çš„æŒ‰é’®ï¼Œç¡®ä¿å‹¾é€‰ç”Ÿæ•ˆã€‚"""
        selectors = [
            'button:has-text("ç¡®å®š")',
            'button:has-text("å®Œæˆ")',
            'button:has-text("åº”ç”¨")',
            'button:has-text("ä¿å­˜")',
            '.el-dialog .el-button--primary',
            '.ant-modal .ant-btn-primary',
        ]
        for sel in selectors:
            try:
                btn = page.locator(sel)
                if btn.count() > 0 and btn.first.is_visible():
                    btn.first.click()
                    logger.info(f"ç‚¹å‡»æŒ‡æ ‡é¢æ¿ç¡®è®¤æŒ‰é’®: {sel}")
                    page.wait_for_timeout(500)
                    return
            except Exception:
                continue
        # å¦‚æœæ²¡æœ‰ç¡®è®¤æŒ‰é’®ï¼Œå°è¯•ç‚¹å‡»é¢æ¿å¤–åŒºåŸŸå…³é—­
        try:
            page.mouse.click(10, 10)
        except Exception:
            pass



    def _normalize_text(self, s: str) -> str:
        """è§„èŒƒåŒ–ä¸­æ–‡æŒ‡æ ‡æ–‡æ¡ˆï¼šå»ç©ºæ ¼ã€ç»Ÿä¸€æ‹¬å·ã€å»æ ‡ç‚¹ã€è½¬å°å†™ã€‚"""
        s = (s or "").strip()
        s = s.replace("ï¼ˆ", "(").replace("ï¼‰", ")")
        s = re.sub(r"\s+", "", s)
        s = re.sub(r"[^0-9A-Za-z\u4e00-\u9fff]", "", s)
        return s.lower()

    def _match_metric_title(self, page, target: str) -> Optional[str]:
        """åœ¨é¡µé¢çš„ multi-selector æ ‡é¢˜ä¸­ä¸ºç›®æ ‡è¯å¯»æ‰¾æœ€ä¼˜åŒ¹é…ï¼ˆè§„èŒƒåŒ– + åŒä¹‰è¯ + ç›¸ä¼¼åº¦ï¼‰ã€‚"""
        try:
            import difflib
        except Exception:
            difflib = None

        synonyms: Dict[str, List[str]] = {
            "å•†å“é¡µè®¿é—®é‡": ["å•†å“é¡µé¢è®¿é—®é‡", "å•†å“è®¿é—®é‡", "å•†å“é¡µé¢è®¿é—®äººæ•°", "å•†å“é¡µè®¿é—®äººæ•°"],
            "é”€å”®é¢": ["é”€å”®é¢ï¼ˆå·²ä»˜æ¬¾è®¢å•ï¼‰", "GMV", "é”€å”®é¢(å•†å“)", "æ€»é”€å”®é¢", "é”€å”®é¢(å·²ä»˜æ¬¾è®¢å•)", "é”€å”®é¢(å·²ä»˜æ¬¾)", "é”€å”®é¢-å·²ä»˜æ¬¾"],
            "é”€é‡": ["é”€é‡", "é”€å”®é‡", "ä»¶æ•°ï¼ˆå·²ä»˜æ¬¾è®¢å•ï¼‰", "è®¢å•ä»¶æ•°", "å·²ä»˜æ¬¾ä»¶æ•°", "æˆäº¤ä»¶æ•°"],
            "åŠ è´­é‡": ["åŠ è´­é‡", "åŠ å…¥è´­ç‰©è½¦æ•°", "ä»¶æ•° (åŠ å…¥è´­ç‰©è½¦ï¼‰", "åŠ å…¥è´­ç‰©è½¦ä»¶æ•°", "åŠ è´­ä»¶æ•°"],
            "ç‚¹å‡»ç‡": ["ç‚¹å‡»ç‡", "CTR", "ç‚¹å‡»ç‡%"],
            "è½¬åŒ–ç‡": ["è½¬åŒ–ç‡", "CVR", "è½¬åŒ–ç‡%"],
            "è®¢å•ä¹°å®¶æ•°": ["è®¢å•ä¹°å®¶æ•°", "ä¹°å®¶æ•°ï¼ˆå·²ä»˜æ¬¾è®¢å•ï¼‰", "ä¸‹å•ä¹°å®¶æ•°", "å·²ä»˜æ¬¾ä¹°å®¶æ•°"],
            "æ›å…‰é‡": ["æ›å…‰é‡", "å±•ç°é‡", "æ›å…‰äººæ•°", "æœç´¢æ›å…‰é‡", "æœç´¢æ›å…‰"],
        }

        target_norm = self._normalize_text(target)

        titles_locator = page.locator('li.multi-selector__item .title')
        n = titles_locator.count()
        titles: List[str] = []
        titles_norm: Dict[str, str] = {}
        for i in range(min(n, 200)):
            try:
                t = (titles_locator.nth(i).inner_text() or '').strip()
                if t:
                    titles.append(t)
                    titles_norm[t] = self._normalize_text(t)
            except Exception:
                continue

        if not titles:
            logger.debug("æœªåœ¨é¡µé¢ä¸Šå‘ç° multi-selector æ ‡é¢˜åˆ—è¡¨")
            return None

        for t in titles:
            tn = titles_norm.get(t, "")
            if target_norm == tn or (target_norm and target_norm in tn):
                return t

        for alt in synonyms.get(target, []):
            an = self._normalize_text(alt)
            for t in titles:
                tn = titles_norm.get(t, "")
                if an == tn or (an and an in tn):
                    return t

        if difflib is not None:
            best_text, best_ratio = None, 0.0
            for t in titles:
                r = difflib.SequenceMatcher(None, target_norm, titles_norm.get(t, "")).ratio()
                if r > best_ratio:
                    best_text, best_ratio = t, r
            if best_text and best_ratio >= 0.6:
                logger.info(f"ä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é… '{target}' -> '{best_text}' (ratio={best_ratio:.2f})")
                return best_text

        logger.debug(f"æœªæ‰¾åˆ°ä¸ '{target}' åŒ¹é…çš„æ ‡é¢˜ï¼Œå€™é€‰æœ‰: {titles[:10]}")
        return None


    def inspect_date_picker(self, page: "Page") -> Dict:
        """æ—¥æœŸæ§ä»¶æ¢æµ‹å™¨ï¼šåˆ†æé¡µé¢ä¸Šçš„æ—¥æœŸé€‰æ‹©æ§ä»¶ç±»å‹ä¸çŠ¶æ€"""
        try:
            logger.info("ğŸ” å¼€å§‹æ—¥æœŸæ§ä»¶æ¢æµ‹...")

            # æ³¨å…¥æ¢æµ‹è„šæœ¬
            script = """
            () => {
                const result = {
                    hasShortcuts: false,
                    hasInputs: false,
                    hasCalendar: false,
                    shortcuts: [],
                    activeShortcut: null,
                    selectedRange: null,
                    controlType: 'unknown'
                };

                // 1. æ£€æµ‹å¿«æ·æŒ‰é’®
                const shortcuts = document.querySelectorAll('.eds-date-shortcut-item, .bi-date-shortcuts li');
                if (shortcuts.length > 0) {
                    result.hasShortcuts = true;
                    shortcuts.forEach(item => {
                        const text = item.querySelector('.eds-date-shortcut-item__text')?.textContent?.trim() ||
                                   item.textContent?.trim();
                        if (text) {
                            result.shortcuts.push(text);
                            if (item.classList.contains('active')) {
                                result.activeShortcut = text;
                            }
                        }
                    });
                }

                // 2. æ£€æµ‹è¾“å…¥æ¡†
                const inputs = document.querySelectorAll('.eds-date-picker input[type="text"], .bi-date-picker input[type="text"]');
                result.hasInputs = inputs.length > 0;

                // 3. æ£€æµ‹æ—¥å†è¡¨æ ¼
                const calendar = document.querySelector('.eds-date-table, .eds-month-table, .eds-year-table');
                result.hasCalendar = !!calendar;

                // 4. æ£€æµ‹é€‰ä¸­èŒƒå›´ï¼ˆå‘¨é€‰æ‹©ï¼‰
                const selectedCells = document.querySelectorAll('.week-selection, .range-start, .range-end, .selected');
                if (selectedCells.length > 0) {
                    const startCell = document.querySelector('.range-start, .selected');
                    const endCell = document.querySelector('.range-end');
                    if (startCell) {
                        const startText = startCell.textContent?.trim();
                        const endText = endCell?.textContent?.trim() || startText;
                        result.selectedRange = `${startText} ~ ${endText}`;
                    }
                }

                // 5. åˆ¤æ–­æ§ä»¶ç±»å‹
                if (result.hasShortcuts && result.hasCalendar && !result.hasInputs) {
                    result.controlType = 'shortcut_calendar';
                } else if (result.hasShortcuts && result.hasInputs) {
                    result.controlType = 'hybrid';
                } else if (result.hasInputs && !result.hasShortcuts) {
                    result.controlType = 'input_only';
                } else if (result.hasShortcuts && !result.hasCalendar) {
                    result.controlType = 'shortcut_only';
                }

                return result;
            }
            """

            result = page.evaluate(script)

            # æ ¼å¼åŒ–è¾“å‡º
            logger.info("ğŸ“Š æ—¥æœŸæ§ä»¶æ¢æµ‹ç»“æœ:")
            logger.info(f"  æ§ä»¶ç±»å‹: {result['controlType']}")
            logger.info(f"  å¿«æ·æŒ‰é’®: {'âœ“' if result['hasShortcuts'] else 'âœ—'}")
            logger.info(f"  è¾“å…¥æ¡†: {'âœ“' if result['hasInputs'] else 'âœ—'}")
            logger.info(f"  æ—¥å†è¡¨æ ¼: {'âœ“' if result['hasCalendar'] else 'âœ—'}")

            if result['shortcuts']:
                logger.info(f"  å¯ç”¨å¿«æ·é¡¹: {result['shortcuts']}")
            if result['activeShortcut']:
                logger.info(f"  å½“å‰æ¿€æ´»: {result['activeShortcut']}")
            if result['selectedRange']:
                logger.info(f"  é€‰ä¸­èŒƒå›´: {result['selectedRange']}")

            return result

        except Exception as e:
            logger.error(f"æ—¥æœŸæ§ä»¶æ¢æµ‹å¤±è´¥: {e}")
            return {"controlType": "error", "error": str(e)}

    def install_date_picker_monitor(self, page_or_frame) -> None:
        """å®‰è£…æ—¥æœŸæ§ä»¶äº¤äº’ç›‘å¬å™¨ï¼ˆå¢å¼ºç‰ˆï¼šå½•åˆ¶å¤åˆ»ç”¨ï¼‰

        Args:
            page_or_frame: Pageæˆ–Frameå¯¹è±¡ï¼Œæ”¯æŒä¸»é¡µé¢å’Œiframe
        """
        try:
            script = """
            () => {
                // é¿å…é‡å¤å®‰è£…
                if (window.__date_picker_monitor_installed__) return;
                window.__date_picker_monitor_installed__ = true;
                window.__date_picker_events__ = [];

                // ç”Ÿæˆå…ƒç´ çš„å¤šé‡å®šä½ç‰¹å¾
                function generateSelectors(element) {
                    const selectors = [];

                    // 1. æ–‡æœ¬å†…å®¹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                    const text = element.textContent?.trim();
                    if (text && text.length < 50) {
                        selectors.push({type: 'text', value: text, priority: 1});
                    }

                    // 2. CSS é€‰æ‹©å™¨ç»„åˆ
                    const tagName = element.tagName.toLowerCase();
                    const classes = Array.from(element.classList);
                    if (classes.length > 0) {
                        selectors.push({type: 'css', value: `${tagName}.${classes.join('.')}`, priority: 2});
                        // å…³é”®ç±»åå•ç‹¬æå–
                        const keyClasses = classes.filter(c =>
                            c.includes('date') || c.includes('time') || c.includes('shortcut') ||
                            c.includes('picker') || c.includes('input') || c.includes('value')
                        );
                        if (keyClasses.length > 0) {
                            selectors.push({type: 'css', value: `.${keyClasses.join('.')}`, priority: 1.5});
                        }
                    }

                    // 3. å±æ€§é€‰æ‹©å™¨
                    for (const attr of element.attributes) {
                        if (attr.name.startsWith('data-') || attr.name === 'role') {
                            selectors.push({type: 'css', value: `[${attr.name}="${attr.value}"]`, priority: 3});
                        }
                    }

                    // 4. ç»“æ„åŒ–å®šä½ï¼ˆç›¸å¯¹äºå®¹å™¨ï¼‰
                    const dateContainer = element.closest('.bi-date-input, .eds-date-picker, .bi-date-picker');
                    if (dateContainer) {
                        const containerClasses = Array.from(dateContainer.classList);
                        if (containerClasses.length > 0) {
                            selectors.push({
                                type: 'css',
                                value: `.${containerClasses.join('.')} ${tagName}${classes.length ? '.' + classes.join('.') : ''}`,
                                priority: 2.5
                            });
                        }
                    }

                    // 5. å…œåº•ï¼šæ ‡ç­¾+ä½ç½®
                    const siblings = Array.from(element.parentElement?.children || []);
                    const index = siblings.indexOf(element);
                    if (index >= 0) {
                        selectors.push({type: 'css', value: `${tagName}:nth-child(${index + 1})`, priority: 4});
                    }

                    return selectors.sort((a, b) => a.priority - b.priority);
                }

                // ç›‘å¬ç‚¹å‡»äº‹ä»¶
                document.addEventListener('click', (e) => {
                    const target = e.target;
                    let eventType = 'unknown_click';
                    let details = {
                        selectors: generateSelectors(target),
                        boundingBox: target.getBoundingClientRect(),
                        timestamp: Date.now()
                    };

                    // åˆ¤æ–­ç‚¹å‡»çš„å…ƒç´ ç±»å‹
                    if (target.closest('.eds-date-shortcut-item, .bi-date-shortcuts li')) {
                        eventType = 'shortcut_click';
                        details.text = target.textContent?.trim();
                        details.element = target.closest('.eds-date-shortcut-item, .bi-date-shortcuts li').className;
                        details.action = 'select_shortcut';
                    } else if (target.closest('.bi-date-input, .eds-date-picker')) {
                        eventType = 'date_container_click';
                        details.text = target.textContent?.trim();
                        details.classes = target.className;
                        details.action = 'open_picker';
                    } else if (target.closest('.eds-date-table__cell')) {
                        eventType = 'calendar_cell_click';
                        details.text = target.textContent?.trim();
                        details.classes = target.className;
                        details.action = 'select_date';
                    } else if (target.closest('input[type="text"]')) {
                        eventType = 'input_click';
                        details.value = target.value;
                        details.action = 'focus_input';
                    }

                    if (eventType !== 'unknown_click') {
                        window.__date_picker_events__.push({
                            type: eventType,
                            timestamp: Date.now(),
                            details: details
                        });
                        console.log('[DatePicker Recorder]', eventType, details);
                    }
                }, true);

                console.log('[DatePicker Recorder] å¢å¼ºç›‘å¬å™¨å·²å®‰è£…');
            }
            """
            page_or_frame.evaluate(script)
            # è·å–é¡µé¢/frameçš„URLç”¨äºæ—¥å¿—
            try:
                url = page_or_frame.url
                frame_info = f" (URL: {url[:50]}...)" if len(url) > 50 else f" (URL: {url})"
            except:
                frame_info = ""
            logger.info(f"ğŸ¯ æ—¥æœŸæ§ä»¶å½•åˆ¶ç›‘å¬å™¨å·²å®‰è£…{frame_info}")

        except Exception as e:
            logger.error(f"å®‰è£…æ—¥æœŸæ§ä»¶ç›‘å¬å™¨å¤±è´¥: {e}")

    def _install_recording_monitors(self, page: "Page") -> None:
        """ä¸ºå½•åˆ¶æ¨¡å¼å®‰è£…å…¨å±€ç›‘å¬å™¨ï¼ˆæ”¯æŒiframeï¼‰"""
        try:
            logger.info("ğŸ¯ å®‰è£…å½•åˆ¶æ¨¡å¼ç›‘å¬å™¨ï¼ˆæ”¯æŒiframeï¼‰...")

            # ä¸ºä¸»é¡µé¢å®‰è£…ç›‘å¬å™¨
            self.install_date_picker_monitor(page)

            # ä¸ºæ‰€æœ‰ç°æœ‰frameså®‰è£…ç›‘å¬å™¨
            for frame in page.frames:
                try:
                    if frame != page.main_frame:
                        self.install_date_picker_monitor(frame)
                        logger.debug(f"å·²ä¸ºframeå®‰è£…ç›‘å¬å™¨: {frame.url}")
                except Exception as e:
                    logger.debug(f"ä¸ºframeå®‰è£…ç›‘å¬å™¨å¤±è´¥: {e}")

            # ç›‘å¬æ–°frameçš„åŠ è½½
            def handle_frame_attached(frame):
                try:
                    # å»¶è¿Ÿå®‰è£…ï¼Œé¿å…frameè¿˜æœªå®Œå…¨åŠ è½½
                    def delayed_install():
                        try:
                            # ç­‰å¾…frameåŠ è½½å®Œæˆ
                            frame.wait_for_load_state("domcontentloaded", timeout=3000)
                            # å†æ¬¡æ£€æŸ¥frameæ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                            if not frame.is_detached():
                                self.install_date_picker_monitor(frame)
                                logger.debug(f"æ–°frameå·²å®‰è£…ç›‘å¬å™¨: {frame.url}")
                        except Exception as e:
                            logger.debug(f"ä¸ºæ–°frameå®‰è£…ç›‘å¬å™¨å¤±è´¥: {e}")

                    # ä½¿ç”¨é¡µé¢çš„evaluateæ¥å»¶è¿Ÿæ‰§è¡Œ
                    page.evaluate("() => setTimeout(() => {}, 100)")
                    delayed_install()
                except Exception as e:
                    logger.debug(f"å¤„ç†æ–°frameå¤±è´¥: {e}")

            page.on("frameattached", handle_frame_attached)
            logger.info("âœ… å½•åˆ¶ç›‘å¬å™¨å®‰è£…å®Œæˆï¼ˆåŒ…æ‹¬iframeæ”¯æŒï¼‰")

        except Exception as e:
            logger.error(f"å®‰è£…å½•åˆ¶ç›‘å¬å™¨å¤±è´¥: {e}")

    def _try_recipe_automation(self, page, start_date: str, end_date: str) -> bool:
        """å°è¯•ä½¿ç”¨å½•åˆ¶é…æ–¹è¿›è¡Œè‡ªåŠ¨åŒ–æ“ä½œ"""
        try:
            from modules.services.recipe_executor import RecipeExecutor

            # æ ¹æ®æ—¥æœŸèŒƒå›´æ¨æ–­ç›®æ ‡é€‰é¡¹
            target_option = self._infer_target_option(start_date, end_date)

            executor = RecipeExecutor()
            success = executor.execute_date_picker_recipe(page, target_option=target_option)

            if success:
                logger.info(f"ğŸ¬ é…æ–¹è‡ªåŠ¨åŒ–æˆåŠŸï¼šå·²é€‰æ‹© {target_option}")
                return True
            else:
                logger.warning("ğŸ“‹ é…æ–¹è‡ªåŠ¨åŒ–å¤±è´¥")
                return False

        except Exception as e:
            logger.warning(f"é…æ–¹è‡ªåŠ¨åŒ–å¼‚å¸¸: {e}")
            return False

    def _infer_target_option(self, start_date: str, end_date: str) -> str:
        """æ ¹æ®æ—¥æœŸèŒƒå›´æ¨æ–­ç›®æ ‡é€‰é¡¹"""
        try:
            from datetime import datetime, timedelta

            start = datetime.strptime(start_date, '%Y-%m-%d')
            end = datetime.strptime(end_date, '%Y-%m-%d')
            days_diff = (end - start).days + 1  # åŒ…å«ç»“æŸæ—¥æœŸ

            # æ ¹æ®å¤©æ•°å·®å¼‚æ¨æ–­é€‰é¡¹
            if days_diff == 1:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ˜¨å¤©
                yesterday = datetime.now() - timedelta(days=1)
                if start.date() == yesterday.date():
                    return "æ˜¨å¤©"
                else:
                    return "ä»Šæ—¥å®æ—¶"
            elif days_diff <= 8:  # 7-8å¤©éƒ½è®¤ä¸ºæ˜¯è¿‡å»7å¤©
                return "è¿‡å»7 å¤©"
            elif days_diff <= 31:  # 29-31å¤©éƒ½è®¤ä¸ºæ˜¯è¿‡å»30å¤©
                return "è¿‡å»30 å¤©"
            else:
                # è¶…è¿‡31å¤©ï¼Œé»˜è®¤ä½¿ç”¨è¿‡å»30å¤©
                logger.warning(f"æ—¥æœŸèŒƒå›´ {days_diff} å¤©è¶…å‡ºå¸¸ç”¨èŒƒå›´ï¼Œä½¿ç”¨è¿‡å»30å¤©")
                return "è¿‡å»30 å¤©"

        except Exception as e:
            logger.warning(f"æ—¥æœŸæ¨æ–­å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹")
            return "è¿‡å»7 å¤©"

    def generate_date_picker_recipe(self, page: "Page", diag_dir: Path, timestamp: str) -> None:
        """ä»ç›‘å¬äº‹ä»¶ç”Ÿæˆæ—¥æœŸæ§ä»¶æ“ä½œé…æ–¹"""
        try:
            events = self.get_date_picker_events(page)
            if not events:
                logger.info("æ— æ—¥æœŸæ§ä»¶äº¤äº’äº‹ä»¶ï¼Œè·³è¿‡é…æ–¹ç”Ÿæˆ")
                return

            # è¿‡æ»¤å¹¶æ’åºäº‹ä»¶
            valid_events = []
            for event in events:
                if event.get('type') in ['date_container_click', 'shortcut_click']:
                    valid_events.append(event)

            if not valid_events:
                logger.info("æ— æœ‰æ•ˆçš„æ—¥æœŸæ§ä»¶æ“ä½œäº‹ä»¶")
                return

            # æŒ‰æ—¶é—´æ’åº
            valid_events.sort(key=lambda x: x.get('timestamp', 0))

            # ç”Ÿæˆé…æ–¹
            recipe = {
                "page_key": "datacenter/product/performance",
                "generated_at": timestamp,
                "url_pattern": "*/datacenter/product/performance*",
                "steps": []
            }

            for i, event in enumerate(valid_events):
                details = event.get('details', {})
                action = details.get('action', 'click')

                step = {
                    "step_id": i + 1,
                    "action": action,
                    "description": f"{action}: {details.get('text', 'unknown')}",
                    "candidates": []
                }

                # æå–å€™é€‰é€‰æ‹©å™¨
                selectors = details.get('selectors', [])
                for sel in selectors[:5]:  # å–å‰5ä¸ªæœ€ä¼˜é€‰æ‹©å™¨
                    candidate = {
                        "type": sel['type'],
                        "value": sel['value'],
                        "priority": sel['priority']
                    }
                    step["candidates"].append(candidate)

                # æ·»åŠ å…œåº•é€‰æ‹©å™¨
                text = details.get('text', '').strip()
                if text:
                    step["candidates"].append({
                        "type": "text",
                        "value": text,
                        "priority": 1
                    })

                recipe["steps"].append(step)

            # ä¿å­˜é…æ–¹
            recipe_dir = diag_dir / "recipes"
            recipe_dir.mkdir(parents=True, exist_ok=True)
            recipe_file = recipe_dir / "date_picker.json"

            recipe_file.write_text(
                json.dumps(recipe, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )

            logger.info(f"ğŸ“ æ—¥æœŸæ§ä»¶æ“ä½œé…æ–¹å·²ç”Ÿæˆ: {recipe_file}")
            logger.info(f"   åŒ…å« {len(recipe['steps'])} ä¸ªæ“ä½œæ­¥éª¤")

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ—¥æœŸæ§ä»¶é…æ–¹å¤±è´¥: {e}")

    def get_date_picker_events(self, page: "Page") -> List[Dict]:
        """è·å–æ—¥æœŸæ§ä»¶äº¤äº’äº‹ä»¶è®°å½•"""
        try:
            events = page.evaluate("() => window.__date_picker_events__ || []")
            return events
        except Exception as e:
            logger.error(f"è·å–æ—¥æœŸæ§ä»¶äº‹ä»¶å¤±è´¥: {e}")
            return []

    def load_date_picker_recipe(self, shop_id: str | None = None) -> Dict | None:
        """åŠ è½½æ—¥æœŸæ§ä»¶æ“ä½œé…æ–¹ï¼ˆshop_id ä»…ä¸ºå…¼å®¹ä¿ç•™ï¼Œä¸å‚ä¸è·¯å¾„åŒ¹é…ï¼‰"""
        try:
            # é€’å½’æœç´¢æœ€è¿‘ç”Ÿæˆçš„é…æ–¹æ–‡ä»¶ï¼ˆé¿å…è·¯å¾„ä¾èµ–è´¦å·/åº—é“ºåï¼‰
            pattern = os.path.join('temp', 'outputs', 'shopee', '**', 'products', 'weekly', '.diag', 'recipes', 'date_picker.json')
            candidates = glob.glob(pattern, recursive=True)
            if not candidates:
                logger.debug("æœªæ‰¾åˆ°æ—¥æœŸæ§ä»¶é…æ–¹æ–‡ä»¶")
                return None

            latest_path = max(candidates, key=lambda p: os.path.getmtime(p))
            recipe_text = Path(latest_path).read_text(encoding="utf-8")
            recipe = json.loads(recipe_text)
            logger.info(f"ğŸ“– å·²åŠ è½½æ—¥æœŸæ§ä»¶é…æ–¹: {latest_path}")
            return recipe

        except Exception as e:
            logger.error(f"åŠ è½½æ—¥æœŸæ§ä»¶é…æ–¹å¤±è´¥: {e}")
            return None

    def replay_date_picker_recipe(self, page: "Page", recipe: Dict) -> bool:
        """å¤åˆ»æ‰§è¡Œæ—¥æœŸæ§ä»¶æ“ä½œé…æ–¹"""
        try:
            steps = recipe.get("steps", [])
            if not steps:
                logger.warning("é…æ–¹ä¸­æ— æ“ä½œæ­¥éª¤")
                return False

            logger.info(f"ğŸ¬ å¼€å§‹å¤åˆ»æ—¥æœŸæ§ä»¶æ“ä½œï¼Œå…± {len(steps)} ä¸ªæ­¥éª¤")

            for step in steps:
                step_id = step.get("step_id", 0)
                action = step.get("action", "click")
                description = step.get("description", "unknown")
                candidates = step.get("candidates", [])

                logger.info(f"  æ­¥éª¤ {step_id}: {description}")

                success = False
                for candidate in candidates:
                    try:
                        selector_type = candidate.get("type", "css")
                        selector_value = candidate.get("value", "")

                        if not selector_value:
                            continue

                        # æ ¹æ®é€‰æ‹©å™¨ç±»å‹å®šä½å…ƒç´ 
                        if selector_type == "text":
                            locator = page.locator(f'text="{selector_value}"')
                        elif selector_type == "css":
                            locator = page.locator(selector_value)
                        else:
                            continue

                        # æ£€æŸ¥å…ƒç´ æ˜¯å¦å­˜åœ¨ä¸”å¯è§
                        if locator.count() == 0:
                            continue

                        element = locator.first
                        if not element.is_visible():
                            continue

                        # æ‰§è¡Œæ“ä½œ
                        try:
                            element.scroll_into_view_if_needed()
                            element.hover()

                            if action in ["click", "open_picker", "select_shortcut", "select_date"]:
                                element.click(force=True)
                            elif action == "focus_input":
                                element.focus()
                            else:
                                element.click(force=True)

                            page.wait_for_timeout(300)
                            success = True
                            logger.info(f"    âœ“ æˆåŠŸ: {selector_type}='{selector_value}'")
                            break

                        except Exception as e:
                            logger.debug(f"    æ“ä½œå¤±è´¥: {selector_type}='{selector_value}' - {e}")
                            continue

                    except Exception as e:
                        logger.debug(f"    å®šä½å¤±è´¥: {candidate} - {e}")
                        continue

                if not success:
                    logger.warning(f"  æ­¥éª¤ {step_id} æ‰§è¡Œå¤±è´¥ï¼Œå°è¯•ç»§ç»­")

            logger.info("ğŸ¬ é…æ–¹å¤åˆ»æ‰§è¡Œå®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"å¤åˆ»æ‰§è¡Œé…æ–¹å¤±è´¥: {e}")
            return False

    def _save_compare_snapshot(self, page: "Page", diag_dir: Path, timestamp: str, phase: str) -> None:
        """ä¿å­˜å¯¹æ¯”è¯Šæ–­å¿«ç…§ï¼ˆbefore/afterï¼‰"""
        try:
            # 1. é¡µé¢HTMLå’Œæˆªå›¾
            html_file = diag_dir / f"{timestamp}_{phase}_page.html"
            screenshot_file = diag_dir / f"{timestamp}_{phase}_page.png"

            html_file.write_text(page.content(), encoding="utf-8")
            page.screenshot(path=str(screenshot_file), full_page=True)
            logger.info(f"{phase} å¿«ç…§ï¼šé¡µé¢HTMLå’Œæˆªå›¾å·²ä¿å­˜")

            # 2. æ—¶é—´æ§ä»¶è¯¦ç»†ä¿¡æ¯
            time_info = self._extract_time_controls(page)
            time_file = diag_dir / f"{timestamp}_{phase}_time_controls_enhanced.json"
            time_file.write_text(json.dumps(time_info, ensure_ascii=False, indent=2), encoding="utf-8")

            # 3. æŒ‡æ ‡å‹¾é€‰é¡¹æ¸…å•
            metrics_info = self._extract_metrics_checkboxes(page)
            metrics_file = diag_dir / f"{timestamp}_{phase}_metrics_checkboxes.json"
            metrics_file.write_text(json.dumps(metrics_info, ensure_ascii=False, indent=2), encoding="utf-8")

            # 4. å¯è®¿é—®æ€§æ ‘å¿«ç…§
            try:
                accessibility_tree = page.accessibility.snapshot()
                accessibility_file = diag_dir / f"{timestamp}_{phase}_accessibility.json"
                accessibility_file.write_text(json.dumps(accessibility_tree, ensure_ascii=False, indent=2), encoding="utf-8")
            except Exception as e:
                logger.warning(f"{phase} å¯è®¿é—®æ€§æ ‘å¿«ç…§å¤±è´¥: {e}")

            logger.info(f"âœ… {phase} å¿«ç…§ä¿å­˜å®Œæˆ")

        except Exception as e:
            logger.error(f"{phase} å¿«ç…§ä¿å­˜å¤±è´¥: {e}")

    def _generate_comparison_report(self, diag_dir: Path, timestamp: str) -> None:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        try:
            before_time_file = diag_dir / f"{timestamp}_before_time_controls_enhanced.json"
            after_time_file = diag_dir / f"{timestamp}_after_time_controls_enhanced.json"
            before_metrics_file = diag_dir / f"{timestamp}_before_metrics_checkboxes.json"
            after_metrics_file = diag_dir / f"{timestamp}_after_metrics_checkboxes.json"

            diff_report = {
                "timestamp": timestamp,
                "comparison_type": "before_vs_after",
                "time_controls_diff": {},
                "metrics_diff": {},
                "summary": {}
            }

            # å¯¹æ¯”æ—¶é—´æ§ä»¶
            if before_time_file.exists() and after_time_file.exists():
                before_time = json.loads(before_time_file.read_text(encoding="utf-8"))
                after_time = json.loads(after_time_file.read_text(encoding="utf-8"))

                # æå–æ—¶é—´æ˜¾ç¤ºæ–‡æœ¬çš„å˜åŒ–
                before_texts = []
                after_texts = []

                for key, info in before_time.get("time_selectors", {}).items():
                    if info.get("text_content"):
                        before_texts.append(info["text_content"])

                for key, info in after_time.get("time_selectors", {}).items():
                    if info.get("text_content"):
                        after_texts.append(info["text_content"])

                diff_report["time_controls_diff"] = {
                    "before_texts": before_texts,
                    "after_texts": after_texts,
                    "changed": before_texts != after_texts
                }

            # å¯¹æ¯”æŒ‡æ ‡å‹¾é€‰
            if before_metrics_file.exists() and after_metrics_file.exists():
                before_metrics = json.loads(before_metrics_file.read_text(encoding="utf-8"))
                after_metrics = json.loads(after_metrics_file.read_text(encoding="utf-8"))

                # ç»Ÿè®¡å‹¾é€‰çŠ¶æ€å˜åŒ–ï¼ˆä¼ ç»Ÿ checkboxï¼‰
                before_checked = []
                after_checked = []

                for key, info in before_metrics.get("checkboxes", {}).items():
                    if info.get("checked"):
                        before_checked.append(info.get("text", key))

                for key, info in after_metrics.get("checkboxes", {}).items():
                    if info.get("checked"):
                        after_checked.append(info.get("text", key))

                # è¡¨å¤´åˆ—ï¼ˆä½œä¸ºå·²é€‰æŒ‡æ ‡çš„æ›¿ä»£ä¿¡å·ï¼‰
                before_headers = before_metrics.get("table_headers", [])
                after_headers = after_metrics.get("table_headers", [])

                # ç»Ÿè®¡ multi-selector çŠ¶æ€å˜åŒ–
                before_selected = []
                after_selected = []

                for key, info in before_metrics.get("multi_selector_items", {}).items():
                    if info.get("selected"):
                        before_selected.append(info.get("title", key))

                for key, info in after_metrics.get("multi_selector_items", {}).items():
                    if info.get("selected"):
                        after_selected.append(info.get("title", key))

                diff_report["metrics_diff"] = {
                    "before_checked": before_checked,
                    "after_checked": after_checked,
                    "newly_checked": list(set(after_checked) - set(before_checked)),
                    "unchecked": list(set(before_checked) - set(after_checked)),
                    "before_selected": before_selected,
                    "after_selected": after_selected,
                    "newly_selected": list(set(after_selected) - set(before_selected)),
                    "newly_unselected": list(set(before_selected) - set(after_selected)),
                    "before_headers": before_headers,
                    "after_headers": after_headers,
                    "new_headers": list(set(after_headers) - set(before_headers)),
                    "removed_headers": list(set(before_headers) - set(after_headers))
                }

            # ç”Ÿæˆæ‘˜è¦
            metrics_changed = (
                len(diff_report["metrics_diff"].get("newly_checked", [])) > 0 or
                len(diff_report["metrics_diff"].get("unchecked", [])) > 0 or
                len(diff_report["metrics_diff"].get("newly_selected", [])) > 0 or
                len(diff_report["metrics_diff"].get("newly_unselected", [])) > 0
            )

            diff_report["summary"] = {
                "time_changed": diff_report["time_controls_diff"].get("changed", False),
                "metrics_changed": metrics_changed,
                "multi_selector_changed": len(diff_report["metrics_diff"].get("newly_selected", [])) > 0 or len(diff_report["metrics_diff"].get("newly_unselected", [])) > 0,
                "total_changes": sum([
                    diff_report["time_controls_diff"].get("changed", False),
                    metrics_changed
                ])
            }

            # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
            diff_file = diag_dir / f"{timestamp}_diff.json"
            diff_file.write_text(json.dumps(diff_report, ensure_ascii=False, indent=2), encoding="utf-8")

            logger.info(f"ğŸ“Š å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {diff_file}")
            logger.info(f"ğŸ“ˆ å˜åŒ–æ‘˜è¦: æ—¶é—´æ§ä»¶{'å·²å˜åŒ–' if diff_report['summary']['time_changed'] else 'æœªå˜åŒ–'}, "
                       f"æŒ‡æ ‡å‹¾é€‰{'å·²å˜åŒ–' if diff_report['summary']['metrics_changed'] else 'æœªå˜åŒ–'}, "
                       f"å¤šé€‰å™¨{'å·²å˜åŒ–' if diff_report['summary']['multi_selector_changed'] else 'æœªå˜åŒ–'}")

            # ç”Ÿæˆæ—¥æœŸæ§ä»¶æ“ä½œé…æ–¹ï¼ˆåœ¨å¯¹æ¯”è¯Šæ–­ç»“æŸæ—¶ï¼‰
            try:
                # éœ€è¦ä»è°ƒç”¨æ–¹ä¼ å…¥ page å¯¹è±¡ï¼Œè¿™é‡Œå…ˆå ä½
                # self.generate_date_picker_recipe(page, diag_dir, timestamp)
                pass
            except Exception as e:
                logger.error(f"ç”Ÿæˆé…æ–¹æ—¶å‡ºé”™: {e}")

        except Exception as e:
            logger.error(f"ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šå¤±è´¥: {e}")

    def _install_mutation_observer(self, page: "Page") -> None:
        """å®‰è£… DOM å˜åŒ–ç›‘å¬å™¨ï¼Œæ•æ‰é¡µé¢å…ƒç´ å±æ€§å’Œå­èŠ‚ç‚¹å˜åŒ–"""
        script = """
        () => {
          if (window.__x_mutations_installed__) return;
          window.__x_mutations_installed__ = true;
          window.__x_mutations__ = [];

          const observer = new MutationObserver((mutations) => {
            for (const m of mutations) {
              const rec = {
                type: m.type,
                target: m.target && m.target.outerHTML ? m.target.outerHTML.slice(0, 500) : (m.target?.nodeName || ''),
                attributeName: m.attributeName || null,
                addedNodes: Array.from(m.addedNodes || []).map(n => (n.outerHTML||n.nodeName||'')).slice(0,5),
                removedNodes: Array.from(m.removedNodes || []).map(n => (n.outerHTML||n.nodeName||'')).slice(0,5),
                oldValue: m.oldValue || null,
                timestamp: Date.now()
              };
              try {
                window.__x_mutations__.push(rec);
                // é™åˆ¶æ•°ç»„å¤§å°ï¼Œé¿å…å†…å­˜æº¢å‡º
                if (window.__x_mutations__.length > 1000) {
                  window.__x_mutations__ = window.__x_mutations__.slice(-500);
                }
              } catch(e) {}
            }
          });

          observer.observe(document.body, {
            attributes: true,
            childList: true,
            subtree: true,
            characterData: false,
            attributeOldValue: true
          });

          window.__x_mutation_observer__ = observer;
          console.log('ğŸ§© DOM MutationObserver å·²å®‰è£…');
        }
        """
        page.evaluate(script)
        logger.info("ğŸ§© DOMå˜åŒ–ç›‘å¬å™¨å·²å®‰è£…")

    def _dump_mutations(self, page: "Page", diag_dir: Path, timestamp: str) -> None:
        """å¯¼å‡º DOM å˜åŒ–è®°å½•"""
        try:
            data = page.evaluate("() => (window.__x_mutations__||[])")

            # è¿‡æ»¤å‡ºæœ‰æ„ä¹‰çš„å˜åŒ–ï¼ˆé‡ç‚¹å…³æ³¨ class å±æ€§å˜åŒ–å’Œ multi-selector ç›¸å…³ï¼‰
            filtered_mutations = []
            for mutation in data if isinstance(data, list) else []:
                # ä¿ç•™æ‰€æœ‰ attributeName=class çš„å˜åŒ–
                if mutation.get("attributeName") == "class":
                    filtered_mutations.append(mutation)
                # ä¿ç•™åŒ…å« multi-selector çš„å…ƒç´ å˜åŒ–
                elif "multi-selector" in str(mutation.get("target", "")):
                    filtered_mutations.append(mutation)
                # ä¿ç•™æ–°å¢/åˆ é™¤èŠ‚ç‚¹çš„å˜åŒ–
                elif mutation.get("addedNodes") or mutation.get("removedNodes"):
                    filtered_mutations.append(mutation)

            out = {
                "timestamp": timestamp,
                "total_mutations": len(data) if isinstance(data, list) else 0,
                "filtered_count": len(filtered_mutations),
                "mutations": filtered_mutations[:500],  # æœ€å¤šä¿ç•™500æ¡
                "filter_criteria": [
                    "attributeName == 'class'",
                    "target contains 'multi-selector'",
                    "has addedNodes or removedNodes"
                ]
            }

            mutations_file = diag_dir / f"{timestamp}_mutations.json"
            mutations_file.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")

            logger.info(f"ğŸ§© DOMå˜åŒ–è®°å½•å·²ä¿å­˜: {mutations_file}")
            logger.info(f"ğŸ“Š å˜åŒ–ç»Ÿè®¡: æ€»è®¡{out['total_mutations']}æ¡, è¿‡æ»¤å{out['filtered_count']}æ¡")

        except Exception as e:
            logger.error(f"å¯¼å‡ºDOMå˜åŒ–è®°å½•å¤±è´¥: {e}")

    def _export_via_ui(
        self,
        page: "Page",
        target_path: Path,
        *,
        diag_dir: Optional[Path] = None,
        ts: Optional[str] = None,
        capture_network: bool = False,
        enable_auto_regenerate: bool = False,
    ) -> Tuple[bool, str]:
        """é€šè¿‡é¡µé¢æŒ‰é’®æ‰§è¡Œå¯¼å‡ºå¹¶è‡ªåŠ¨ä¸‹è½½ï¼›å¯é€‰æŠ“å–ç½‘ç»œå¿«ç…§ã€‚

        - è‡ªåŠ¨ç‚¹å‡»"å¯¼å‡ºæ•°æ®"æŒ‰é’®
        - è‡ªåŠ¨ç‚¹å‡»å¼¹çª—ä¸­çš„"ä¸‹è½½"æŒ‰é’®ï¼ˆå¤šè¯­è¨€å…¼å®¹ï¼‰
        - å¦‚æœ capture_network=Trueï¼Œåˆ™åœ¨ç‚¹å‡»åæŠ“å–çº¦30ç§’ç½‘ç»œè¯·æ±‚ï¼Œä¿å­˜ä¸º <ts>_post_net.json
        - è‹¥å·²æä¾› pre_net.jsonï¼Œä¼šç”Ÿæˆ net_diff.jsonï¼ˆæ–°å¢è¯·æ±‚ã€å¯¼å‡ºç›¸å…³URLã€è¯·æ±‚ä½“æ‘˜è¦ï¼‰
        """
        try:
            # å¯èƒ½çš„å¯¼å‡ºæŒ‰é’®é€‰æ‹©å™¨
            export_btn_selectors = [
                'button:has-text("å¯¼å‡ºæ•°æ®")',
                'button:has-text("å¯¼å‡º")',
                'button:has-text("ä¸‹è½½")',
                'button:has-text("å¯¼å‡ºæŠ¥è¡¨")',
                '[data-testid*="export"]',
                '.export-btn',
                '.download-btn',
            ]

            # è§†çª—æ»šåŠ¨åˆ°ä½ æä¾›çš„æŒ‡æ ‡åŒºåŸŸ XPathï¼Œé¿å…æŒ‰é’®ä¸å¯è§
            try:
                xpath_panel = '/html/body/div[1]/div[2]/div[2]/div[2]/div/div/div/div[2]/div/section/div/div/div[5]/div[3]'
                panel = page.locator(f'xpath={xpath_panel}')
                if panel.count() > 0:
                    panel.first.scroll_into_view_if_needed(timeout=2000)
                    page.wait_for_timeout(300)
            except Exception:
                pass

            # å°è¯•ç‚¹å‡»å¯¼å‡º/ä¸‹è½½
            clicked = False
            for sel in export_btn_selectors:
                try:
                    loc = page.locator(sel)
                    if loc.count() > 0 and loc.first.is_visible():
                        loc.first.click()
                        clicked = True
                        logger.info(f"ç‚¹å‡»å¯¼å‡ºæŒ‰é’®: {sel}")
                        break
                except Exception:
                    continue

            if not clicked:
                try:
                    btn = page.get_by_role("button", name=re.compile("å¯¼å‡º|ä¸‹è½½", re.IGNORECASE))
                    if btn.count() > 0 and btn.first.is_visible():
                        btn.first.click()
                        clicked = True
                        logger.info("é€šè¿‡æŒ‰é’®è§’è‰²ç‚¹å‡»å¯¼å‡º/ä¸‹è½½")
                except Exception:
                    pass

            if not clicked:
                return False, "æœªæ‰¾åˆ°å¯¼å‡º/ä¸‹è½½æŒ‰é’®"

            # ç­‰å¾…å¯¼å‡ºå¼¹çª—å‡ºç°å¹¶è‡ªåŠ¨ç‚¹å‡»æœ€æ–°ä¸€æ¡â€œæœªä¸‹è½½â€çš„æŠ¥å‘Š
            page.wait_for_timeout(2000)  # ç­‰å¾…å¼¹çª—åŠ è½½

            download_clicked = False

            # ç­‰å¾…"è¿›è¡Œä¸­"çŠ¶æ€å˜ä¸º"ä¸‹è½½"
            self._wait_for_download_ready(page)

            try:
                # 1) ä¼˜å…ˆç‚¹å‡»ç¬¬ä¸€æ¡â€œæœªä¸‹è½½â€çš„ä¸‹è½½æŒ‰é’®ï¼ˆä¸åŒ…å«â€œå·²ä¸‹è½½â€æ–‡æ¡ˆï¼‰
                # åˆ—è¡¨ç»“æ„å¤§è‡´ä¸ºï¼šè¡Œ(åŒ…å«æŠ¥å‘Šå) + æ“ä½œåˆ—(æŒ‰é’®æˆ–â€œå·²ä¸‹è½½â€æ–‡æœ¬)
                report_rows = page.locator('div[role="dialog"] .ant-table-row, .el-dialog .el-table__row, .report-list .row, .latest-report .row')
                if report_rows.count() > 0:
                    # éå†å‰5è¡Œï¼Œæ‰¾åˆ°ä¸å«â€œå·²ä¸‹è½½â€çš„è¡Œ
                    limit = min(5, report_rows.count())
                    for i in range(limit):
                        row = report_rows.nth(i)
                        txt = row.inner_text(timeout=1000).lower()
                        if ("å·²ä¸‹è½½" not in txt) and ("downloaded" not in txt):
                            # ç‚¹å‡»è¯¥è¡Œä¸­çš„ä¸‹è½½æŒ‰é’®
                            btn = row.locator('button:has-text("ä¸‹è½½"), button:has-text("Download"), button:has-text("ä¸‹è¼‰")')
                            if btn.count() > 0 and btn.first.is_visible():
                                # ç‚¹å‡»æ—¶ç­‰å¾…ä¸‹è½½äº‹ä»¶ï¼Œé¿å…é”™è¿‡äº‹ä»¶
                                with page.expect_download(timeout=20000) as dl_info:
                                    btn.first.click()
                                download = dl_info.value

                                # è·å–ä¸‹è½½çš„æ–‡ä»¶åå¹¶ä¿å­˜åˆ°ç›®æ ‡è·¯å¾„
                                suggested_filename = download.suggested_filename
                                tmp_path = target_path.parent / suggested_filename
                                download.save_as(str(tmp_path))
                                if tmp_path != target_path:
                                    try:
                                        tmp_path.rename(target_path)
                                    except Exception:
                                        try:
                                            import shutil
                                            shutil.copy2(tmp_path, target_path)
                                            tmp_path.unlink(missing_ok=True)
                                        except Exception:
                                            pass

                                size = target_path.stat().st_size if target_path.exists() else 0
                                logger.success(f"ä¸‹è½½å®Œæˆ(UI): {target_path} ({size:,} bytes)")
                                return True, "ä¸‹è½½å®Œæˆ(UI)"
            except Exception:
                pass

            # 2) å…œåº•ï¼šæŒ‰é€šç”¨é€‰æ‹©å™¨ç‚¹å‡»ç¬¬ä¸€ä¸ªä¸‹è½½æŒ‰é’®
            if not download_clicked:
                candidates = [
                    'button:has-text("ä¸‹è½½")',
                    'button:has-text("Download")',
                    'button:has-text("ä¸‹è¼‰")',
                    'a:has-text("ä¸‹è½½")',
                    'a:has-text("Download")',
                    '.download-btn',
                    '[data-testid*="download"]',
                ]
                for sel in candidates:
                    try:
                        loc = page.locator(sel)
                        if loc.count() > 0 and loc.first.is_visible():
                            # ç‚¹å‡»æ—¶ç­‰å¾…ä¸‹è½½äº‹ä»¶
                            with page.expect_download(timeout=20000) as dl_info:
                                loc.first.click()
                            download = dl_info.value

                            suggested_filename = download.suggested_filename
                            tmp_path = target_path.parent / suggested_filename
                            download.save_as(str(tmp_path))
                            if tmp_path != target_path:
                                try:
                                    tmp_path.rename(target_path)
                                except Exception:
                                    try:
                                        import shutil
                                        shutil.copy2(tmp_path, target_path)
                                        tmp_path.unlink(missing_ok=True)
                                    except Exception:
                                        pass

                            size = target_path.stat().st_size if target_path.exists() else 0
                            logger.success(f"ä¸‹è½½å®Œæˆ(UI): {target_path} ({size:,} bytes)")
                            return True, "ä¸‹è½½å®Œæˆ(UI)"
                    except Exception:
                        continue

            if not download_clicked:
                logger.warning("æœªæ‰¾åˆ°å¯ç‚¹å‡»çš„ä¸‹è½½æŒ‰é’®ï¼Œå°†ç­‰å¾…è‡ªåŠ¨ä¸‹è½½")

            # å¯é€‰ï¼šç‚¹å‡»å¯¼å‡ºåæŠ“ post ç½‘ç»œå¿«ç…§
            if capture_network and diag_dir and ts:
                try:
                    post_net = diag_dir / f"{ts}_post_net.json"
                    self._capture_network_snapshot(page, duration_ms=30000, out_file=post_net)
                    pre_net = diag_dir / f"{ts}_pre_net.json"
                    if pre_net.exists():
                        self._diff_network_files(pre_net, post_net, diag_dir / f"{ts}_net_diff.json")
                    # æˆåŠŸåæ‰“å°å‰5æ¡å¯ç–‘è¯·æ±‚
                    try:
                        diff_path = diag_dir / f"{ts}_net_diff.json"
                        if diff_path.exists():
                            summary = json.loads(diff_path.read_text(encoding='utf-8'))
                            interesting = summary.get('interesting', [])[:5]
                            if interesting:
                                logger.info("ç½‘ç»œå·®å¼‚(å‰5æ¡å¯ç–‘)ï¼š")
                                for i, it in enumerate(interesting, 1):
                                    url = it.get('url', '')
                                    method = it.get('method', '')
                                    post = it.get('post', '')
                                    logger.info(f"[{i}] {method} {url} | post={post}")
                    except Exception as pe:
                        logger.debug(f"æ‰“å°ç½‘ç»œå·®å¼‚æ‘˜è¦å¤±è´¥: {pe}")
                except Exception as ne:
                    logger.debug(f"æŠ“å–/å¯¹æ¯”ç½‘ç»œå¿«ç…§å¤±è´¥: {ne}")

            # è‹¥æ²¡æœ‰å¯ç‚¹å‡»çš„ä¸‹è½½ä¸”å¼€å¯è‡ªåŠ¨é‡ç”Ÿï¼Œå°è¯•ç”Ÿæˆæ–°æŠ¥å‘Š
            if enable_auto_regenerate and not download_clicked:
                try:
                    regen_candidates = [
                        'button:has-text("å¯¼å‡ºæ•°æ®")',
                        'button:has-text("é‡æ–°ç”Ÿæˆ")',
                        'a:has-text("å¯¼å‡ºæ•°æ®")',
                    ]
                    clicked_regen = False
                    for sel in regen_candidates:
                        loc = page.locator(sel)
                        if loc.count() > 0 and loc.first.is_visible():
                            loc.first.click()
                            clicked_regen = True
                            logger.info(f"è§¦å‘é‡æ–°ç”Ÿæˆ: {sel}")
                            break
                    if clicked_regen:
                        # ç­‰å¾…è¿›è¡Œä¸­â†’ä¸‹è½½
                        self._wait_for_download_ready(page, max_wait_seconds=90)
                        # å°è¯•å†æ¬¡ç‚¹å‡»å¹¶ç­‰å¾…ä¸‹è½½
                        rows = page.locator('div[role="dialog"] .ant-table-row, .el-dialog .el-table__row')
                        if rows.count() > 0:
                            btn = rows.first.locator('button:has-text("ä¸‹è½½"), button:has-text("Download")')
                            if btn.count() > 0 and btn.first.is_visible():
                                with page.expect_download(timeout=30000) as dl_info:
                                    btn.first.click()
                                download = dl_info.value
                                suggested_filename = download.suggested_filename
                                tmp_path = target_path.parent / suggested_filename
                                download.save_as(str(tmp_path))
                                if tmp_path != target_path:
                                    try:
                                        tmp_path.rename(target_path)
                                    except Exception:
                                        import shutil
                                        shutil.copy2(tmp_path, target_path)
                                        try:
                                            tmp_path.unlink(missing_ok=True)
                                        except Exception:
                                            pass
                                size = target_path.stat().st_size if target_path.exists() else 0
                                logger.success(f"ä¸‹è½½å®Œæˆ(UI): {target_path} ({size:,} bytes)")
                                return True, "ä¸‹è½½å®Œæˆ(UI)"
                except Exception as re:
                    logger.debug(f"è‡ªåŠ¨é‡æ–°ç”Ÿæˆå¤±è´¥: {re}")

            # æ£€æŸ¥æ˜¯å¦æœ‰"è¿™æ˜¯æ‚¨è¿˜æ²¡ä¸‹è½½çš„æŠ¥å‘Š"æç¤º
            try:
                no_download_text = page.locator('text="è¿™æ˜¯æ‚¨è¿˜æ²¡ä¸‹è½½çš„æŠ¥å‘Š"')
                if no_download_text.count() > 0 and no_download_text.first.is_visible():
                    logger.warning("âš ï¸ æ£€æµ‹åˆ°'è¿™æ˜¯æ‚¨è¿˜æ²¡ä¸‹è½½çš„æŠ¥å‘Š'ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç”ŸæˆæŠ¥å‘Š")
                    return False, "æ²¡æœ‰å¯ä¸‹è½½çš„æŠ¥å‘Šï¼Œè¯·é‡æ–°ç”Ÿæˆ"
            except Exception:
                pass

            # æ•è·ä¸‹è½½ï¼ˆç›´æ¥ä¸‹è½½åˆ°æŒ‡å®šç›®å½•ï¼‰
            try:
                # å…ˆçŸ­æš‚ç­‰å¾…è§¦å‘ä¸‹è½½
                page.wait_for_timeout(1500)

                # 1) ä¼˜å…ˆç­‰å¾…UIä¸‹è½½äº‹ä»¶ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡çº§åˆ«ç›‘å¬ï¼Œé¿å…è·¨é¡µ/iframeä¸¢å¤±ï¼‰
                with page.context.expect_download(timeout=20000) as dl_info:  # 20ç§’
                    pass
                download = dl_info.value

                # è·å–ä¸‹è½½çš„æ–‡ä»¶å
                suggested_filename = download.suggested_filename
                download_path = target_path.parent / suggested_filename

                # ä¿å­˜åˆ°ä¸´æ—¶ä½ç½®ï¼Œç„¶åé‡å‘½åä¸ºç›®æ ‡æ–‡ä»¶å
                download.save_as(str(download_path))

                if download_path != target_path:
                    download_path.rename(target_path)

                size = target_path.stat().st_size if target_path.exists() else 0
                logger.success(f"ä¸‹è½½å®Œæˆ(UI): {target_path} ({size:,} bytes)")
                return True, "ä¸‹è½½å®Œæˆ(UI)"

            except Exception as download_error:
                logger.warning(f"ä¸‹è½½ç­‰å¾…è¶…æ—¶æˆ–å¤±è´¥: {download_error}")

                # 2) å…œåº•ï¼šæ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦æœ‰æ–°æ–‡ä»¶
                success, message = self._check_alternative_download(page, target_path)
                if success:
                    return True, message

                # å¦‚æœå¼€å¯è‡ªåŠ¨é‡ç”Ÿï¼Œå·²ç»åœ¨ä¸Šæ–‡å°è¯•è¿‡ï¼›æ­¤å¤„èµ°æœ€ç»ˆå¤±è´¥è·¯å¾„
                logger.error("âŒ ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶æœªç”Ÿæˆ")
                return False, f"ä¸‹è½½å¤±è´¥: {download_error}"
        except Exception as e:
            logger.debug(f"UIå¯¼å‡ºå¤±è´¥: {e}")
            return False, f"UIå¯¼å‡ºå¤±è´¥: {e}"

    def _capture_network_snapshot(self, page: "Page", duration_ms: int, out_file: Path) -> None:
        """åœ¨Pythonä¾§çŸ­æ—¶é—´æ•æ‰ç½‘ç»œè¯·æ±‚ï¼ˆresponse äº‹ä»¶ï¼‰ï¼Œä¿å­˜åˆ° JSONã€‚

        ä¿å­˜å­—æ®µï¼šæ—¶é—´æˆ³ã€æ–¹æ³•ã€URLã€çŠ¶æ€ã€å†…å®¹ç±»å‹ã€éƒ¨åˆ†è¯·æ±‚ä½“/å“åº”ä½“ï¼ˆæœ€å¤š200å­—ï¼‰ã€‚
        """
        try:
            events: List[Dict] = []

            def _on_response(res):
                try:
                    req = res.request
                    url = getattr(req, "url", lambda: "")()
                    method = getattr(req, "method", lambda: "")()
                    post = getattr(req, "post_data", lambda: None)() or ""
                    status = res.status
                    headers = res.headers
                    ct = (headers.get("content-type", "") or "").lower()
                    preview = ""
                    try:
                        # text() å¯èƒ½è¾ƒæ…¢ï¼Œæˆªæ–­åˆ°200å­—ç¬¦
                        preview = (res.text() or "")[:200]
                    except Exception:
                        pass
                    events.append({
                        "t": int(time.time() * 1000),
                        "method": method,
                        "url": url,
                        "status": status,
                        "content_type": ct,
                        "post": (post or "")[:200],
                        "preview": preview,
                    })
                except Exception:
                    pass

            page.on("response", _on_response)
            try:
                page.wait_for_timeout(duration_ms)
            finally:
                try:
                    page.off("response", _on_response)
                except Exception:
                    pass

            out_file.write_text(json.dumps(events, ensure_ascii=False, indent=2), encoding="utf-8")
            logger.info(f"ç½‘ç»œå¿«ç…§å·²ä¿å­˜: {out_file}")
        except Exception as e:
            logger.debug(f"ç½‘ç»œå¿«ç…§å¤±è´¥: {e}")

    def _diff_network_files(self, pre_path: Path, post_path: Path, out_path: Path) -> None:
        """å¯¹æ¯”ä¸¤ä»½ç½‘ç»œå¿«ç…§ï¼Œç”Ÿæˆå·®å¼‚æ‘˜è¦ã€‚"""
        try:
            pre = json.loads(pre_path.read_text(encoding='utf-8')) if pre_path.exists() else []
            post = json.loads(post_path.read_text(encoding='utf-8')) if post_path.exists() else []

            pre_urls = {item.get('url') for item in pre}
            added = [item for item in post if item.get('url') not in pre_urls]

            # é‡ç‚¹æ ‡è®°åŒ…å«å¯¼å‡º/ä¸‹è½½/metrics/column ç­‰å…³é”®è¯çš„è¯·æ±‚
            keywords = ['export', 'download', 'report', 'metric', 'column', 'performance']
            interesting = [it for it in added if any(k in (it.get('url','')) for k in keywords)]

            out = {
                'pre_count': len(pre),
                'post_count': len(post),
                'added_count': len(added),
                'added_samples': added[:20],
                'interesting': interesting[:20],
            }
            out_path.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding='utf-8')
            logger.info(f"ç½‘ç»œå·®å¼‚æŠ¥å‘Šå·²ä¿å­˜: {out_path}")
        except Exception as e:
            logger.debug(f"ç½‘ç»œå·®å¼‚å¯¹æ¯”å¤±è´¥: {e}")


    def _open_metric_selector(self, page: "Page") -> None:
        """å°è¯•æ‰“å¼€æŒ‡æ ‡é€‰æ‹©é¢æ¿"""
        try:
            # æ–¹æ³•1: é€šè¿‡æŒ‰é’®è§’è‰²æŸ¥æ‰¾
            btn = page.get_by_role("button", name=re.compile("é€‰æ‹©æŒ‡æ ‡|é€‰æ‹©åˆ—|æŒ‡æ ‡", re.IGNORECASE))
            if btn.count() > 0 and btn.first.is_visible():
                btn.first.click()
                page.wait_for_timeout(1000)  # ç­‰å¾…é¢æ¿åŠ è½½
                logger.info("âœ“ é€šè¿‡æŒ‰é’®è§’è‰²æ‰“å¼€æŒ‡æ ‡é€‰æ‹©é¢æ¿")
                return
        except Exception as e:
            logger.debug(f"æŒ‰é’®è§’è‰²æ–¹æ³•å¤±è´¥: {e}")

        try:
            # æ–¹æ³•2: é€šè¿‡æ–‡æœ¬æŸ¥æ‰¾
            text_btn = page.get_by_text(re.compile("é€‰æ‹©æŒ‡æ ‡|é€‰æ‹©åˆ—|æŒ‡æ ‡", re.IGNORECASE)).first
            if text_btn and text_btn.is_visible():
                text_btn.click()
                page.wait_for_timeout(1000)
                logger.info("âœ“ é€šè¿‡æ–‡æœ¬æŸ¥æ‰¾æ‰“å¼€æŒ‡æ ‡é€‰æ‹©é¢æ¿")
                return
        except Exception as e:
            logger.debug(f"æ–‡æœ¬æŸ¥æ‰¾æ–¹æ³•å¤±è´¥: {e}")

        try:
            # æ–¹æ³•3: æŸ¥æ‰¾å¯èƒ½çš„é€‰æ‹©å™¨æŒ‰é’®
            selectors = [
                'button:has-text("é€‰æ‹©æŒ‡æ ‡")',
                'button:has-text("çŸ©å½¢ é€‰æ‹©æŒ‡æ ‡")',
                'button:has-text("é€‰æ‹©åˆ—")',
                'button:has-text("æŒ‡æ ‡")',
                '.metric-selector-btn',
                '.column-selector',
                '[data-testid*="metric"]',
                '[data-testid*="column"]'
            ]

            for selector in selectors:
                try:
                    element = page.locator(selector).first
                    if element.count() > 0 and element.is_visible():
                        element.click()
                        page.wait_for_timeout(1000)
                        logger.info(f"âœ“ é€šè¿‡é€‰æ‹©å™¨æ‰“å¼€æŒ‡æ ‡é¢æ¿: {selector}")
                        return
                except:
                    continue

        except Exception as e:
            logger.debug(f"é€‰æ‹©å™¨æ–¹æ³•å¤±è´¥: {e}")

        logger.warning("âš  æœªèƒ½è‡ªåŠ¨æ‰“å¼€æŒ‡æ ‡é€‰æ‹©é¢æ¿ï¼Œè¯·ç¡®ä¿æ‰‹åŠ¨æ“ä½œæ—¶é¢æ¿å·²æ‰“å¼€")

    def _wait_for_download_ready(self, page, max_wait_seconds: int = 60) -> bool:
        """
        ç­‰å¾…ä¸‹è½½æŒ‰é’®ä»"è¿›è¡Œä¸­"çŠ¶æ€å˜ä¸º"ä¸‹è½½"çŠ¶æ€

        Args:
            page: Playwrighté¡µé¢å¯¹è±¡
            max_wait_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: æ˜¯å¦æˆåŠŸç­‰å¾…åˆ°ä¸‹è½½å°±ç»ª
        """
        try:
            import time

            logger.info("â³ ç­‰å¾…å¯¼å‡ºå®Œæˆï¼Œç›‘æ§çŠ¶æ€å˜åŒ–...")

            start_time = time.time()
            check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡

            while time.time() - start_time < max_wait_seconds:
                try:
                    # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„çŠ¶æ€æŒ‡ç¤ºå™¨
                    status_selectors = [
                        'text="è¿›è¡Œä¸­"',
                        'text="Processing"',
                        'text="æ­£åœ¨ç”Ÿæˆ"',
                        'text="Generating"',
                        '.processing',
                        '.generating',
                        '[data-status="processing"]'
                    ]

                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰"è¿›è¡Œä¸­"çŠ¶æ€
                    has_processing = False
                    for selector in status_selectors:
                        try:
                            elements = page.locator(selector)
                            if elements.count() > 0:
                                # æ£€æŸ¥å…ƒç´ æ˜¯å¦å¯è§
                                for i in range(elements.count()):
                                    if elements.nth(i).is_visible():
                                        has_processing = True
                                        break
                                if has_processing:
                                    break
                        except Exception:
                            continue

                    if not has_processing:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ä¸‹è½½æŒ‰é’®
                        download_selectors = [
                            'button:has-text("ä¸‹è½½")',
                            'button:has-text("Download")',
                            'a:has-text("ä¸‹è½½")',
                            'a:has-text("Download")'
                        ]

                        for selector in download_selectors:
                            try:
                                elements = page.locator(selector)
                                if elements.count() > 0 and elements.first.is_visible():
                                    logger.info("âœ… å¯¼å‡ºå®Œæˆï¼Œä¸‹è½½æŒ‰é’®å·²å°±ç»ª")
                                    return True
                            except Exception:
                                continue

                    # æ˜¾ç¤ºç­‰å¾…è¿›åº¦
                    elapsed = int(time.time() - start_time)
                    logger.info(f"â³ ç­‰å¾…å¯¼å‡ºå®Œæˆ... ({elapsed}s/{max_wait_seconds}s)")

                    time.sleep(check_interval)

                except Exception as e:
                    logger.debug(f"çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {e}")
                    time.sleep(check_interval)

            logger.warning(f"âš ï¸ ç­‰å¾…è¶…æ—¶ ({max_wait_seconds}s)ï¼Œç»§ç»­å°è¯•ä¸‹è½½")
            return False

        except Exception as e:
            logger.error(f"ç­‰å¾…ä¸‹è½½å°±ç»ªå¤±è´¥: {e}")
            return False

    def _wait_for_download(self, page, target_path: Path, timeout: int = 60) -> tuple[bool, Optional[Path]]:
        """
        ç­‰å¾…ä¸‹è½½å®Œæˆå¹¶ä¿å­˜åˆ°ç›®æ ‡è·¯å¾„ã€‚
        å…ˆç›‘å¬ UI ä¸‹è½½äº‹ä»¶ï¼Œå¤±è´¥åˆ™æ£€æŸ¥å¸¸è§ä¸‹è½½ç›®å½•ä½œä¸ºå…œåº•ã€‚
        """
        try:
            with page.expect_download(timeout=timeout * 1000) as dl_info:
                pass
            download = dl_info.value
            suggested = target_path.parent / download.suggested_filename
            download.save_as(str(suggested))
            if suggested != target_path:
                try:
                    suggested.rename(target_path)
                except Exception:
                    import shutil
                    shutil.move(str(suggested), str(target_path))
            return True, target_path
        except Exception as e:
            logger.warning(f"ç­‰å¾…ä¸‹è½½äº‹ä»¶å¤±è´¥ï¼Œå°è¯•å…œåº•æ£€æŸ¥: {e}")
            ok, msg = self._check_alternative_download(page, target_path)
            if ok:
                return True, target_path
            return False, None

    def _check_alternative_download(self, page, target_path: Path) -> Tuple[bool, str]:
        """æ£€æŸ¥å¤‡ç”¨ä¸‹è½½æ–¹å¼"""
        try:
            import time
            from pathlib import Path

            logger.info("ğŸ” æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ä¸‹è½½æ–¹å¼...")

            # 0. é¦–å…ˆæ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨ï¼ˆå¯èƒ½å·²ç»ä¸‹è½½å®Œæˆï¼‰
            if target_path.exists() and target_path.stat().st_size > 0:
                size = target_path.stat().st_size
                logger.success(f"âœ… ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨: {target_path} ({size:,} bytes)")
                return True, f"æ–‡ä»¶å·²å­˜åœ¨: {size:,} bytes)"

            # 1. æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„ä¸‹è½½ç›®å½•
            possible_download_dirs = [
                Path.home() / "Downloads",
                Path.home() / "ä¸‹è½½",
                Path("C:/Users") / Path.home().name / "Downloads",
                Path("C:/Users") / Path.home().name / "ä¸‹è½½",
                # æ–°å¢ï¼šPlaywrightæŒä¹…åŒ–é»˜è®¤ä¸‹è½½ç›®å½•
                Path("profiles") / "shopee" / "**" / "Default" / "Downloads",
            ]

            from glob import glob
            for downloads_dir in possible_download_dirs:
                try:
                    # æ”¯æŒé€šé… profiles/shopee/**/Default/Downloads
                    candidate_paths = []
                    if "**" in str(downloads_dir):
                        candidate_paths = [Path(p) for p in glob(str(downloads_dir))]
                    else:
                        candidate_paths = [downloads_dir]

                    for d in candidate_paths:
                        if not d.exists():
                            continue
                        logger.debug(f"æ£€æŸ¥ä¸‹è½½ç›®å½•: {d}")
                        xlsx_files = list(d.glob("*.xlsx"))
                        if xlsx_files:
                            latest_file = max(xlsx_files, key=lambda f: f.stat().st_mtime)
                            if time.time() - latest_file.stat().st_mtime < 600:
                                try:
                                    target_path.parent.mkdir(parents=True, exist_ok=True)
                                    if target_path.exists():
                                        backup_path = target_path.with_suffix(f".backup_{int(time.time())}.xlsx")
                                        target_path.rename(backup_path)
                                        logger.info(f"å¤‡ä»½å·²å­˜åœ¨æ–‡ä»¶: {backup_path}")
                                    # ä¼˜å…ˆç§»åŠ¨
                                    try:
                                        latest_file.rename(target_path)
                                    except Exception:
                                        import shutil
                                        shutil.copy2(latest_file, target_path)
                                    size = target_path.stat().st_size
                                    logger.success(f"âœ… ä»ä¸‹è½½ç›®å½•è·å–æ–‡ä»¶: {target_path} ({size:,} bytes)")
                                    return True, f"ä»ä¸‹è½½ç›®å½•è·å–æ–‡ä»¶: {size:,} bytes"
                                except Exception as e:
                                    logger.warning(f"å¤„ç†ä¸‹è½½ç›®å½•æ–‡ä»¶å¤±è´¥: {e}")
                except Exception:
                    continue

            # 2. æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰ç›´æ¥ä¸‹è½½é“¾æ¥
            try:
                download_links = page.locator('a[href*=".xlsx"], a[download*=".xlsx"]')
                if download_links.count() > 0:
                    link = download_links.first
                    if link.is_visible():
                        href = link.get_attribute('href')
                        if href:
                            logger.info(f"ğŸ”— å‘ç°ç›´æ¥ä¸‹è½½é“¾æ¥: {href}")
                            # è¿™é‡Œå¯ä»¥æ·»åŠ ç›´æ¥ä¸‹è½½é€»è¾‘
                            return False, "å‘ç°ä¸‹è½½é“¾æ¥ä½†æœªå®ç°ç›´æ¥ä¸‹è½½"
            except Exception:
                pass

            # 3. æ£€æŸ¥é¡µé¢æ˜¯å¦æ˜¾ç¤º"å·²ä¸‹è½½"æˆ–ç±»ä¼¼çŠ¶æ€
            try:
                download_status_selectors = [
                    'text="å·²ä¸‹è½½"',
                    'text="Downloaded"',
                    'text="ä¸‹è½½å®Œæˆ"',
                    '[class*="download"][class*="success"]',
                    '[class*="download"][class*="complete"]'
                ]

                for selector in download_status_selectors:
                    try:
                        elements = page.locator(selector)
                        if elements.count() > 0 and elements.first.is_visible():
                            logger.info(f"ğŸ¯ æ£€æµ‹åˆ°ä¸‹è½½çŠ¶æ€æŒ‡ç¤º: {selector}")

                            # å¦‚æœé¡µé¢æ˜¾ç¤ºå·²ä¸‹è½½ï¼Œå†æ¬¡å°è¯•æŸ¥æ‰¾æ–‡ä»¶ï¼ˆå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´ï¼‰
                            logger.info("â³ é¡µé¢æ˜¾ç¤ºå·²ä¸‹è½½ï¼Œç­‰å¾…æ–‡ä»¶å‡ºç°...")
                            for wait_attempt in range(6):  # ç­‰å¾…æœ€å¤š30ç§’
                                time.sleep(5)

                                # é‡æ–°æ£€æŸ¥æ‰€æœ‰ä¸‹è½½ç›®å½•
                                for downloads_dir in possible_download_dirs:
                                    if not downloads_dir.exists():
                                        continue
                                    xlsx_files = list(downloads_dir.glob("*.xlsx"))
                                    if xlsx_files:
                                        latest_file = max(xlsx_files, key=lambda f: f.stat().st_mtime)
                                        if time.time() - latest_file.stat().st_mtime < 600:  # 10åˆ†é’Ÿå†…
                                            try:
                                                import shutil
                                                target_path.parent.mkdir(parents=True, exist_ok=True)
                                                shutil.copy2(latest_file, target_path)
                                                size = target_path.stat().st_size
                                                logger.success(f"âœ… å»¶è¿Ÿè·å–åˆ°æ–‡ä»¶: {target_path} ({size:,} bytes)")
                                                return True, f"å»¶è¿Ÿè·å–æ–‡ä»¶æˆåŠŸ: {size:,} bytes"
                                            except Exception as e:
                                                logger.debug(f"å»¶è¿Ÿè·å–æ–‡ä»¶å¤±è´¥: {e}")

                                logger.info(f"â³ ç­‰å¾…æ–‡ä»¶å‡ºç°... ({(wait_attempt+1)*5}s/30s)")

                            logger.warning("âš ï¸ é¡µé¢æ˜¾ç¤ºå·²ä¸‹è½½ä½†30ç§’å†…æœªè·å–åˆ°æ–‡ä»¶")
                            return False, "é¡µé¢æ˜¾ç¤ºå·²ä¸‹è½½ä½†æ–‡ä»¶è·å–è¶…æ—¶"
                    except Exception:
                        continue
            except Exception:
                pass

            logger.warning("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹è½½æ–¹å¼")
            return False, "ä¸‹è½½å¤±è´¥ï¼Œæœªæ‰¾åˆ°æ–‡ä»¶"

        except Exception as e:
            logger.error(f"æ£€æŸ¥å¤‡ç”¨ä¸‹è½½å¤±è´¥: {e}")
            return False, f"æ£€æŸ¥å¤‡ç”¨ä¸‹è½½å¤±è´¥: {e}"

    def _calculate_granularity(self, start_date: str, end_date: str) -> str:
        """æ ¹æ®æ—¥æœŸèŒƒå›´åŠ¨æ€è®¡ç®—ç²’åº¦"""
        try:
            from datetime import datetime
            start = datetime.strptime(start_date, "%Y-%m-%d")
            end = datetime.strptime(end_date, "%Y-%m-%d")
            days = (end - start).days + 1

            if days == 1:
                return "daily"
            elif 2 <= days <= 7:
                return "weekly"
            elif 8 <= days <= 31:
                return "monthly"
            elif 32 <= days <= 93:
                return "quarterly"
            else:
                return "custom"
        except Exception as e:
            logger.warning(f"è®¡ç®—ç²’åº¦å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return "weekly"


def _safe_slug(s: str) -> str:
    try:
        from modules.utils.path_sanitizer import safe_slug as _ss
        return _ss(s)
    except Exception:
        return "".join(c if (c.isalnum() or c in "-_.") else "_" for c in (s or "")).strip("._") or "unknown"

