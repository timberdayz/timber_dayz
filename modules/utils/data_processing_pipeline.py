#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ™ºèƒ½æ•°æ®å¤„ç†ç®¡é“
è´Ÿè´£ï¼šæ–‡ä»¶é‡å‘½å â†’ ç›®å½•ç»„ç»‡ â†’ æ•°æ®æ¸…æ´— â†’ æ•°æ®åº“è®°å½•
æŒ‰data_organizerè§„èŒƒå®ç°ç»†ç²’åº¦è´¦å·çº§åˆ«åˆ†ç¦»
"""

import os
import shutil
import hashlib
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from pathlib import Path
import pandas as pd

from modules.core.logger import get_logger
from models.database import CollectionTask, DatabaseManager

logger = get_logger(__name__)


class DataProcessingPipeline:
    """æ•°æ®å¤„ç†ç®¡é“"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®å¤„ç†ç®¡é“"""
        self.base_downloads_dir = Path("downloads")
        self.base_processed_dir = Path("processed_data")
        self.backup_dir = Path("temp/backups")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for directory in [self.base_downloads_dir, self.base_processed_dir, self.backup_dir]:
            directory.mkdir(parents=True, exist_ok=True)
    
    def process_collection_result(self, collection_result: Dict[str, Any], 
                                account: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†é‡‡é›†ç»“æœçš„å®Œæ•´æµç¨‹
        
        Args:
            collection_result: é‡‡é›†ç»“æœå­—å…¸
            account: è´¦å·ä¿¡æ¯
            
        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        processing_result = {
            "success": False,
            "processed_files": [],
            "database_records": [],
            "error": None,
            "processing_time": 0
        }
        
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ”„ å¼€å§‹æ•°æ®å¤„ç†æµç¨‹")
            
            # 1. æ–‡ä»¶é‡å‘½åå’Œç»„ç»‡
            if collection_result.get("downloaded_files"):
                for file_path in collection_result["downloaded_files"]:
                    renamed_result = self._rename_and_organize_file(
                        file_path, account, collection_result
                    )
                    if renamed_result["success"]:
                        processing_result["processed_files"].append(renamed_result)
            
            # 2. æ•°æ®æ¸…æ´—ï¼ˆå¦‚æœæœ‰å¤„ç†çš„æ–‡ä»¶ï¼‰
            for file_info in processing_result["processed_files"]:
                if file_info["success"]:
                    cleaned_result = self._clean_data_file(file_info["new_path"], account)
                    file_info["cleaned"] = cleaned_result
            
            # 3. æ•°æ®åº“è®°å½•
            db_record = self._create_database_record(collection_result, account, processing_result)
            if db_record:
                processing_result["database_records"].append(db_record)
            
            # 4. åˆ¤æ–­æ•´ä½“æˆåŠŸçŠ¶æ€
            successful_files = [f for f in processing_result["processed_files"] if f["success"]]
            if successful_files or db_record:
                processing_result["success"] = True
                logger.info(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œå¤„ç†{len(successful_files)}ä¸ªæ–‡ä»¶")
            else:
                processing_result["error"] = "æ²¡æœ‰æˆåŠŸå¤„ç†çš„æ–‡ä»¶"
                
        except Exception as e:
            processing_result["error"] = f"æ•°æ®å¤„ç†å¼‚å¸¸: {e}"
            logger.error(f"âŒ {processing_result['error']}")
        
        finally:
            end_time = datetime.now()
            processing_result["processing_time"] = (end_time - start_time).total_seconds()
            
        return processing_result
    
    def _rename_and_organize_file(self, file_path: str, account: Dict, 
                                collection_result: Dict) -> Dict[str, Any]:
        """é‡å‘½åå’Œç»„ç»‡æ–‡ä»¶åˆ°è§„èŒƒç›®å½•ç»“æ„"""
        result = {
            "success": False,
            "original_path": file_path,
            "new_path": None,
            "error": None
        }
        
        try:
            original_file = Path(file_path)
            if not original_file.exists():
                result["error"] = f"åŸæ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                return result
            
            # ç”Ÿæˆè´¦å·é”®
            account_key = self._generate_account_key(account)
            
            # è·å–å¹³å°å’Œæ•°æ®ç±»å‹
            platform = account.get("platform", "unknown").lower()
            data_type = collection_result.get("data_type", "sales")
            
            # è·å–æ—¥æœŸä¿¡æ¯
            date_range = collection_result.get("date_range", {})
            start_date = date_range.get("start_date", datetime.now().strftime("%Y-%m-%d"))
            end_date = date_range.get("end_date", start_date)
            
            # è§£ææ—¥æœŸ
            try:
                date_obj = datetime.strptime(start_date, "%Y-%m-%d")
            except:
                date_obj = datetime.now()
            
            # æ„å»ºç›®å½•ç»“æ„ï¼šdownloads/{platform}/{account_key}/{data_type}/{YYYY}/{YYYYMM}/{YYYYMMDD}/raw
            target_dir = (self.base_downloads_dir / platform / account_key / data_type / 
                         f"{date_obj.year}" / f"{date_obj.year:04d}{date_obj.month:02d}" / 
                         f"{date_obj.year:04d}{date_obj.month:02d}{date_obj.day:02d}" / "raw")
            target_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆæ–°æ–‡ä»¶å
            new_filename = self._generate_filename(
                platform, account_key, data_type, start_date, end_date, original_file.suffix
            )
            
            new_file_path = target_dir / new_filename
            
            # ç§»åŠ¨æ–‡ä»¶
            shutil.move(str(original_file), str(new_file_path))
            
            result["success"] = True
            result["new_path"] = str(new_file_path)
            
            logger.info(f"âœ… æ–‡ä»¶é‡å‘½åå®Œæˆ: {original_file.name} â†’ {new_filename}")
            
        except Exception as e:
            result["error"] = f"æ–‡ä»¶é‡å‘½åå¤±è´¥: {e}"
            logger.error(f"âŒ {result['error']}")
        
        return result
    
    def _generate_account_key(self, account: Dict) -> str:
        """ç”Ÿæˆè´¦å·é”®"""
        platform = account.get("platform", "unknown").lower()
        store_name = account.get("store_name", "")
        username = account.get("username", "")
        
        # ä¼˜å…ˆä½¿ç”¨store_nameï¼Œå…¶æ¬¡username
        identifier = store_name or username or "unknown"
        
        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        clean_identifier = "".join(c for c in identifier if c.isalnum() or c in "._-")
        
        return f"{platform}_{clean_identifier}".lower().replace("@", "_")
    
    def _generate_filename(self, platform: str, account_key: str, data_type: str,
                          start_date: str, end_date: str, file_extension: str) -> str:
        """ç”Ÿæˆæ ‡å‡†åŒ–æ–‡ä»¶å"""
        try:
            # å½“å‰æ—¶é—´æˆ³
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # æ—¥æœŸèŒƒå›´å­—ç¬¦ä¸²
            if start_date == end_date:
                date_range_str = start_date.replace("-", "")
            else:
                start_str = start_date.replace("-", "")
                end_str = end_date.replace("-", "")
                date_range_str = f"{start_str}_{end_str}"
            
            # ç”Ÿæˆæ–‡ä»¶å†…å®¹å“ˆå¸Œï¼ˆç”¨äºå»é‡ï¼‰
            content_hash = hashlib.md5(f"{platform}_{account_key}_{data_type}_{timestamp}".encode()).hexdigest()[:8]
            
            # æ–‡ä»¶åæ ¼å¼ï¼šYYYYMMDD_HHMMSS_{platform}_{account_key}_{data_type}_{daterange}_{hash}.xlsx
            filename = f"{timestamp}_{platform}_{account_key}_{data_type}_{date_range_str}_{content_hash}{file_extension}"
            
            return filename
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ–‡ä»¶åå¤±è´¥: {e}")
            # é™çº§åˆ°ç®€å•æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            return f"{timestamp}_{platform}_{data_type}{file_extension}"
    
    def _clean_data_file(self, file_path: str, account: Dict) -> Dict[str, Any]:
        """æ•°æ®æ¸…æ´—"""
        result = {
            "success": False,
            "cleaned_file": None,
            "row_count": 0,
            "error": None
        }
        
        try:
            file_path_obj = Path(file_path)
            
            # ç›®å‰åªå¤„ç†Excelæ–‡ä»¶
            if file_path_obj.suffix.lower() not in ['.xlsx', '.xls', '.csv']:
                result["error"] = "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"
                return result
            
            # è¯»å–æ•°æ®
            if file_path_obj.suffix.lower() == '.csv':
                df = pd.read_csv(file_path, encoding='utf-8-sig')
            else:
                df = pd.read_excel(file_path)
            
            if df.empty:
                result["error"] = "æ–‡ä»¶ä¸ºç©º"
                return result
            
            # åŸºæœ¬æ•°æ®æ¸…æ´—
            df_cleaned = self._perform_basic_cleaning(df, account)
            
            # ä¿å­˜æ¸…æ´—åçš„æ–‡ä»¶åˆ°processed_dataç›®å½•
            processed_file = self._save_cleaned_data(df_cleaned, file_path_obj, account)
            
            result["success"] = True
            result["cleaned_file"] = str(processed_file)
            result["row_count"] = len(df_cleaned)
            
            logger.info(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {result['row_count']}è¡Œæ•°æ®")
            
        except Exception as e:
            result["error"] = f"æ•°æ®æ¸…æ´—å¤±è´¥: {e}"
            logger.error(f"âŒ {result['error']}")
        
        return result
    
    def _perform_basic_cleaning(self, df: pd.DataFrame, account: Dict) -> pd.DataFrame:
        """æ‰§è¡ŒåŸºæœ¬æ•°æ®æ¸…æ´—"""
        try:
            df_cleaned = df.copy()
            
            # 1. åˆ é™¤å®Œå…¨ç©ºç™½çš„è¡Œå’Œåˆ—
            df_cleaned = df_cleaned.dropna(how='all').dropna(axis=1, how='all')
            
            # 2. æ ‡å‡†åŒ–æ—¥æœŸåˆ—ï¼ˆå¸¸è§çš„æ—¥æœŸåˆ—åï¼‰
            date_columns = ['æ—¥æœŸ', 'æ—¶é—´', 'date', 'time', 'ä¸‹å•æ—¶é—´', 'åˆ›å»ºæ—¶é—´', 'æ›´æ–°æ—¶é—´']
            for col in df_cleaned.columns:
                if any(date_keyword in str(col).lower() for date_keyword in date_columns):
                    try:
                        df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')
                    except:
                        pass
            
            # 3. æ ‡å‡†åŒ–é‡‘é¢åˆ—ï¼ˆç§»é™¤è´§å¸ç¬¦å·ï¼Œè½¬æ¢ä¸ºæ•°å€¼ï¼‰
            amount_columns = ['é‡‘é¢', 'ä»·æ ¼', 'è´¹ç”¨', 'amount', 'price', 'cost', 'é”€å”®é¢', 'åˆ©æ¶¦']
            for col in df_cleaned.columns:
                if any(amount_keyword in str(col).lower() for amount_keyword in amount_columns):
                    try:
                        # ç§»é™¤è´§å¸ç¬¦å·å’Œé€—å·
                        df_cleaned[col] = df_cleaned[col].astype(str).str.replace(r'[ï¿¥$,]', '', regex=True)
                        df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')
                    except:
                        pass
            
            # 4. æ·»åŠ å¤„ç†å…ƒæ•°æ®
            df_cleaned['_processed_at'] = datetime.now()
            df_cleaned['_account_platform'] = account.get('platform', '')
            df_cleaned['_account_key'] = self._generate_account_key(account)
            
            return df_cleaned
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®æ¸…æ´—å¤„ç†å¤±è´¥: {e}")
            return df
    
    def _save_cleaned_data(self, df: pd.DataFrame, original_file: Path, account: Dict) -> Path:
        """ä¿å­˜æ¸…æ´—åçš„æ•°æ®"""
        try:
            # æ„å»ºprocessed_dataç›®å½•ç»“æ„
            account_key = self._generate_account_key(account)
            platform = account.get("platform", "unknown").lower()
            
            # ä»åŸæ–‡ä»¶è·¯å¾„æå–æ—¥æœŸä¿¡æ¯
            date_parts = original_file.parts
            year = month = day = None
            for part in date_parts:
                if part.isdigit() and len(part) == 4:  # å¹´ä»½
                    year = part
                elif part.isdigit() and len(part) == 6:  # å¹´æœˆ
                    year, month = part[:4], part[4:6]
                elif part.isdigit() and len(part) == 8:  # å¹´æœˆæ—¥
                    year, month, day = part[:4], part[4:6], part[6:8]
            
            if not year:
                year = datetime.now().strftime("%Y")
                month = datetime.now().strftime("%m")
                day = datetime.now().strftime("%d")
            
            processed_dir = (self.base_processed_dir / platform / account_key / "sales" / 
                           year / f"{year}{month}" / f"{year}{month}{day}")
            processed_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆå¤„ç†åæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            row_count = len(df)
            processed_filename = f"{timestamp}_{platform}_{account_key}_sales_{row_count}_v1.parquet"
            
            processed_file = processed_dir / processed_filename
            
            # ä¿å­˜ä¸ºParquetæ ¼å¼ï¼ˆæ›´é«˜æ•ˆï¼‰
            df.to_parquet(processed_file, index=False)
            
            logger.info(f"âœ… æ¸…æ´—æ•°æ®å·²ä¿å­˜: {processed_filename}")
            return processed_file
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ¸…æ´—æ•°æ®å¤±è´¥: {e}")
            # é™çº§ä¿å­˜ä¸ºCSV
            fallback_file = original_file.parent / f"cleaned_{original_file.stem}.csv"
            df.to_csv(fallback_file, index=False, encoding='utf-8-sig')
            return fallback_file
    
    def _create_database_record(self, collection_result: Dict, account: Dict,
                              processing_result: Dict) -> Optional[int]:
        """åˆ›å»ºæ•°æ®åº“è®°å½•"""
        try:
            db_manager = DatabaseManager()
            session = db_manager.get_session()
            
            # åˆ›å»ºCollectionTaskè®°å½•
            task = CollectionTask(
                platform=account.get("platform", "unknown"),
                account_name=account.get("store_name") or account.get("username", "unknown"),
                data_type=collection_result.get("data_type", "sales"),
                status="completed" if collection_result.get("success") else "failed",
                start_date=datetime.fromisoformat(collection_result.get("start_time", datetime.now().isoformat())),
                end_date=datetime.now(),
                file_path=";".join([f["new_path"] for f in processing_result["processed_files"] if f["success"]]),
                error_message=collection_result.get("error") or processing_result.get("error")
            )
            
            session.add(task)
            session.commit()
            
            task_id = task.id
            session.close()
            
            logger.info(f"âœ… æ•°æ®åº“è®°å½•åˆ›å»ºæˆåŠŸ: Task ID {task_id}")
            return task_id
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“è®°å½•å¤±è´¥: {e}")
            return None
