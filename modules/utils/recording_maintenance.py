from __future__ import annotations

"""å½•åˆ¶ä¸è¯Šæ–­æ–‡ä»¶ç»´æŠ¤å·¥å…·

ç­–ç•¥ï¼š
- ç»ä¸åˆ é™¤ï¼Œä»…å½’æ¡£åˆ° backups/ ç›®å½•
- æŒ‰å¹³å°/æ•°æ®ç±»å‹/æ—¶é—´æ’åºï¼Œä¿ç•™æ¯ç±»æœ€è¿‘ N ä¸ªï¼Œå…¶ä½™å½’æ¡£
- æ”¯æŒ dry_run æ˜¾ç¤ºè®¡åˆ’

ç›®å½•ï¼š
- å½•åˆ¶è„šæœ¬ï¼š.diag/recipes/*.json æˆ– temp/development/recordings/*.pyï¼ˆå¯æ‰©å±•ï¼‰
- è¯Šæ–­å¿«ç…§ï¼šè¾“å‡ºç›®å½•ä¸‹çš„ .diag/*
"""
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple
import shutil
import time
from datetime import datetime, timedelta
import zipfile


@dataclass
class RetentionPolicy:
    per_category_keep: int = 10  # æ¯ç±»ï¼ˆå¹³å°/æ•°æ®ç±»å‹ï¼‰ä¿ç•™æœ€è¿‘Nä¸ª
    dry_run: bool = False


class RecordingMaintenance:
    def __init__(self, project_root: Path | None = None, policy: RetentionPolicy | None = None, platform_filter: str | None = None) -> None:
        self.root = project_root or Path.cwd()
        self.policy = policy or RetentionPolicy()
        self.platform_filter = (platform_filter or "").lower() or None
        self.backups = self.root / "backups" / time.strftime("%Y%m%d_recordings_archive")
        self.backups.mkdir(parents=True, exist_ok=True)
        self.actions: list[str] = []  # è®°å½•è®¡åˆ’/å®é™…å½’æ¡£åŠ¨ä½œ
        # ä»é…ç½®è¯»å–é»˜è®¤ç­–ç•¥
        try:
            from modules.core.config import get_config_value
            keep = get_config_value('simple_config', 'collection.maintenance.per_category_keep', self.policy.per_category_keep)
            dry = get_config_value('simple_config', 'collection.maintenance.dry_run_default', True)
            if isinstance(keep, int):
                self.policy.per_category_keep = keep
            if isinstance(dry, bool):
                self.policy.dry_run = dry
        except Exception:
            pass

    def _list_recipe_files(self) -> List[Path]:
        candidates = []
        # é…æ–¹ç›®å½•
        for p in self.root.rglob(".diag/recipes/*.json"):
            candidates.append(p)
        # å½•åˆ¶è„šæœ¬ï¼ˆå¯é€‰ç›®å½•ï¼Œè‹¥ä¸å­˜åœ¨å¿½ç•¥ï¼‰
        rec_dir = self.root / "temp" / "development" / "recordings"
        if rec_dir.exists():
            for p in rec_dir.rglob("*.py"):
                candidates.append(p)
        return candidates

    def _list_diag_dirs(self) -> List[Path]:
        dirs = []
        for p in (self.root / "temp" / "outputs").rglob(".diag"):
            if p.is_dir():
                dirs.append(p)
        return dirs

    def _list_media_dirs(self) -> List[Path]:
        """åˆ—å‡ºåª’ä½“æ–‡ä»¶ç›®å½•ï¼ˆæˆªå›¾/å½•å±ï¼‰"""
        dirs = []
        for sub in ["temp/media", "temp/outputs", "temp/logs"]:
            base = self.root / sub
            if base.exists():
                dirs.append(base)
        return dirs

    def _list_recording_files(self) -> Tuple[List[Path], List[Path]]:
        """è¿”å› (py_list, pyc_list) for temp/recordings/**/*"""
        py_list: List[Path] = []
        pyc_list: List[Path] = []
        base = self.root / "temp" / "recordings"
        if not base.exists():
            return py_list, pyc_list
        for p in base.rglob("*.py"):
            py_list.append(p)
        for p in base.rglob("__pycache__/*.pyc"):
            pyc_list.append(p)
        return py_list, pyc_list

    def _category_key(self, p: Path) -> Tuple[str, str]:
        # å¹³å°è¿‡æ»¤ï¼ˆè‹¥è®¾ç½®ï¼‰
        if self.platform_filter:
            try:
                if self.platform_filter not in [s.lower() for s in p.parts]:
                    return ("__skip__", "__skip__")
            except Exception:
                pass
        # ç®€åŒ–åˆ†ç±»ï¼šå¹³å° + æ•°æ®ç±»å‹ï¼ˆä»è·¯å¾„ä¸­æå–ï¼‰
        path_str = str(p.as_posix())
        platform = "unknown"
        data_type = "unknown"
        # ä¾‹å¦‚ temp/outputs/shopee/<account>/<shop>/<data_type>/...
        parts = p.parts
        if "outputs" in parts:
            try:
                idx = parts.index("outputs")
                platform = parts[idx + 1]
                data_type = parts[idx + 4]
            except Exception:
                pass
        return platform, data_type

    def enforce(self) -> None:
        # ä»é…ç½®è¯»å–ä¿ç•™å¤©æ•°
        try:
            from modules.core.config import get_config_value
            retention = get_config_value('simple_config', 'collection.maintenance.retention_days', {}) or {}
            dev_days = int(retention.get('development', 7))
            out_days = int(retention.get('outputs', 30))
            media_days = int(retention.get('media', 90))
            log_days = int(retention.get('logs', 180))
        except Exception:
            dev_days, out_days, media_days, log_days = 7, 30, 90, 180

        now = datetime.now()
        def older_than(p: Path, days: int) -> bool:
            try:
                return (now - datetime.fromtimestamp(p.stat().st_mtime)) > timedelta(days=days)
            except Exception:
                return False

        # å¤„ç†é…æ–¹æ–‡ä»¶
        recipes = self._list_recipe_files()
        grouped: dict[Tuple[str, str], List[Path]] = {}
        for f in recipes:
            key = self._category_key(f)
            if key == ("__skip__", "__skip__"):
                continue
            grouped.setdefault(key, []).append(f)

        for key, files in grouped.items():
            files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            keep = files[: self.policy.per_category_keep]
            archive = files[self.policy.per_category_keep :]
            if archive:
                for f in archive:
                    rel = f.relative_to(self.root)
                    target_dir = self.backups / rel.parent
                    target_dir.mkdir(parents=True, exist_ok=True)
                    plan = f"ARCHIVE {f} -> {target_dir / f.name}"
                    if self.policy.dry_run:
                        print(f"[DRY_RUN] {plan}")
                        self.actions.append(f"DRY_RUN {plan}")
                    else:
                        shutil.move(str(f), str(target_dir / f.name))
                        self.actions.append(plan)

        # å¤„ç†è¯Šæ–­ç›®å½•ï¼ˆ.diagï¼‰
        diag_dirs = self._list_diag_dirs()
        # åŒå¹³å°/æ•°æ®ç±»å‹ä¸‹ï¼ŒæŒ‰çˆ¶ç›®å½•æ—¶é—´æ’åºå½’æ¡£å¤šä½™
        grouped_dirs: dict[Tuple[str, str], List[Path]] = {}
        for d in diag_dirs:
            key = self._category_key(d)
            if key == ("__skip__", "__skip__"):
                continue
            grouped_dirs.setdefault(key, []).append(d.parent)
        for key, parents in grouped_dirs.items():
            unique_parents = sorted(set(parents), key=lambda x: x.stat().st_mtime, reverse=True)
            keep = unique_parents[: self.policy.per_category_keep]
            archive = unique_parents[self.policy.per_category_keep :]
            for parent in archive:
                rel = parent.relative_to(self.root)
                target_dir = self.backups / rel
                target_dir.parent.mkdir(parents=True, exist_ok=True)
                plan = f"ARCHIVE DIR {parent} -> {target_dir}"
                if self.policy.dry_run:
                    print(f"[DRY_RUN] {plan}")
                    self.actions.append(f"DRY_RUN {plan}")
                else:
                    shutil.move(str(parent), str(target_dir))
                    self.actions.append(plan)

        # å¤„ç†å½•åˆ¶è„šæœ¬ï¼ˆtemp/recordingsï¼‰ï¼šæŒ‰ç±»åˆ«ï¼ˆå¹³å°/ç±»å‹ï¼‰ä¿ç•™ N ä¸ªï¼Œå…¶ä½™å½’æ¡£
        py_list, pyc_list = self._list_recording_files()
        def _rec_key(p: Path) -> Tuple[str, str, str]:
            # å¹³å°/è´¦å·æˆ–åº—é“º/ç±»å‹(login|complete|collection_*|other)
            parts = p.parts
            platform = parts[parts.index('recordings') + 1] if 'recordings' in parts else 'unknown'
            name = p.stem
            # ç±»å‹è¯†åˆ«
            if 'login' in name:
                kind = 'login'
            elif 'complete' in name:
                kind = 'complete'
            elif 'collection_' in name:
                kind = name.split('collection_')[1].split('_')[0]
                kind = f'collection_{kind}'
            else:
                kind = 'other'
            # è´¦å·/åº—é“ºæå–ï¼ˆå°½åŠ›ä»å‰ç¼€å–ä¸€æ®µï¼‰
            account = name.split('_')[0]
            return platform, kind, account
        grouped_rec: dict[Tuple[str, str, str], List[Path]] = {}
        for f in py_list:
            key = _rec_key(f)
            grouped_rec.setdefault(key, []).append(f)
        for key, files in grouped_rec.items():
            files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            archive = files[self.policy.per_category_keep :]
            for f in archive:
                rel = f.relative_to(self.root)
                target_dir = self.backups / rel.parent
                target_dir.mkdir(parents=True, exist_ok=True)
                plan = f"ARCHIVE RECORDING {f} -> {target_dir / f.name}"
                if self.policy.dry_run:
                    print(f"[DRY_RUN] {plan}")
                    self.actions.append(f"DRY_RUN {plan}")
                else:
                    shutil.move(str(f), str(target_dir / f.name))
                    self.actions.append(plan)
        # __pycache__ å½’æ¡£
        for f in pyc_list:
            rel = f.relative_to(self.root)
            target_dir = self.backups / rel.parent
            target_dir.mkdir(parents=True, exist_ok=True)
            plan = f"ARCHIVE PYC {f} -> {target_dir / f.name}"
            if self.policy.dry_run:
                print(f"[DRY_RUN] {plan}")
                self.actions.append(f"DRY_RUN {plan}")
            else:
                shutil.move(str(f), str(target_dir / f.name))
                self.actions.append(plan)

        # å¤„ç†åª’ä½“/æ—¥å¿—ç±»å¤§æ–‡ä»¶ç›®å½•ï¼ˆæŒ‰å¤©æ•°é˜ˆå€¼å½’æ¡£ï¼‰
        for base in self._list_media_dirs():
            for p in base.rglob("*"):
                try:
                    if not p.is_file():
                        continue
                    rel = p.relative_to(self.root)
                    days = media_days
                    if "/logs/" in rel.as_posix():
                        days = log_days
                    elif "/development/" in rel.as_posix():
                        days = dev_days
                    elif "/outputs/" in rel.as_posix():
                        days = out_days
                    if older_than(p, days):
                        target = self.backups / rel
                        target.parent.mkdir(parents=True, exist_ok=True)
                        plan = f"ARCHIVE OLD {p} -> {target}"
                        if self.policy.dry_run:
                            print(f"[DRY_RUN] {plan}")
                            self.actions.append(f"DRY_RUN {plan}")
                        else:
                            shutil.move(str(p), str(target))
                            self.actions.append(plan)
                except Exception:
                    continue

        # å¤‡ä»½è½®è½¬ï¼šå‹ç¼©æ—§çš„ backups/* å­ç›®å½•ï¼ˆæŒ‰é…ç½®ï¼‰
        try:
            from modules.core.config import get_config_value
            backup_cfg = get_config_value('simple_config', 'collection.maintenance.backups', {}) or {}
            rotate_days = int(backup_cfg.get('days', 90))
            enable_zip = bool(backup_cfg.get('compress', True))
            purge_after_zip = bool(backup_cfg.get('purge_after_zip', False))
        except Exception:
            rotate_days, enable_zip, purge_after_zip = 90, True, False

        # å…è®¸ CLI è¦†ç›–ï¼ˆä»…å½“å‰è¿è¡Œç”Ÿæ•ˆï¼‰
        override_purge = getattr(self, "_override_purge", None)
        if override_purge is True:
            purge_after_zip = True
        override_rotate = getattr(self, "_override_rotate_days", None)
        if isinstance(override_rotate, int) and override_rotate > 0:
            rotate_days = override_rotate

        backups_root = self.root / "backups"
        for sub in backups_root.iterdir() if backups_root.exists() else []:
            try:
                if not sub.is_dir():
                    continue
                if not older_than(sub, rotate_days):
                    continue
                if enable_zip:
                    zip_path = backups_root / f"{sub.name}.zip"
                    plan = f"ZIP {sub} -> {zip_path}"
                    if self.policy.dry_run:
                        print(f"[DRY_RUN] {plan}")
                        self.actions.append(f"DRY_RUN {plan}")
                    else:
                        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                            for f in sub.rglob('*'):
                                if f.is_file():
                                    zf.write(f, f.relative_to(backups_root))
                        self.actions.append(plan)
                        if purge_after_zip:
                            shutil.rmtree(sub, ignore_errors=True)
                            self.actions.append(f"PURGE {sub}")
                else:
                    # ä»…æŠ¥å‘Šå¯å‹ç¼©é¡¹
                    plan = f"ROTATE ELIGIBLE {sub} (older than {rotate_days}d)"
                    print(f"[DRY_RUN] {plan}")
                    self.actions.append(f"DRY_RUN {plan}")
            except Exception:
                continue


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Recordings/Diagnostics maintenance (archive-only)")
    parser.add_argument("--platform", help="filter platform (e.g., shopee, miaoshou, tiktok)", default=None)
    parser.add_argument("--keep", type=int, help="per-category keep count (override config)", default=None)
    parser.add_argument("--apply", action="store_true", help="apply changes (disable dry-run)")
    parser.add_argument("--purge-plan", action="store_true", help="plan purge-after-zip (DRY-RUN unless --apply)")
    parser.add_argument("--rotate-days", type=int, help="override backups rotate days for this run", default=None)
    args = parser.parse_args()

    tool = RecordingMaintenance(platform_filter=args.platform)
    if args.keep is not None:
        tool.policy.per_category_keep = args.keep
    if args.apply:
        tool.policy.dry_run = False
    if args.purge_plan:
        setattr(tool, "_override_purge", True)
    if args.rotate_days is not None:
        setattr(tool, "_override_rotate_days", int(args.rotate_days))

    # ç»Ÿè®¡å½’æ¡£å‰å®¹é‡
    def _dir_size(p: Path) -> int:
        total = 0
        if p.exists():
            for f in p.rglob("*"):
                try:
                    if f.is_file():
                        total += f.stat().st_size
                except Exception:
                    pass
        return total

    outputs_dir = tool.root / "temp" / "outputs"
    before_size = _dir_size(outputs_dir)

    tool.enforce()

    after_size = _dir_size(outputs_dir)
    saved = before_size - after_size if before_size >= after_size else 0
    mode = "APPLY" if not tool.policy.dry_run else "DRY-RUN"
    print(f"âœ… ç»´æŠ¤å®Œæˆ [{mode}]ï¼šå½’æ¡£å‰ {before_size/1024/1024:.2f} MBï¼Œå½’æ¡£å {after_size/1024/1024:.2f} MBï¼Œè¡¨è§‚é‡Šæ”¾ {saved/1024/1024:.2f} MBï¼ˆç§»åŠ¨è‡³ backupsï¼‰")

    # å†™å‡ºæŠ¥å‘Š
    try:
        reports_dir = tool.root / "temp" / "logs" / "maintenance"
        reports_dir.mkdir(parents=True, exist_ok=True)
        ts = time.strftime("%Y%m%d_%H%M%S")
        report = reports_dir / f"{ts}_recordings_archive_report.txt"
        report.write_text(
            "\n".join([
                f"Mode: {mode}",
                f"Before: {before_size} bytes",
                f"After: {after_size} bytes",
                f"Saved: {saved} bytes",
                "",
                "Actions:",
                *tool.actions,
            ]),
            encoding="utf-8"
        )
        print(f"ğŸ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {report}")
    except Exception:
        pass
