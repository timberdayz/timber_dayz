# 并发任务处理问题调查报告

**日期**: 2026-01-03  
**状态**: ✅ 问题已定位  
**根本原因**: API 速率限制（预期行为）

---

## 问题描述

在性能测试中，并发任务提交测试失败：

- 3 个并发任务：✅ 全部成功
- 5 个并发任务：✅ 全部成功
- 10 个并发任务：❌ 只有 2 个成功，8 个失败

---

## 调查结果

### 测试数据

| 并发数 | 成功 | 失败 | 失败原因            |
| ------ | ---- | ---- | ------------------- |
| 3      | 3    | 0    | -                   |
| 5      | 5    | 0    | -                   |
| 10     | 2    | 8    | HTTP 429 - 速率限制 |

### 错误详情

**失败任务错误信息**:

```
HTTP 429 - 速率限制错误，请稍后重试
详情: "10 per 1 minute"
Retry-After: 60秒
```

**时间分布**:

- 失败任务时间差：22.47ms（几乎同时提交）
- 这表明存在竞态条件，多个请求同时到达限流检查点

---

## 根本原因

### API 限流配置

单文件同步 API (`/api/data-sync/single`) 的限流配置：

```python
@conditional_rate_limit("10/minute")  # 每分钟最多 10 次
async def sync_single_file(...):
    ...
```

### 限流机制

1. **FastAPI 层限流**（slowapi）:

   - 单文件同步：10 次/分钟
   - 批量同步：5 次/分钟
   - 全量同步：3 次/分钟

2. **Nginx 层限流**:
   - 数据同步 API：30 次/分钟（burst=10）

### 问题分析

当 10 个任务几乎同时提交时（时间差 < 100ms）：

1. 所有请求几乎同时到达 FastAPI 限流检查点
2. 前几个请求通过限流检查
3. 后续请求被限流拦截（HTTP 429）
4. 这不是 bug，而是**预期的安全机制**

---

## 结论

### ✅ 这是预期的行为

限流机制正常工作，目的是：

- 防止 API 滥用
- 保护后端服务资源
- 防止恶意攻击

### ⚠️ 对测试的影响

1. **性能测试**:

   - 3-5 个并发任务可以正常测试
   - 10 个并发任务会触发限流

2. **压力测试**:
   - 需要调整测试方法（见下文）

---

## 解决方案

### 方案 1: 调整测试方法（推荐）

#### 1.1 增加请求间隔

```python
# 在并发测试中，每个请求间隔 100ms
for i, file_id in enumerate(file_ids):
    submit_task(file_id)
    if i < len(file_ids) - 1:
        time.sleep(0.1)  # 100ms 间隔
```

#### 1.2 使用批量同步 API

批量同步 API 可以一次提交多个文件，避免多次调用单文件 API：

```python
# 使用批量同步 API
payload = {
    "file_ids": [1948, 1947, 1946, ...],
    "priority": 5
}
response = requests.post("/api/data-sync/batch", json=payload)
```

#### 1.3 分批次测试

将 10 个任务分成多个批次，每批次间隔 1 分钟：

```python
# 第一批：5 个任务
# 等待 1 分钟
# 第二批：5 个任务
```

### 方案 2: 调整限流配置（仅用于测试环境）

如果需要在测试环境中进行压力测试，可以：

1. **临时提高限流阈值**:

   ```python
   @conditional_rate_limit("30/minute")  # 从 10 提高到 30
   ```

2. **使用环境变量控制**:

   ```python
   rate_limit = os.getenv("RATE_LIMIT_SINGLE_FILE", "10/minute")
   @conditional_rate_limit(rate_limit)
   ```

3. **测试时禁用限流**:
   ```python
   # 在测试环境中设置环境变量
   RATE_LIMIT_ENABLED=false
   ```

### 方案 3: 使用更智能的限流策略

考虑实施基于用户的限流，而不是全局限流：

```python
# 每个用户独立限流
@limiter.limit("10/minute", key_func=lambda: f"user_{current_user.user_id}")
```

---

## 建议

### 对于性能测试

1. ✅ **使用 3-5 个并发任务**进行性能测试（不会触发限流）
2. ✅ **使用批量同步 API**进行大规模测试
3. ✅ **增加请求间隔**（100ms）避免触发限流

### 对于压力测试

1. ⚠️ **分批次测试**：将 100 个任务分成多个批次
2. ⚠️ **使用批量 API**：一次提交多个文件
3. ⚠️ **考虑临时调整限流**：仅在测试环境中

### 对于生产环境

1. ✅ **保持当前限流配置**：10 次/分钟是合理的
2. ✅ **监控限流触发情况**：如果经常触发，考虑调整
3. ✅ **考虑用户级限流**：不同用户独立限流

---

## 测试脚本更新

已创建调试脚本 `scripts/test_concurrent_tasks_debug.py`，可以：

- 详细分析并发任务失败原因
- 显示错误类型和时间分布
- 帮助识别竞态条件

---

## 相关文件

- `backend/routers/data_sync.py` - API 限流配置
- `scripts/test_concurrent_tasks_debug.py` - 并发任务调试脚本
- `scripts/test_celery_performance.py` - 性能测试脚本

---

## 下一步

1. ✅ 问题已定位（API 速率限制）
2. ⏳ 更新性能测试脚本，使用批量 API 或增加间隔
3. ⏳ 进行压力测试（使用调整后的方法）
