#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¿ç§»file_hashè„šæœ¬

å°†ç°æœ‰è®°å½•çš„file_hashæ›´æ–°ä¸ºåŒ…å«shop_idå’Œplatform_codeçš„æ–°hashå€¼ã€‚
"""

import sys
from pathlib import Path
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sqlalchemy import func, select, update
from modules.core.db import CatalogFile
from backend.models.database import SessionLocal
from modules.core.logger import get_logger

logger = get_logger(__name__)


def _compute_sha256_with_metadata(file_path: Path, shop_id: str = None, platform_code: str = None, block_size: int = 1024 * 1024) -> str:
    """
    è®¡ç®—æ–‡ä»¶SHA256å“ˆå¸Œï¼ˆåŒ…å«shop_idå’Œplatform_codeï¼‰
    
    â­ v4.17.3ä¿®å¤ï¼šå°†shop_idå’Œplatform_codeçº³å…¥hashè®¡ç®—
    """
    h = hashlib.sha256()
    
    # å…ˆåŠ å…¥shop_idå’Œplatform_codeï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if shop_id:
        h.update(f"shop_id:{shop_id}".encode('utf-8'))
    if platform_code:
        h.update(f"platform:{platform_code}".encode('utf-8'))
    
    # å†åŠ å…¥æ–‡ä»¶å†…å®¹
    with open(file_path, "rb") as f:
        while True:
            chunk = f.read(block_size)
            if not chunk:
                break
            h.update(chunk)
    
    return h.hexdigest()


def migrate_file_hash(dry_run: bool = True):
    """
    è¿ç§»file_hash
    
    Args:
        dry_run: å¦‚æœä¸ºTrueï¼Œåªæ˜¾ç¤ºå°†è¦æ›´æ–°çš„è®°å½•ï¼Œä¸å®é™…æ›´æ–°
    """
    db = SessionLocal()
    
    try:
        print(f"\n{'='*80}")
        print(f"ğŸ”„ file_hashè¿ç§»è„šæœ¬ï¼ˆv4.17.3ä¿®å¤ï¼‰")
        print(f"{'='*80}\n")
        
        if dry_run:
            print(f"âš ï¸  è¿è¡Œæ¨¡å¼: DRY RUNï¼ˆåªæ˜¾ç¤ºï¼Œä¸å®é™…æ›´æ–°ï¼‰\n")
        else:
            print(f"âš ï¸  è¿è¡Œæ¨¡å¼: å®é™…æ›´æ–°ï¼ˆå°†ä¿®æ”¹æ•°æ®åº“ï¼‰\n")
        
        # 1. æŸ¥è¯¢æ‰€æœ‰éœ€è¦æ›´æ–°çš„è®°å½•
        files = db.execute(
            select(CatalogFile).where(
                CatalogFile.file_hash.isnot(None),
                CatalogFile.file_path.isnot(None)
            )
        ).scalars().all()
        
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        print(f"{'-'*80}")
        print(f"éœ€è¦æ›´æ–°çš„è®°å½•æ•°: {len(files)}")
        print()
        
        # 2. å¤„ç†æ¯æ¡è®°å½•
        updated_count = 0
        skipped_count = 0
        error_count = 0
        
        print(f"ğŸ“‹ å¤„ç†è®°å½•")
        print(f"{'-'*80}")
        
        for idx, file_record in enumerate(files, 1):
            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                file_path = Path(file_record.file_path)
                if not file_path.exists():
                    logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                    skipped_count += 1
                    continue
                
                # è·å–shop_idå’Œplatform_code
                shop_id = file_record.shop_id
                platform_code = file_record.platform_code or file_record.source_platform
                
                # è®¡ç®—æ–°çš„hash
                new_hash = _compute_sha256_with_metadata(
                    file_path,
                    shop_id=shop_id,
                    platform_code=platform_code
                )
                
                # æ£€æŸ¥hashæ˜¯å¦å˜åŒ–
                old_hash = file_record.file_hash
                if old_hash == new_hash:
                    # hashæ²¡æœ‰å˜åŒ–ï¼Œè·³è¿‡
                    skipped_count += 1
                    continue
                
                # æ˜¾ç¤ºæ›´æ–°ä¿¡æ¯
                if idx <= 10 or not dry_run:  # åªæ˜¾ç¤ºå‰10æ¡æˆ–å®é™…æ›´æ–°æ—¶æ˜¾ç¤ºæ‰€æœ‰
                    print(f"{idx}. {file_record.file_name}")
                    print(f"   æ—§hash: {old_hash[:16]}...")
                    print(f"   æ–°hash: {new_hash[:16]}...")
                    print(f"   shop_id: {shop_id}, platform_code: {platform_code}")
                
                # æ›´æ–°è®°å½•
                if not dry_run:
                    # æ£€æŸ¥æ–°hashæ˜¯å¦å·²å­˜åœ¨ï¼ˆé¿å…å†²çªï¼‰
                    existing = db.execute(
                        select(CatalogFile).where(CatalogFile.file_hash == new_hash)
                    ).scalar_one_or_none()
                    
                    if existing and existing.id != file_record.id:
                        logger.error(
                            f"æ–°hashå·²å­˜åœ¨ï¼ˆå†²çªï¼‰: {file_record.file_name}, "
                            f"æ–°hash={new_hash[:16]}..., å·²å­˜åœ¨è®°å½•ID={existing.id}"
                        )
                        error_count += 1
                        continue
                    
                    # æ›´æ–°hash
                    db.execute(
                        update(CatalogFile)
                        .where(CatalogFile.id == file_record.id)
                        .values(file_hash=new_hash)
                    )
                    updated_count += 1
                else:
                    updated_count += 1
                
            except Exception as e:
                logger.error(f"å¤„ç†è®°å½•å¤±è´¥: {file_record.file_name}, é”™è¯¯: {e}", exc_info=True)
                error_count += 1
        
        # 3. æäº¤äº‹åŠ¡
        if not dry_run:
            db.commit()
            print(f"\nâœ… å·²æäº¤ {updated_count} æ¡è®°å½•çš„æ›´æ–°")
        else:
            print(f"\nğŸ“Š é¢„è§ˆç»“æœï¼ˆDRY RUNï¼‰")
        
        # 4. æ˜¾ç¤ºç»Ÿè®¡
        print(f"\n{'='*80}")
        print(f"ğŸ“Š è¿ç§»ç»Ÿè®¡")
        print(f"{'='*80}")
        print(f"æ€»è®°å½•æ•°: {len(files)}")
        print(f"æ›´æ–°è®°å½•æ•°: {updated_count}")
        print(f"è·³è¿‡è®°å½•æ•°: {skipped_count}ï¼ˆhashæœªå˜åŒ–æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
        print(f"é”™è¯¯è®°å½•æ•°: {error_count}")
        print()
        
        if dry_run:
            print(f"ğŸ’¡ æç¤º: è¿™æ˜¯DRY RUNæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…æ›´æ–°æ•°æ®åº“")
            print(f"   è¦å®é™…æ‰§è¡Œæ›´æ–°ï¼Œè¯·è¿è¡Œ: python scripts/migrate_file_hash_with_metadata.py --execute")
        else:
            print(f"âœ… è¿ç§»å®Œæˆï¼")
        
        print(f"\n{'='*80}\n")
        
    except Exception as e:
        logger.error(f"è¿ç§»å¤±è´¥: {e}", exc_info=True)
        db.rollback()
        print(f"\nâŒ è¿ç§»å¤±è´¥: {e}")
    finally:
        db.close()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="è¿ç§»file_hashï¼ˆåŒ…å«shop_idå’Œplatform_codeï¼‰")
    parser.add_argument("--execute", action="store_true", help="å®é™…æ‰§è¡Œæ›´æ–°ï¼ˆé»˜è®¤æ˜¯DRY RUNï¼‰")
    args = parser.parse_args()
    
    migrate_file_hash(dry_run=not args.execute)

